{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "477b0698-1d5c-4d85-b5a5-0c4cc9766421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "665026fc-9622-4dc3-972e-4e8c3de33e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5a20b11-1a27-4f59-8054-f4686a12e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4198c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dae2ca0-69c8-442c-8bee-da802a6b26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4300b2-d429-48f4-85ed-68772465def6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18d6bf42-0914-487c-922f-b54f2712adee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7fa2fad23f70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/deep-learning-dna/dnabert-pretrain-ablation-dim:8dim\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc98b4a9-90f8-442f-8f7e-7633b6f117cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples:v1, 4086.55MB. 1260 files... Done. 0:0:0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples:v1\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae0979-85aa-46e8-9cc4-61380710728e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate batches\n",
    "split_ratios = [0.8, 0.2]\n",
    "subsample_length = 1000\n",
    "sequence_length = 150\n",
    "kmer = 3\n",
    "batch_size = 20\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613ec15a-94ea-40f6-83c4-593956d79975",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bfd656b-2de3-4a36-a0d6-9be8c1492d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n",
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n"
     ]
    }
   ],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=subsample_length, sequence_length=sequence_length,kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81aba5f7-0fd3-4017-8eeb-cd955c99b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Apr2016_S84_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes5-5-CCE_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MR-Apr2016_S13_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Sep2015_S43_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley012-HN-051120_S151_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Sep2015_S91_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Sep2015_S52_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes26-8-AG_S27_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Jul2016_S22_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes25-8-MU_S26_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Oct2016_S63_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes3-5-TCR_S4_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-May2015_S160_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Oct2016_S80_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Jul2015_S74_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Sep2015_S35_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-CCW-Sep2015_S28_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Oct2016_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HF-Jul2015_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-May2015_S73_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Apr2016_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Apr2016_S85_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes20-8-HF_S21_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes38-10-WH_S39_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley047-SF-100420_S186_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley055-HAP-051120_S194_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley006-HLP-051220_S145_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes39-10-HF_S40_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-Jul2016_S38_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley035-HLP2-072820_S174_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes13-5-HLP_S14_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-May2015_S17_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley005-HF-051220_S144_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes47-10-FC_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-May2015_S152_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley045-HLP-100420_S184_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley033-MU-072820_S172_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley043-L-100420_S182_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes48-10-CCW_S49_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Sep2015_S44_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley010-HW-051120_S149_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes36-8-HW_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley011-Ag-051120_S150_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley027-HLP-072820_S166_L001_R1_001.db']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be7e12c7-d792-4e37-9ab2-3db8658b5814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae445919-6300-44ff-b3c2-fd2d9828335b",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5928c7f-92ab-4952-ab8b-477e0e457959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder= dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6fc1685-c320-40f5-bb4a-1c217be25963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47f6fd-2a44-46f8-8b46-15fc33786e13",
   "metadata": {},
   "source": [
    "---\n",
    "# Set Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f11e396d-98b4-47ce-903a-c342ec73e234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Set_Transformer_Model(keras.Model):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha, seq_len, encoder, output_shape):\n",
    "        super(Set_Transformer_Model, self).__init__()\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.isabs = []\n",
    "        \n",
    "        for i in range(stack):\n",
    "            self.isabs.append(Set_Transformer.InducedSetAttentionBlock(embed_dim=embed_dim,num_heads=num_heads,num_induce=num_induce,use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha))\n",
    "      \n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "        \n",
    "        self.output_layer = keras.layers.Dense(output_shape)\n",
    "    \n",
    "    def call(self, data):\n",
    "        \n",
    "            embeddings = self.embedding_layer(data)\n",
    "            \n",
    "            linear_transform = self.linear_layer(embeddings)\n",
    "            \n",
    "            attention = linear_transform\n",
    "            \n",
    "            for isab in self.isabs:\n",
    "                attention = isab([attention, None])\n",
    "                \n",
    "            pooling = self.pooling_layer(attention)\n",
    "        \n",
    "            reshape = self.reshape_layer(pooling)\n",
    "            \n",
    "            output = self.output_layer(reshape)    \n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c8632-97aa-46b0-9af1-afee2c87613f",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15b79d89-3c83-41f0-954f-86419d612032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_induce = 30\n",
    "embed_dim = 32\n",
    "num_heads = 4\n",
    "stack = 4\n",
    "use_layernorm = True\n",
    "pre_layernorm = True\n",
    "use_keras_mha = True\n",
    "seq_len = 148\n",
    "encoder = pretrained_encoder\n",
    "output_shape = max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11a8fa23-80d6-47e7-9f5d-39e6d55c6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Set_Transformer_Model(num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha, seq_len, encoder, output_shape)\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51fbd3f6-ad09-4e86-a5e4-27703b9e21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbf382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "20/20 [==============================] - 188s 9s/step - loss: 4.1346 - sparse_categorical_accuracy: 0.0250 - val_loss: 4.0732 - val_sparse_categorical_accuracy: 0.0125\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 175s 9s/step - loss: 4.0407 - sparse_categorical_accuracy: 0.0350 - val_loss: 4.0354 - val_sparse_categorical_accuracy: 0.0375\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 175s 9s/step - loss: 3.9474 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.9302 - val_sparse_categorical_accuracy: 0.0275\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 175s 9s/step - loss: 3.9059 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9189 - val_sparse_categorical_accuracy: 0.0175\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 176s 9s/step - loss: 3.8970 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8768 - val_sparse_categorical_accuracy: 0.0475\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.8009 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.8152 - val_sparse_categorical_accuracy: 0.0450\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7686 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8143 - val_sparse_categorical_accuracy: 0.0325\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7936 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.7407 - val_sparse_categorical_accuracy: 0.0325\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7331 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.7112 - val_sparse_categorical_accuracy: 0.0475\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7878 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.7184 - val_sparse_categorical_accuracy: 0.0200\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7071 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.7054 - val_sparse_categorical_accuracy: 0.0425\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.7118 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.7590 - val_sparse_categorical_accuracy: 0.0375\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.6972 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.6992 - val_sparse_categorical_accuracy: 0.0400\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 176s 9s/step - loss: 3.7199 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.6605 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 184s 9s/step - loss: 3.6333 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.6671 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 228s 12s/step - loss: 3.5651 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.5774 - val_sparse_categorical_accuracy: 0.0825\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 176s 9s/step - loss: 3.6100 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5725 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.6025 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5663 - val_sparse_categorical_accuracy: 0.0875\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.5539 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.5340 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.4498 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4765 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.4847 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.4423 - val_sparse_categorical_accuracy: 0.0625\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.4547 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.5131 - val_sparse_categorical_accuracy: 0.0625\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.4381 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.4488 - val_sparse_categorical_accuracy: 0.0725\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.4093 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3821 - val_sparse_categorical_accuracy: 0.1025\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3820 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.3731 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3406 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3780 - val_sparse_categorical_accuracy: 0.0925\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3751 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3565 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3293 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3080 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3434 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3281 - val_sparse_categorical_accuracy: 0.0575\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3406 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.2775 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.2798 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.2955 - val_sparse_categorical_accuracy: 0.0725\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.2961 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.2845 - val_sparse_categorical_accuracy: 0.1050\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.2919 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2467 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 177s 9s/step - loss: 3.3028 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.2815 - val_sparse_categorical_accuracy: 0.0475\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.2474 - sparse_categorical_accuracy: 0.0925"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d585f-8f1a-455d-a812-4b1931ab19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Set_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c554e7-b35d-4322-96f6-30d2ac93ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Set_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24ec60e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Plot history and accuracy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m211\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACGCAYAAADQHI0rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAALJElEQVR4nO3dX4hc533G8e/TlQWNa+IkXrtBshq1qHVViMGZKm6TNnaLU8k0iIAv5IYYTEC4jUvpRYnphXPRm5bclLROhDAi5CLWRWMnKsiWDaF1qOtUq+I/khOHrZLGiwL+i0OdUiPn14s5QsN613u0Ozuz2ff7gWHnnPd9Z3/zsnuePWfnnJOqQpLUrl+YdgGSpOkyCCSpcQaBJDXOIJCkxhkEktQ4g0CSGrdiECQ5kuTFJKeXaU+SLyaZT/JMkhtG2vYmeb5ru2echUuSxqPPHsFXgL3v0L4P2NU9DgJfBkgyA9zXte8Gbk+yey3FSpLGb8UgqKrHgVffoct+4Ks19CRwZZL3A3uA+ao6W1VvAke7vpKkDWQc/yPYBrwwsrzQrVtuvSRpA9kyhtfIEuvqHdYv/SLJQYaHlrj88ss/dN11142hNElqw6lTp16uqtnVjB1HECwA144sbwfOAVuXWb+kqjoMHAYYDAY1Nzc3htIkqQ1J/nu1Y8dxaOgYcEf36aEbgder6sfASWBXkp1JtgIHur6SpA1kxT2CJA8ANwFXJVkAPg9cBlBVh4DjwK3APPBT4M6u7XySu4ETwAxwpKrOrMN7kCStwYpBUFW3r9BewGeXaTvOMCgkSRuUZxZLUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhrXKwiS7E3yfJL5JPcs0f5XSZ7qHqeTvJXkvV3bD5M827V5I2JJ2mD63KpyBrgPuIXhjepPJjlWVc9d6FNVXwC+0PX/BPCXVfXqyMvcXFUvj7VySdJY9Nkj2APMV9XZqnoTOArsf4f+twMPjKM4SdL66xME24AXRpYXunVvk+RdwF7g6yOrC3g0yakkB1dbqCRpfax4aAjIEutqmb6fAP5t0WGhj1TVuSRXA48l+V5VPf62bzIMiYMAO3bs6FGWJGkc+uwRLADXjixvB84t0/cAiw4LVdW57uuLwEMMDzW9TVUdrqpBVQ1mZ2d7lCVJGoc+QXAS2JVkZ5KtDDf2xxZ3SvJu4GPAN0fWXZ7kigvPgY8Dp8dRuCRpPFY8NFRV55PcDZwAZoAjVXUmyV1d+6Gu6yeBR6vqjZHh1wAPJbnwvb5WVY+M8w1IktYmVcsd7p+ewWBQc3OeciBJfSU5VVWD1Yz1zGJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuN6BUGSvUmeTzKf5J4l2m9K8nqSp7rHvX3HSpKma8VbVSaZAe4DbmF4I/uTSY5V1XOLun67qv54lWMlSVPSZ49gDzBfVWer6k3gKLC/5+uvZawkaQL6BME24IWR5YVu3WK/k+TpJA8n+a1LHEuSg0nmksy99NJLPcqSJI1DnyDIEusW3/H+P4FfqarrgX8AvnEJY4crqw5X1aCqBrOzsz3KkiSNQ58gWACuHVneDpwb7VBVP6mq/+meHwcuS3JVn7GSpOnqEwQngV1JdibZChwAjo12SPLLSdI939O97it9xkqSpmvFTw1V1fkkdwMngBngSFWdSXJX134IuA340yTngf8FDlRVAUuOXaf3IklahQy31xvLYDCoubm5aZchST83kpyqqsFqxnpmsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY3rFQRJ9iZ5Psl8knuWaP9Ukme6xxNJrh9p+2GSZ5M8lcSbDEjSBrPiHcqSzAD3AbcwvAfxySTHquq5kW4/AD5WVa8l2QccBj480n5zVb08xrolSWPSZ49gDzBfVWer6k3gKLB/tENVPVFVr3WLTzK8Sb0k6edAnyDYBrwwsrzQrVvOZ4CHR5YLeDTJqSQHL71ESdJ6WvHQEJAl1i15o+MkNzMMgo+OrP5IVZ1LcjXwWJLvVdXjS4w9CBwE2LFjR4+yJEnj0GePYAG4dmR5O3BucackHwTuB/ZX1SsX1lfVue7ri8BDDA81vU1VHa6qQVUNZmdn+78DSdKa9AmCk8CuJDuTbAUOAMdGOyTZATwIfLqqvj+y/vIkV1x4DnwcOD2u4iVJa7fioaGqOp/kbuAEMAMcqaozSe7q2g8B9wLvA76UBOB8VQ2Aa4CHunVbgK9V1SPr8k4kSauSqiUP90/VYDCouTlPOZCkvpKc6v4Av2SeWSxJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalyvIEiyN8nzSeaT3LNEe5J8sWt/JskNfcdKkqZrxSBIMgPcB+wDdgO3J9m9qNs+YFf3OAh8+RLGSpKmqM8ewR5gvqrOVtWbwFFg/6I++4Gv1tCTwJVJ3t9zrCRpivoEwTbghZHlhW5dnz59xkqSpmhLjz5ZYt3iO94v16fP2OELJAcZHlYC+L8kp3vU1oKrgJenXcQG4Dxc5Fxc5Fxc9BurHdgnCBaAa0eWtwPnevbZ2mMsAFV1GDgMkGSuqgY9atv0nIsh5+Ei5+Ii5+KiJHOrHdvn0NBJYFeSnUm2AgeAY4v6HAPu6D49dCPwelX9uOdYSdIUrbhHUFXnk9wNnABmgCNVdSbJXV37IeA4cCswD/wUuPOdxq7LO5EkrUqfQ0NU1XGGG/vRdYdGnhfw2b5jezh8if03M+diyHm4yLm4yLm4aNVzkeE2XJLUKi8xIUmNm1oQrOWyFZtNj7n4VDcHzyR5Isn106hzEvpekiTJbyd5K8ltk6xvkvrMRZKbkjyV5EySf510jZPS43fk3Un+OcnT3VzcOY0611uSI0leXO7j9aveblbVxB8M/3H8X8CvMvyI6dPA7kV9bgUeZnguwo3Ad6ZR6waZi98F3tM939fyXIz0+xbD/z3dNu26p/hzcSXwHLCjW7562nVPcS7+Gvi77vks8Cqwddq1r8Nc/D5wA3B6mfZVbTentUewlstWbDYrzkVVPVFVr3WLTzI8H2Mz6ntJkj8Hvg68OMniJqzPXPwJ8GBV/QigqjbrfPSZiwKuSBLglxgGwfnJlrn+qupxhu9tOavabk4rCNZy2YrN5lLf52cYJv5mtOJcJNkGfBI4xObW5+fi14H3JPmXJKeS3DGx6iarz1z8I/CbDE9YfRb4i6r62WTK21BWtd3s9fHRdbCWy1ZsNpdyGY6bGQbBR9e1ounpMxd/D3yuqt4a/vG3afWZiy3Ah4A/BH4R+PckT1bV99e7uAnrMxd/BDwF/AHwa8BjSb5dVT9Z59o2mlVtN6cVBGu5bMVm0+t9JvkgcD+wr6pemVBtk9ZnLgbA0S4ErgJuTXK+qr4xkQonp+/vyMtV9QbwRpLHgeuBzRYEfebiTuBva3igfD7JD4DrgP+YTIkbxqq2m9M6NLSWy1ZsNivORZIdwIPApzfhX3ujVpyLqtpZVR+oqg8A/wT82SYMAej3O/JN4PeSbEnyLuDDwHcnXOck9JmLHzHcMyLJNQwvwHZ2olVuDKvabk5lj6DWcNmKzabnXNwLvA/4UveX8PnahBfa6jkXTegzF1X13SSPAM8APwPur6pNd9Xenj8XfwN8JcmzDA+PfK6qNt1VSZM8ANwEXJVkAfg8cBmsbbvpmcWS1DjPLJakxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ17v8B+hrXNvxq5OsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot history and accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae52ab4-742c-4cc1-bdc7-feb96529a535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../deep-learning-dna\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../../deep-learning-dna/common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b9c98a-b4ee-4667-89a3-5f04549f7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "from Attention import Set_Transformer\n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utilities as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7f146bf721d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-64dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   420 of 420 files downloaded.  \n",
      "Done. 0:0:3.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./artifacts/dnasamples-complete:v0/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download()\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [1,1]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:5], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len, kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 250\n",
    "max_set_len = set_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > set_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(max_set_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        result = tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "        return result\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4600b-3e9b-45f0-bb25-d5fe78129767",
   "metadata": {},
   "source": [
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1ce3fc91-be96-4395-87c5-49f35689bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cache_Memory(current_state, previous_state, memory_length):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "            excess = current_state[:, :-memory_length, :]\n",
    "        else:\n",
    "            concatanted =  tf.concat([previous_state, current_state], 1)\n",
    "            new_mem = concatanted[:, -memory_length:, :]\n",
    "            excess = concatanted[:,:-memory_length,:]\n",
    "            \n",
    "    return tf.stop_gradient(new_mem), tf.stop_gradient(excess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50453f-628c-412e-942b-d486d01c6b8a",
   "metadata": {},
   "source": [
    "---\n",
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1bf9ef79-9ede-4271-8542-223cdd1e11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(keras.layers.Layer):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        if self.num_induce == 0:       \n",
    "            self.attention = (Set_Transformer.SetAttentionBlock(embed_dim=self.embed_dim, num_heads=self.num_heads, use_layernorm=self.use_layernorm,pre_layernorm=self.pre_layernorm,use_keras_mha=self.use_keras_mha))\n",
    "        else:\n",
    "            self.attention = Set_Transformer.InducedSetAttentionBlock(embed_dim=self.embed_dim, num_heads=self.num_heads, num_induce=self.num_induce, use_layernorm=self.use_layernorm, pre_layernorm=self.pre_layernorm, use_keras_mha=self.use_keras_mha)\n",
    "\n",
    "    def call(self, data, mems=None):\n",
    "            attention = self.attention([data, mems])\n",
    "                \n",
    "            return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_compressed_seeds,\n",
    "                 num_induce, \n",
    "                 embed_dim,\n",
    "                 num_heads,\n",
    "                 use_layernorm,\n",
    "                 pre_layernorm,\n",
    "                 use_keras_mha,):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__()\n",
    "        \n",
    "        self.num_compressed_seeds = num_compressed_seeds\n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        self.attention = Attention\n",
    "        \n",
    "        self.compress = Set_Transformer.CompressedPoolingByMultiHeadAttention(\n",
    "            num_seeds=self.num_compressed_seeds,\n",
    "            embed_dim=self.embed_dim,\n",
    "            num_heads=self.num_heads,\n",
    "            use_layernorm=self.use_layernorm,\n",
    "            pre_layernorm=self.pre_layernorm, \n",
    "            use_keras_mha=self.use_keras_mha, \n",
    "            is_final_block=True)\n",
    "        \n",
    "        self.attention_layer = self.attention(self.num_induce, self.embed_dim, self.num_heads, self.use_layernorm, self.pre_layernorm, self.use_keras_mha)\n",
    "    \n",
    "    # def compress(self, x):\n",
    "    #         return 1 + x[:,self.num_compressed_seeds:,:]\n",
    "    \n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             state=None,\n",
    "             compressed=None):\n",
    "        \n",
    "        memories = tf.concat((state, compressed), axis=1)\n",
    "        \n",
    "        attention_output = self.attention_layer(content_stream, memories)\n",
    "\n",
    "        return attention_output       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 mem_switched, \n",
    "                 num_compressed_seeds,\n",
    "                 compressed_len,\n",
    "                 mem_len,\n",
    "                 num_layers,\n",
    "                 num_induce,\n",
    "                 embed_dim,\n",
    "                 num_heads,\n",
    "                 dropout_rate,\n",
    "                 use_layernorm=True,\n",
    "                 pre_layernorm=True, \n",
    "                 use_keras_mha=True):\n",
    "        \n",
    "        super(TransformerXL, self).__init__()\n",
    "\n",
    "        self.mem_switched = mem_switched\n",
    "        self.num_compressed_seeds = num_compressed_seeds\n",
    "        self.compressed_len = compressed_len\n",
    "        self.mem_len = mem_len\n",
    "        self.num_layers = num_layers\n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        self.transformer_xl_layers = []\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(self.num_compressed_seeds,\n",
    "                                        self.num_induce,\n",
    "                                        self.embed_dim,\n",
    "                                        self.num_heads,\n",
    "                                        self.use_layernorm,\n",
    "                                        self.pre_layernorm, \n",
    "                                        self.use_keras_mha))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             state=None,\n",
    "             compressed=None):\n",
    "        \n",
    "        new_mems = []\n",
    "        new_compressed = []\n",
    "\n",
    "        if state is None:\n",
    "            state = [None] * self.num_layers\n",
    "            \n",
    "        if new_compressed is None:\n",
    "            new_compressed = [None] * self.num_layers\n",
    "            \n",
    "        for i, transformer_xl_layer in enumerate(self.transformer_xl_layers):\n",
    "            if self.mem_switched == False:\n",
    "                mems_append, mems_excess = Cache_Memory(content_stream, state[i], self.mem_len)\n",
    "                new_mems.append(mems_append)\n",
    "                \n",
    "                #Perform attention between current segment and uncompressed trimmed memory\n",
    "                #uncompressed_attention = transformer_xl_layer.attention_layer(tf.stop_gradient(content_stream), tf.stop_gradient(mems_excess))\n",
    "                \n",
    "                compressed_mems = transformer_xl_layer.compress(mems_excess)\n",
    "                \n",
    "                compressed_append, _ = Cache_Memory(compressed_mems, compressed[i], self.compressed_len)\n",
    "                new_compressed.append(compressed_append)\n",
    "            \n",
    "                #Perform attention between current segment and compressed trimmed memory\n",
    "                #compressed_attention = transformer_xl_layer.attention_layer( tf.stop_gradient(content_stream), tf.stop_gradient(compressed_mems))\n",
    "                \n",
    "                #loss = tf.linalg.norm(uncompressed_attention-compressed_attention)\n",
    "                \n",
    "            transformer_xl_output = transformer_xl_layer(content_stream=content_stream,\n",
    "                                                        state=state[i], compressed=compressed[i])\n",
    "            \n",
    "            content_stream = self.output_dropout(transformer_xl_output)\n",
    "\n",
    "        loss = 0\n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems, new_compressed, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, mem_switched, num_compressed_seeds, compressed_len, mem_len, max_files, encoder, block_size, max_set_len, num_induce, embed_dim, num_layers, num_heads, dropout_rate, num_seeds_output, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.mem_switched = mem_switched\n",
    "        self.num_compressed_seeds = num_compressed_seeds\n",
    "        self.compressed_len = compressed_len\n",
    "        self.mem_len = mem_len\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.block_size = block_size\n",
    "        self.max_set_len = max_set_len\n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_seeds_output = num_seeds_output\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(self.encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(self.embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(self.mem_switched,\n",
    "                                            self.num_compressed_seeds,\n",
    "                                            self.compressed_len,\n",
    "                                            self.mem_len,\n",
    "                                            self.num_layers,\n",
    "                                             self.num_induce,\n",
    "                                             self.embed_dim,\n",
    "                                             self.num_heads,\n",
    "                                             self.dropout_rate,\n",
    "                                             self.use_layernorm,\n",
    "                                             self.pre_layernorm,\n",
    "                                             self.use_keras_mha)\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=self.num_seeds_output,embed_dim=self.embed_dim,num_heads=self.num_heads,use_layernorm=self.use_layernorm,pre_layernorm=self.pre_layernorm, use_keras_mha=self.use_keras_mha, is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((self.embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, loss_compressed = self(x, return_loss=True, training=True) \n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "            trainable_vars = self.trainable_variables\n",
    "            gradients = tape.gradient(loss+loss_compressed, trainable_vars)\n",
    "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "            self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "            return {m.name: m.result() for m in self.metrics}\n",
    "        \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred, loss_compressed = self(x, return_loss=True, training=False)\n",
    "\n",
    "        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, x, return_loss=False, training=None):  \n",
    "        \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.mem_len, self.embed_dim))\n",
    "        compressed = tf.zeros((self.num_layers, tf.shape(x)[0], self.compressed_len, self.embed_dim))\n",
    "\n",
    "        embeddings = self.embedding_layer(x)\n",
    "\n",
    "        linear_transform = self.linear_layer(embeddings)\n",
    "\n",
    "        losses = 0\n",
    "        \n",
    "        for i in range(0, self.max_set_len, self.block_size):\n",
    "            block = linear_transform[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems, compressed, loss = self.transformer_xl(content_stream=block, state=mems, compressed=compressed)\n",
    "            losses = losses + loss\n",
    "            \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        if return_loss:\n",
    "            return output, losses\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters\n",
    "encoder = pretrained_encoder\n",
    "mem_switched = False\n",
    "num_seeds_compressed = 200\n",
    "compressed_len = 250\n",
    "mem_len = 250\n",
    "num_induce = 0\n",
    "embed_dim = 64\n",
    "num_layers = 4\n",
    "num_heads = 4\n",
    "dropout_rate = 0.01\n",
    "num_seeds_output = 1\n",
    "use_layernorm = True\n",
    "pre_layernorm = True\n",
    "use_keras_mha = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(mem_switched, num_seeds_compressed, compressed_len, mem_len, max_files, encoder, block_size, max_set_len, num_induce, embed_dim, num_layers, num_heads, dropout_rate, num_seeds_output, use_layernorm, pre_layernorm, use_keras_mha)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Adam(1e-3), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a668083e-6a11-4de2-b366-67bdc28f6df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[0.02401159, 0.067814  , 0.8353462 , 0.0686931 , 0.00413507]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7ddcc096-cb9a-4c19-a838-0aa92a6a13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a4e79fc-5cbf-4807-a782-ed7cbe4e4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/attention_output/bias:0', 'dense_250/kernel:0', 'dense_250/bias:0', 'dense_251/kernel:0', 'dense_251/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/attention_output/bias:0', 'dense_254/kernel:0', 'dense_254/bias:0', 'dense_255/kernel:0', 'dense_255/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/attention_output/bias:0', 'dense_258/kernel:0', 'dense_258/bias:0', 'dense_259/kernel:0', 'dense_259/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/attention_output/bias:0', 'dense_262/kernel:0', 'dense_262/bias:0', 'dense_263/kernel:0', 'dense_263/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_44/multi_head_attention_block_58/multi_head_attention_102/attention_output/bias:0', 'dense_250/kernel:0', 'dense_250/bias:0', 'dense_251/kernel:0', 'dense_251/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_45/multi_head_attention_block_59/multi_head_attention_104/attention_output/bias:0', 'dense_254/kernel:0', 'dense_254/bias:0', 'dense_255/kernel:0', 'dense_255/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_46/multi_head_attention_block_60/multi_head_attention_106/attention_output/bias:0', 'dense_258/kernel:0', 'dense_258/bias:0', 'dense_259/kernel:0', 'dense_259/bias:0', 'CSeeds:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/query/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/query/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/key/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/key/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/value/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/value/bias:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/attention_output/kernel:0', 'xl_model_14/transformer_xl_14/compressed_pooling_by_multi_head_attention_47/multi_head_attention_block_61/multi_head_attention_108/attention_output/bias:0', 'dense_262/kernel:0', 'dense_262/bias:0', 'dense_263/kernel:0', 'dense_263/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "20/20 [==============================] - 28s 855ms/step - loss: 2.1033 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.3735 - val_sparse_categorical_accuracy: 0.3500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "638c98d4-0063-45fc-aff3-5e2bae838669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'CSeeds:0' shape=(1, 200, 64) dtype=float32, numpy=\n",
       " array([[[-0.01044076,  0.01633035,  0.03292162, ..., -0.02150482,\n",
       "           0.00901913,  0.0025207 ],\n",
       "         [-0.093173  ,  0.03271655, -0.13451068, ..., -0.07813554,\n",
       "          -0.09983643,  0.0357213 ],\n",
       "         [ 0.01803841, -0.00130155,  0.03728583, ..., -0.11020125,\n",
       "           0.00694254,  0.04405535],\n",
       "         ...,\n",
       "         [-0.04518931, -0.04866203,  0.08861157, ..., -0.0316733 ,\n",
       "           0.00328898, -0.0001425 ],\n",
       "         [-0.04779753,  0.03958122,  0.01364814, ..., -0.03591426,\n",
       "           0.04815786,  0.03601424],\n",
       "         [ 0.00156752, -0.00309683,  0.03725267, ..., -0.10404078,\n",
       "          -0.06174248, -0.00969997]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/query/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[ 0.02207458,  0.01448111, -0.03452677, ..., -0.0108335 ,\n",
       "           0.00944628,  0.01343188],\n",
       "         [-0.02335364,  0.02503648,  0.03241988, ..., -0.01697494,\n",
       "           0.0024481 , -0.00995507],\n",
       "         [ 0.03039048,  0.01176047,  0.00750575, ..., -0.02283678,\n",
       "           0.02267224, -0.02389054],\n",
       "         [-0.03107393,  0.03072756, -0.03337452, ...,  0.02172171,\n",
       "           0.03078821,  0.01803575]],\n",
       " \n",
       "        [[-0.02106436,  0.00838263, -0.02071905, ...,  0.00523179,\n",
       "          -0.00103243,  0.03261093],\n",
       "         [ 0.01874074,  0.0059665 ,  0.01175932, ..., -0.01377134,\n",
       "          -0.00024922,  0.01929849],\n",
       "         [-0.00688791,  0.03086308,  0.02132288, ..., -0.00950566,\n",
       "           0.02724276,  0.02789643],\n",
       "         [-0.00185893,  0.00506021, -0.00082334, ..., -0.0127113 ,\n",
       "          -0.01770746, -0.02311338]],\n",
       " \n",
       "        [[ 0.01333017,  0.02807777,  0.01202692, ...,  0.02908949,\n",
       "          -0.00380303, -0.01892735],\n",
       "         [-0.02427371,  0.0152242 , -0.0094125 , ...,  0.03255933,\n",
       "          -0.025136  ,  0.01022524],\n",
       "         [ 0.02215122, -0.00245833,  0.01764328, ...,  0.00767324,\n",
       "           0.01340705, -0.01136861],\n",
       "         [ 0.01537717,  0.01221552, -0.03252508, ...,  0.02173094,\n",
       "           0.01336693, -0.02556489]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.03366825,  0.03497598,  0.00818441, ...,  0.03420123,\n",
       "          -0.00320233,  0.0186017 ],\n",
       "         [-0.00668734,  0.01013846,  0.01834841, ...,  0.01666666,\n",
       "           0.03573845,  0.02356869],\n",
       "         [ 0.00863723, -0.02676357, -0.02328976, ..., -0.00565112,\n",
       "          -0.00672292,  0.0310699 ],\n",
       "         [-0.02457659, -0.00539597, -0.02162746, ...,  0.00650984,\n",
       "           0.03594203, -0.02200816]],\n",
       " \n",
       "        [[-0.03349531, -0.00297226,  0.01996085, ...,  0.00481527,\n",
       "           0.02250993,  0.01521852],\n",
       "         [ 0.02905287,  0.02249341,  0.0031679 , ..., -0.01784234,\n",
       "          -0.00566772,  0.01751104],\n",
       "         [ 0.02520218, -0.00342753, -0.02988531, ..., -0.02588659,\n",
       "           0.00011503,  0.01771429],\n",
       "         [ 0.02481806,  0.0348317 , -0.01396711, ..., -0.00917214,\n",
       "           0.00551935,  0.00127245]],\n",
       " \n",
       "        [[-0.03484153,  0.02616377,  0.02898033, ..., -0.03569261,\n",
       "          -0.0251845 ,  0.02195231],\n",
       "         [ 0.01416361, -0.03610091,  0.03023985, ..., -0.00851607,\n",
       "           0.02294021,  0.00502614],\n",
       "         [ 0.02268919,  0.02806455, -0.02800383, ..., -0.01174478,\n",
       "          -0.00955728, -0.00831245],\n",
       "         [ 0.0136873 , -0.02917164, -0.026624  , ..., -0.00111335,\n",
       "           0.01199288, -0.02780157]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/query/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/key/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[ 0.03619969, -0.00911468,  0.03593708, ...,  0.02725279,\n",
       "          -0.02797666, -0.03024308],\n",
       "         [-0.03590738,  0.01183157,  0.00609007, ..., -0.00253376,\n",
       "          -0.03147966,  0.01157198],\n",
       "         [-0.03021318, -0.03209245,  0.0361338 , ..., -0.03483813,\n",
       "           0.0163584 , -0.00996686],\n",
       "         [-0.00464742, -0.00913144,  0.01846507, ...,  0.00769907,\n",
       "           0.01259261, -0.005351  ]],\n",
       " \n",
       "        [[-0.03148747, -0.00373708,  0.02092615, ...,  0.03320567,\n",
       "          -0.0169726 ,  0.00409919],\n",
       "         [-0.03673345,  0.00944039, -0.00718848, ...,  0.00511733,\n",
       "           0.0362087 ,  0.0303122 ],\n",
       "         [-0.00304797,  0.00357181, -0.00771674, ...,  0.01780343,\n",
       "          -0.0233374 ,  0.01990769],\n",
       "         [-0.00146872, -0.02718025,  0.01664484, ..., -0.01948188,\n",
       "           0.01414951,  0.01190686]],\n",
       " \n",
       "        [[ 0.02870221,  0.00907259, -0.00135319, ..., -0.03141328,\n",
       "          -0.00546794, -0.02505368],\n",
       "         [-0.03571067, -0.01129725, -0.013658  , ..., -0.00901758,\n",
       "          -0.01795025,  0.02637585],\n",
       "         [-0.00962207,  0.01815076,  0.03093649, ...,  0.02554558,\n",
       "           0.02496567,  0.00106075],\n",
       "         [ 0.0204991 ,  0.00325244,  0.0115804 , ...,  0.0270349 ,\n",
       "          -0.02815037,  0.01451158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.03303732, -0.0269738 , -0.03361825, ...,  0.00296744,\n",
       "           0.0304562 ,  0.01558632],\n",
       "         [-0.00090673,  0.02037589,  0.00253264, ..., -0.00802769,\n",
       "           0.02449966,  0.03222449],\n",
       "         [ 0.0201185 ,  0.03563466,  0.03242581, ...,  0.02516752,\n",
       "          -0.03613095,  0.03521401],\n",
       "         [-0.01970823,  0.00839287,  0.02932501, ...,  0.0047523 ,\n",
       "           0.01512662,  0.00831584]],\n",
       " \n",
       "        [[ 0.02189621,  0.01795306, -0.02348873, ..., -0.0105125 ,\n",
       "          -0.01103125,  0.0103537 ],\n",
       "         [-0.00236858, -0.02033237, -0.01233061, ...,  0.01605781,\n",
       "           0.00167048,  0.02847876],\n",
       "         [ 0.00206023,  0.02250534,  0.02651495, ...,  0.02771329,\n",
       "          -0.02720764,  0.00275249],\n",
       "         [ 0.00791166, -0.02576873,  0.02643619, ..., -0.00710031,\n",
       "          -0.00769291,  0.02895375]],\n",
       " \n",
       "        [[-0.01496287, -0.00849963,  0.00807508, ...,  0.01245134,\n",
       "          -0.03434804,  0.02142233],\n",
       "         [-0.01343394, -0.00427566,  0.01152984, ..., -0.03372471,\n",
       "           0.00682198,  0.0048397 ],\n",
       "         [ 0.00551509, -0.02856486,  0.00482687, ...,  0.03479254,\n",
       "          -0.02274781,  0.0092336 ],\n",
       "         [-0.03412044, -0.0220831 ,  0.00324849, ...,  0.01892729,\n",
       "          -0.02563229, -0.02549852]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/key/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/value/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[-0.00018075,  0.00188976,  0.01702199, ...,  0.0192711 ,\n",
       "           0.028906  ,  0.03155709],\n",
       "         [-0.00657882, -0.01621851,  0.00763042, ..., -0.0135927 ,\n",
       "          -0.02715024,  0.01766981],\n",
       "         [ 0.01804336,  0.02573242, -0.03356554, ...,  0.03128526,\n",
       "          -0.01935627, -0.00618322],\n",
       "         [ 0.0324363 ,  0.02501879, -0.00872916, ...,  0.0215157 ,\n",
       "          -0.02539565,  0.02005767]],\n",
       " \n",
       "        [[-0.03253539, -0.01767308,  0.01045291, ..., -0.0139101 ,\n",
       "          -0.02727056, -0.01860047],\n",
       "         [-0.02487515, -0.02537979,  0.03587393, ...,  0.01814407,\n",
       "           0.01082864, -0.01931637],\n",
       "         [-0.00235273,  0.00039333, -0.03135882, ...,  0.01186352,\n",
       "          -0.00435656,  0.00190688],\n",
       "         [-0.01314765,  0.01267153,  0.00878272, ..., -0.00843541,\n",
       "           0.02444324,  0.03494394]],\n",
       " \n",
       "        [[ 0.0313013 , -0.02759727,  0.01033363, ..., -0.02951526,\n",
       "          -0.03149031, -0.00434472],\n",
       "         [ 0.03405407, -0.01834403, -0.00496166, ..., -0.00820523,\n",
       "           0.03345786, -0.01822674],\n",
       "         [ 0.01297006,  0.03704366,  0.01799688, ..., -0.0132043 ,\n",
       "           0.01309522,  0.02345634],\n",
       "         [-0.00946115,  0.00016332, -0.02813433, ..., -0.03052965,\n",
       "           0.01416154, -0.01417962]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.02833122, -0.0322933 , -0.01071143, ...,  0.02906572,\n",
       "          -0.00818813, -0.02267569],\n",
       "         [ 0.00024475,  0.00134324,  0.0355078 , ..., -0.03292652,\n",
       "          -0.02542412, -0.00416207],\n",
       "         [ 0.02305259, -0.00589187, -0.01447211, ..., -0.02397726,\n",
       "          -0.03322482,  0.02700404],\n",
       "         [ 0.01025049, -0.00484462,  0.02368198, ...,  0.0052524 ,\n",
       "           0.00699623, -0.0281748 ]],\n",
       " \n",
       "        [[-0.01236945, -0.0129004 ,  0.00388971, ...,  0.03444692,\n",
       "          -0.00486479,  0.02689894],\n",
       "         [ 0.00260466, -0.03470677, -0.0332789 , ..., -0.02878104,\n",
       "          -0.0322064 ,  0.0297749 ],\n",
       "         [-0.02572758, -0.03638367, -0.01119723, ...,  0.02912068,\n",
       "           0.01029966,  0.01447295],\n",
       "         [-0.01985734,  0.00865212, -0.00894523, ...,  0.01785208,\n",
       "           0.00888409, -0.02223854]],\n",
       " \n",
       "        [[ 0.03467506, -0.00799326, -0.0355321 , ..., -0.02049105,\n",
       "           0.03535988,  0.00524171],\n",
       "         [-0.00364969,  0.01887507, -0.01963701, ..., -0.01463195,\n",
       "           0.03149493,  0.03124151],\n",
       "         [-0.03331482,  0.00163716, -0.02915826, ..., -0.03176902,\n",
       "           0.02647832,  0.00078658],\n",
       "         [ 0.00500559, -0.00506101,  0.03514583, ...,  0.00292909,\n",
       "          -0.02507483, -0.00852226]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/value/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/attention_output/kernel:0' shape=(4, 64, 64) dtype=float32, numpy=\n",
       " array([[[-0.04367379,  0.04521395,  0.02312883, ..., -0.08130747,\n",
       "          -0.05657705,  0.05126283],\n",
       "         [-0.06248897,  0.04616209,  0.04473575, ...,  0.05172233,\n",
       "           0.10013423, -0.08331755],\n",
       "         [ 0.03442731, -0.02167717,  0.0783182 , ..., -0.07181097,\n",
       "          -0.05711399,  0.09842081],\n",
       "         ...,\n",
       "         [ 0.09496563,  0.03910313,  0.04702645, ...,  0.09788666,\n",
       "          -0.0727343 , -0.01750709],\n",
       "         [ 0.03326639,  0.0970166 ,  0.04350174, ..., -0.09411851,\n",
       "          -0.0586494 ,  0.02393203],\n",
       "         [ 0.00288647,  0.07209767,  0.04921611, ...,  0.0888445 ,\n",
       "          -0.0782074 , -0.07815325]],\n",
       " \n",
       "        [[-0.09050022,  0.06568073,  0.09511184, ..., -0.09870823,\n",
       "          -0.03246787,  0.03068159],\n",
       "         [ 0.06612314, -0.0020929 , -0.00958327, ..., -0.02562562,\n",
       "           0.10567585, -0.02861822],\n",
       "         [ 0.0370901 , -0.04241142, -0.04826751, ..., -0.04295579,\n",
       "           0.03819782, -0.05356507],\n",
       "         ...,\n",
       "         [ 0.07426011, -0.02610441, -0.03151116, ...,  0.10822617,\n",
       "           0.08168163,  0.07163645],\n",
       "         [-0.03481053, -0.04211866, -0.00329676, ..., -0.06315075,\n",
       "           0.01190541,  0.06637219],\n",
       "         [-0.01178911,  0.09250014,  0.01429628, ...,  0.00494323,\n",
       "          -0.08096856, -0.01776367]],\n",
       " \n",
       "        [[ 0.10005089,  0.0046634 , -0.05471179, ..., -0.01837321,\n",
       "          -0.02041106, -0.05399726],\n",
       "         [ 0.10082144, -0.10153659,  0.0179481 , ...,  0.03124852,\n",
       "           0.00941414, -0.08675042],\n",
       "         [ 0.08850764, -0.00971728,  0.10564711, ...,  0.03260335,\n",
       "           0.00595538,  0.01308034],\n",
       "         ...,\n",
       "         [ 0.07965466,  0.02133106, -0.04534318, ..., -0.09083793,\n",
       "           0.06296849,  0.04070825],\n",
       "         [ 0.0482137 ,  0.0792324 , -0.09979866, ...,  0.07037678,\n",
       "           0.00643014, -0.00247601],\n",
       "         [ 0.05065434, -0.01981145,  0.01008088, ...,  0.06684508,\n",
       "           0.04000563,  0.06200496]],\n",
       " \n",
       "        [[ 0.03939012,  0.10788643, -0.06414992, ...,  0.04654048,\n",
       "          -0.00639202, -0.08502968],\n",
       "         [ 0.04022465,  0.00351689, -0.07042827, ..., -0.06559275,\n",
       "          -0.10479069, -0.09153289],\n",
       "         [ 0.05790132,  0.0073644 , -0.0708915 , ...,  0.08520094,\n",
       "           0.03073633,  0.06705902],\n",
       "         ...,\n",
       "         [-0.09676544,  0.07384393,  0.01331317, ...,  0.02510027,\n",
       "           0.09628365,  0.10104015],\n",
       "         [-0.01024516,  0.09475768, -0.05166273, ...,  0.09101971,\n",
       "          -0.08644853, -0.01393562],\n",
       "         [ 0.00933648, -0.00420397,  0.01043912, ...,  0.10304727,\n",
       "          -0.04628197,  0.04742371]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/attention_output/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_210/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[ 0.18426158, -0.0787724 , -0.09857138, ...,  0.05137725,\n",
       "          0.07314701, -0.20266896],\n",
       "        [-0.06405966, -0.16483983,  0.1867397 , ..., -0.057275  ,\n",
       "          0.21520667,  0.02277312],\n",
       "        [-0.12859854,  0.16543274,  0.07635219, ...,  0.05695723,\n",
       "         -0.00557078,  0.17132922],\n",
       "        ...,\n",
       "        [-0.07409716,  0.04983808,  0.17942436, ..., -0.13073528,\n",
       "         -0.1617814 ,  0.00277179],\n",
       "        [-0.05906804, -0.04428643, -0.16085617, ...,  0.02191171,\n",
       "          0.20274635,  0.14980735],\n",
       "        [-0.07441023, -0.20484924,  0.03550111, ..., -0.17140485,\n",
       "          0.02068472,  0.0605668 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_210/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_211/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[-0.19930112,  0.12260135,  0.05048026, ...,  0.07968549,\n",
       "         -0.02123405,  0.05230917],\n",
       "        [-0.13989297,  0.10157014,  0.13411622, ..., -0.01044694,\n",
       "         -0.04705741, -0.00393896],\n",
       "        [ 0.20623656,  0.08730273, -0.05801423, ..., -0.12895215,\n",
       "         -0.19990279, -0.17762403],\n",
       "        ...,\n",
       "        [-0.02720597, -0.16459948, -0.11758798, ..., -0.11289244,\n",
       "          0.20256345,  0.13508706],\n",
       "        [-0.06903218,  0.16259693, -0.08949937, ..., -0.15054882,\n",
       "          0.0769452 ,  0.02325474],\n",
       "        [-0.06954522, -0.01732551,  0.01758143, ...,  0.05479409,\n",
       "         -0.06328727,  0.16079362]], dtype=float32)>,\n",
       " <tf.Variable 'dense_211/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer_xl.transformer_xl_layers[0].compress.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eb968610-4627-4966-841b-d57930b8b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'CSeeds:0' shape=(1, 200, 64) dtype=float32, numpy=\n",
       " array([[[-0.01044076,  0.01633035,  0.03292162, ..., -0.02150482,\n",
       "           0.00901913,  0.0025207 ],\n",
       "         [-0.093173  ,  0.03271655, -0.13451068, ..., -0.07813554,\n",
       "          -0.09983643,  0.0357213 ],\n",
       "         [ 0.01803841, -0.00130155,  0.03728583, ..., -0.11020125,\n",
       "           0.00694254,  0.04405535],\n",
       "         ...,\n",
       "         [-0.04518931, -0.04866203,  0.08861157, ..., -0.0316733 ,\n",
       "           0.00328898, -0.0001425 ],\n",
       "         [-0.04779753,  0.03958122,  0.01364814, ..., -0.03591426,\n",
       "           0.04815786,  0.03601424],\n",
       "         [ 0.00156752, -0.00309683,  0.03725267, ..., -0.10404078,\n",
       "          -0.06174248, -0.00969997]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/query/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[ 0.02207458,  0.01448111, -0.03452677, ..., -0.0108335 ,\n",
       "           0.00944628,  0.01343188],\n",
       "         [-0.02335364,  0.02503648,  0.03241988, ..., -0.01697494,\n",
       "           0.0024481 , -0.00995507],\n",
       "         [ 0.03039048,  0.01176047,  0.00750575, ..., -0.02283678,\n",
       "           0.02267224, -0.02389054],\n",
       "         [-0.03107393,  0.03072756, -0.03337452, ...,  0.02172171,\n",
       "           0.03078821,  0.01803575]],\n",
       " \n",
       "        [[-0.02106436,  0.00838263, -0.02071905, ...,  0.00523179,\n",
       "          -0.00103243,  0.03261093],\n",
       "         [ 0.01874074,  0.0059665 ,  0.01175932, ..., -0.01377134,\n",
       "          -0.00024922,  0.01929849],\n",
       "         [-0.00688791,  0.03086308,  0.02132288, ..., -0.00950566,\n",
       "           0.02724276,  0.02789643],\n",
       "         [-0.00185893,  0.00506021, -0.00082334, ..., -0.0127113 ,\n",
       "          -0.01770746, -0.02311338]],\n",
       " \n",
       "        [[ 0.01333017,  0.02807777,  0.01202692, ...,  0.02908949,\n",
       "          -0.00380303, -0.01892735],\n",
       "         [-0.02427371,  0.0152242 , -0.0094125 , ...,  0.03255933,\n",
       "          -0.025136  ,  0.01022524],\n",
       "         [ 0.02215122, -0.00245833,  0.01764328, ...,  0.00767324,\n",
       "           0.01340705, -0.01136861],\n",
       "         [ 0.01537717,  0.01221552, -0.03252508, ...,  0.02173094,\n",
       "           0.01336693, -0.02556489]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.03366825,  0.03497598,  0.00818441, ...,  0.03420123,\n",
       "          -0.00320233,  0.0186017 ],\n",
       "         [-0.00668734,  0.01013846,  0.01834841, ...,  0.01666666,\n",
       "           0.03573845,  0.02356869],\n",
       "         [ 0.00863723, -0.02676357, -0.02328976, ..., -0.00565112,\n",
       "          -0.00672292,  0.0310699 ],\n",
       "         [-0.02457659, -0.00539597, -0.02162746, ...,  0.00650984,\n",
       "           0.03594203, -0.02200816]],\n",
       " \n",
       "        [[-0.03349531, -0.00297226,  0.01996085, ...,  0.00481527,\n",
       "           0.02250993,  0.01521852],\n",
       "         [ 0.02905287,  0.02249341,  0.0031679 , ..., -0.01784234,\n",
       "          -0.00566772,  0.01751104],\n",
       "         [ 0.02520218, -0.00342753, -0.02988531, ..., -0.02588659,\n",
       "           0.00011503,  0.01771429],\n",
       "         [ 0.02481806,  0.0348317 , -0.01396711, ..., -0.00917214,\n",
       "           0.00551935,  0.00127245]],\n",
       " \n",
       "        [[-0.03484153,  0.02616377,  0.02898033, ..., -0.03569261,\n",
       "          -0.0251845 ,  0.02195231],\n",
       "         [ 0.01416361, -0.03610091,  0.03023985, ..., -0.00851607,\n",
       "           0.02294021,  0.00502614],\n",
       "         [ 0.02268919,  0.02806455, -0.02800383, ..., -0.01174478,\n",
       "          -0.00955728, -0.00831245],\n",
       "         [ 0.0136873 , -0.02917164, -0.026624  , ..., -0.00111335,\n",
       "           0.01199288, -0.02780157]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/query/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/key/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[ 0.03619969, -0.00911468,  0.03593708, ...,  0.02725279,\n",
       "          -0.02797666, -0.03024308],\n",
       "         [-0.03590738,  0.01183157,  0.00609007, ..., -0.00253376,\n",
       "          -0.03147966,  0.01157198],\n",
       "         [-0.03021318, -0.03209245,  0.0361338 , ..., -0.03483813,\n",
       "           0.0163584 , -0.00996686],\n",
       "         [-0.00464742, -0.00913144,  0.01846507, ...,  0.00769907,\n",
       "           0.01259261, -0.005351  ]],\n",
       " \n",
       "        [[-0.03148747, -0.00373708,  0.02092615, ...,  0.03320567,\n",
       "          -0.0169726 ,  0.00409919],\n",
       "         [-0.03673345,  0.00944039, -0.00718848, ...,  0.00511733,\n",
       "           0.0362087 ,  0.0303122 ],\n",
       "         [-0.00304797,  0.00357181, -0.00771674, ...,  0.01780343,\n",
       "          -0.0233374 ,  0.01990769],\n",
       "         [-0.00146872, -0.02718025,  0.01664484, ..., -0.01948188,\n",
       "           0.01414951,  0.01190686]],\n",
       " \n",
       "        [[ 0.02870221,  0.00907259, -0.00135319, ..., -0.03141328,\n",
       "          -0.00546794, -0.02505368],\n",
       "         [-0.03571067, -0.01129725, -0.013658  , ..., -0.00901758,\n",
       "          -0.01795025,  0.02637585],\n",
       "         [-0.00962207,  0.01815076,  0.03093649, ...,  0.02554558,\n",
       "           0.02496567,  0.00106075],\n",
       "         [ 0.0204991 ,  0.00325244,  0.0115804 , ...,  0.0270349 ,\n",
       "          -0.02815037,  0.01451158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.03303732, -0.0269738 , -0.03361825, ...,  0.00296744,\n",
       "           0.0304562 ,  0.01558632],\n",
       "         [-0.00090673,  0.02037589,  0.00253264, ..., -0.00802769,\n",
       "           0.02449966,  0.03222449],\n",
       "         [ 0.0201185 ,  0.03563466,  0.03242581, ...,  0.02516752,\n",
       "          -0.03613095,  0.03521401],\n",
       "         [-0.01970823,  0.00839287,  0.02932501, ...,  0.0047523 ,\n",
       "           0.01512662,  0.00831584]],\n",
       " \n",
       "        [[ 0.02189621,  0.01795306, -0.02348873, ..., -0.0105125 ,\n",
       "          -0.01103125,  0.0103537 ],\n",
       "         [-0.00236858, -0.02033237, -0.01233061, ...,  0.01605781,\n",
       "           0.00167048,  0.02847876],\n",
       "         [ 0.00206023,  0.02250534,  0.02651495, ...,  0.02771329,\n",
       "          -0.02720764,  0.00275249],\n",
       "         [ 0.00791166, -0.02576873,  0.02643619, ..., -0.00710031,\n",
       "          -0.00769291,  0.02895375]],\n",
       " \n",
       "        [[-0.01496287, -0.00849963,  0.00807508, ...,  0.01245134,\n",
       "          -0.03434804,  0.02142233],\n",
       "         [-0.01343394, -0.00427566,  0.01152984, ..., -0.03372471,\n",
       "           0.00682198,  0.0048397 ],\n",
       "         [ 0.00551509, -0.02856486,  0.00482687, ...,  0.03479254,\n",
       "          -0.02274781,  0.0092336 ],\n",
       "         [-0.03412044, -0.0220831 ,  0.00324849, ...,  0.01892729,\n",
       "          -0.02563229, -0.02549852]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/key/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/value/kernel:0' shape=(64, 4, 64) dtype=float32, numpy=\n",
       " array([[[-0.00018075,  0.00188976,  0.01702199, ...,  0.0192711 ,\n",
       "           0.028906  ,  0.03155709],\n",
       "         [-0.00657882, -0.01621851,  0.00763042, ..., -0.0135927 ,\n",
       "          -0.02715024,  0.01766981],\n",
       "         [ 0.01804336,  0.02573242, -0.03356554, ...,  0.03128526,\n",
       "          -0.01935627, -0.00618322],\n",
       "         [ 0.0324363 ,  0.02501879, -0.00872916, ...,  0.0215157 ,\n",
       "          -0.02539565,  0.02005767]],\n",
       " \n",
       "        [[-0.03253539, -0.01767308,  0.01045291, ..., -0.0139101 ,\n",
       "          -0.02727056, -0.01860047],\n",
       "         [-0.02487515, -0.02537979,  0.03587393, ...,  0.01814407,\n",
       "           0.01082864, -0.01931637],\n",
       "         [-0.00235273,  0.00039333, -0.03135882, ...,  0.01186352,\n",
       "          -0.00435656,  0.00190688],\n",
       "         [-0.01314765,  0.01267153,  0.00878272, ..., -0.00843541,\n",
       "           0.02444324,  0.03494394]],\n",
       " \n",
       "        [[ 0.0313013 , -0.02759727,  0.01033363, ..., -0.02951526,\n",
       "          -0.03149031, -0.00434472],\n",
       "         [ 0.03405407, -0.01834403, -0.00496166, ..., -0.00820523,\n",
       "           0.03345786, -0.01822674],\n",
       "         [ 0.01297006,  0.03704366,  0.01799688, ..., -0.0132043 ,\n",
       "           0.01309522,  0.02345634],\n",
       "         [-0.00946115,  0.00016332, -0.02813433, ..., -0.03052965,\n",
       "           0.01416154, -0.01417962]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.02833122, -0.0322933 , -0.01071143, ...,  0.02906572,\n",
       "          -0.00818813, -0.02267569],\n",
       "         [ 0.00024475,  0.00134324,  0.0355078 , ..., -0.03292652,\n",
       "          -0.02542412, -0.00416207],\n",
       "         [ 0.02305259, -0.00589187, -0.01447211, ..., -0.02397726,\n",
       "          -0.03322482,  0.02700404],\n",
       "         [ 0.01025049, -0.00484462,  0.02368198, ...,  0.0052524 ,\n",
       "           0.00699623, -0.0281748 ]],\n",
       " \n",
       "        [[-0.01236945, -0.0129004 ,  0.00388971, ...,  0.03444692,\n",
       "          -0.00486479,  0.02689894],\n",
       "         [ 0.00260466, -0.03470677, -0.0332789 , ..., -0.02878104,\n",
       "          -0.0322064 ,  0.0297749 ],\n",
       "         [-0.02572758, -0.03638367, -0.01119723, ...,  0.02912068,\n",
       "           0.01029966,  0.01447295],\n",
       "         [-0.01985734,  0.00865212, -0.00894523, ...,  0.01785208,\n",
       "           0.00888409, -0.02223854]],\n",
       " \n",
       "        [[ 0.03467506, -0.00799326, -0.0355321 , ..., -0.02049105,\n",
       "           0.03535988,  0.00524171],\n",
       "         [-0.00364969,  0.01887507, -0.01963701, ..., -0.01463195,\n",
       "           0.03149493,  0.03124151],\n",
       "         [-0.03331482,  0.00163716, -0.02915826, ..., -0.03176902,\n",
       "           0.02647832,  0.00078658],\n",
       "         [ 0.00500559, -0.00506101,  0.03514583, ...,  0.00292909,\n",
       "          -0.02507483, -0.00852226]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/value/bias:0' shape=(4, 64) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/attention_output/kernel:0' shape=(4, 64, 64) dtype=float32, numpy=\n",
       " array([[[-0.04367379,  0.04521395,  0.02312883, ..., -0.08130747,\n",
       "          -0.05657705,  0.05126283],\n",
       "         [-0.06248897,  0.04616209,  0.04473575, ...,  0.05172233,\n",
       "           0.10013423, -0.08331755],\n",
       "         [ 0.03442731, -0.02167717,  0.0783182 , ..., -0.07181097,\n",
       "          -0.05711399,  0.09842081],\n",
       "         ...,\n",
       "         [ 0.09496563,  0.03910313,  0.04702645, ...,  0.09788666,\n",
       "          -0.0727343 , -0.01750709],\n",
       "         [ 0.03326639,  0.0970166 ,  0.04350174, ..., -0.09411851,\n",
       "          -0.0586494 ,  0.02393203],\n",
       "         [ 0.00288647,  0.07209767,  0.04921611, ...,  0.0888445 ,\n",
       "          -0.0782074 , -0.07815325]],\n",
       " \n",
       "        [[-0.09050022,  0.06568073,  0.09511184, ..., -0.09870823,\n",
       "          -0.03246787,  0.03068159],\n",
       "         [ 0.06612314, -0.0020929 , -0.00958327, ..., -0.02562562,\n",
       "           0.10567585, -0.02861822],\n",
       "         [ 0.0370901 , -0.04241142, -0.04826751, ..., -0.04295579,\n",
       "           0.03819782, -0.05356507],\n",
       "         ...,\n",
       "         [ 0.07426011, -0.02610441, -0.03151116, ...,  0.10822617,\n",
       "           0.08168163,  0.07163645],\n",
       "         [-0.03481053, -0.04211866, -0.00329676, ..., -0.06315075,\n",
       "           0.01190541,  0.06637219],\n",
       "         [-0.01178911,  0.09250014,  0.01429628, ...,  0.00494323,\n",
       "          -0.08096856, -0.01776367]],\n",
       " \n",
       "        [[ 0.10005089,  0.0046634 , -0.05471179, ..., -0.01837321,\n",
       "          -0.02041106, -0.05399726],\n",
       "         [ 0.10082144, -0.10153659,  0.0179481 , ...,  0.03124852,\n",
       "           0.00941414, -0.08675042],\n",
       "         [ 0.08850764, -0.00971728,  0.10564711, ...,  0.03260335,\n",
       "           0.00595538,  0.01308034],\n",
       "         ...,\n",
       "         [ 0.07965466,  0.02133106, -0.04534318, ..., -0.09083793,\n",
       "           0.06296849,  0.04070825],\n",
       "         [ 0.0482137 ,  0.0792324 , -0.09979866, ...,  0.07037678,\n",
       "           0.00643014, -0.00247601],\n",
       "         [ 0.05065434, -0.01981145,  0.01008088, ...,  0.06684508,\n",
       "           0.04000563,  0.06200496]],\n",
       " \n",
       "        [[ 0.03939012,  0.10788643, -0.06414992, ...,  0.04654048,\n",
       "          -0.00639202, -0.08502968],\n",
       "         [ 0.04022465,  0.00351689, -0.07042827, ..., -0.06559275,\n",
       "          -0.10479069, -0.09153289],\n",
       "         [ 0.05790132,  0.0073644 , -0.0708915 , ...,  0.08520094,\n",
       "           0.03073633,  0.06705902],\n",
       "         ...,\n",
       "         [-0.09676544,  0.07384393,  0.01331317, ...,  0.02510027,\n",
       "           0.09628365,  0.10104015],\n",
       "         [-0.01024516,  0.09475768, -0.05166273, ...,  0.09101971,\n",
       "          -0.08644853, -0.01393562],\n",
       "         [ 0.00933648, -0.00420397,  0.01043912, ...,  0.10304727,\n",
       "          -0.04628197,  0.04742371]]], dtype=float32)>,\n",
       " <tf.Variable 'xl_model_12/transformer_xl_12/compressed_pooling_by_multi_head_attention_36/multi_head_attention_block_48/multi_head_attention_84/attention_output/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_210/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[ 0.18426158, -0.0787724 , -0.09857138, ...,  0.05137725,\n",
       "          0.07314701, -0.20266896],\n",
       "        [-0.06405966, -0.16483983,  0.1867397 , ..., -0.057275  ,\n",
       "          0.21520667,  0.02277312],\n",
       "        [-0.12859854,  0.16543274,  0.07635219, ...,  0.05695723,\n",
       "         -0.00557078,  0.17132922],\n",
       "        ...,\n",
       "        [-0.07409716,  0.04983808,  0.17942436, ..., -0.13073528,\n",
       "         -0.1617814 ,  0.00277179],\n",
       "        [-0.05906804, -0.04428643, -0.16085617, ...,  0.02191171,\n",
       "          0.20274635,  0.14980735],\n",
       "        [-0.07441023, -0.20484924,  0.03550111, ..., -0.17140485,\n",
       "          0.02068472,  0.0605668 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_210/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_211/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[-0.19930112,  0.12260135,  0.05048026, ...,  0.07968549,\n",
       "         -0.02123405,  0.05230917],\n",
       "        [-0.13989297,  0.10157014,  0.13411622, ..., -0.01044694,\n",
       "         -0.04705741, -0.00393896],\n",
       "        [ 0.20623656,  0.08730273, -0.05801423, ..., -0.12895215,\n",
       "         -0.19990279, -0.17762403],\n",
       "        ...,\n",
       "        [-0.02720597, -0.16459948, -0.11758798, ..., -0.11289244,\n",
       "          0.20256345,  0.13508706],\n",
       "        [-0.06903218,  0.16259693, -0.08949937, ..., -0.15054882,\n",
       "          0.0769452 ,  0.02325474],\n",
       "        [-0.06954522, -0.01732551,  0.01758143, ...,  0.05479409,\n",
       "         -0.06328727,  0.16079362]], dtype=float32)>,\n",
       " <tf.Variable 'dense_211/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer_xl.transformer_xl_layers[0].compress.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e9cbcec-11b3-4a6b-b025-dc1f62580686",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:161\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    158\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 161\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py:156\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 156\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    159\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"Test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee28d57-69c3-428f-8ac0-c5720ceaa463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

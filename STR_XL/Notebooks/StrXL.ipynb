{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../deep-learning-dna\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../../deep-learning-dna/common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b9c98a-b4ee-4667-89a3-5f04549f7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "\n",
    "from Attention import Set_Transformer\n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utilities as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7fa128173c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-64dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   420 of 420 files downloaded.  \n",
      "Done. 0:0:13.8\n"
     ]
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/nachusa-dna:latest\").download()\n",
    "samples = find_dbs(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b3cf28-0fc9-4c02-b24a-2ccc835f3695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:5], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len, kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32beae78-68b4-4e2b-8bd3-255c5db084d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14112544059753418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_dataset[0][0]\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 200\n",
    "max_set_len = set_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > set_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(max_set_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        result = tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "        return result\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cache_Memory(current_state, previous_state, memory_length):\n",
    "    \n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50453f-628c-412e-942b-d486d01c6b8a",
   "metadata": {},
   "source": [
    "---\n",
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf9ef79-9ede-4271-8542-223cdd1e11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(keras.Model):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        if self.num_induce == 0:       \n",
    "            self.attention = (Set_Transformer.SetAttentionBlock(embed_dim=self.embed_dim, num_heads=self.num_heads, use_layernorm=self.use_layernorm,pre_layernorm=self.pre_layernorm,use_keras_mha=self.use_keras_mha))\n",
    "        else:\n",
    "            self.attention = Set_Transformer.InducedSetAttentionBlock(embed_dim=self.embed_dim, num_heads=self.num_heads, num_induce=self.num_induce, use_layernorm=self.use_layernorm, pre_layernorm=self.pre_layernorm, use_keras_mha=self.use_keras_mha)\n",
    "    \n",
    "    \n",
    "    def call(self, data, mems):\n",
    "                \n",
    "            attention = self.attention([data, mems])\n",
    "                \n",
    "            return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_induce, \n",
    "                 embed_dim,\n",
    "                 num_heads,\n",
    "                 use_layernorm,\n",
    "                 pre_layernorm,\n",
    "                 use_keras_mha,):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__()\n",
    "        \n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        self.attention = Attention\n",
    "        \n",
    "        self.attention_layer = self.attention(self.num_induce, self.embed_dim, self.num_heads, self.use_layernorm, self.pre_layernorm, self.use_keras_mha)\n",
    "\n",
    "   \n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             state=None):\n",
    "        \n",
    "        attention_output = self.attention_layer(content_stream, state)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 mem_switched, \n",
    "                 num_layers,\n",
    "                 num_induce,\n",
    "                 embed_dim,\n",
    "                 num_heads,\n",
    "                 dropout_rate,\n",
    "                 mem_len=None,\n",
    "                 use_layernorm=True,\n",
    "                 pre_layernorm=True, \n",
    "                 use_keras_mha=True):\n",
    "        \n",
    "        super(TransformerXL, self).__init__()\n",
    "\n",
    "        self.mem_switched = mem_switched\n",
    "        self.num_layers = num_layers\n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mem_len = mem_len\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(self.num_induce,\n",
    "                                        self.embed_dim,\n",
    "                                        self.num_heads,\n",
    "                                        self.use_layernorm,\n",
    "                                        self.pre_layernorm, \n",
    "                                        self.use_keras_mha))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             state=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        if state is None:\n",
    "            state = [None] * self.num_layers\n",
    "            \n",
    "        for i in range(self.num_layers):\n",
    "            if self.mem_switched == False:\n",
    "                new_mems.append(Cache_Memory(content_stream, state[i], self.mem_len))\n",
    "            \n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(content_stream=content_stream,\n",
    "                                                        state=state[i])\n",
    "            \n",
    "            content_stream = self.output_dropout(transformer_xl_output)\n",
    "            \n",
    "            if self.mem_switched == True:\n",
    "                new_mems.append(Cache_Memory(content_stream, state[i], self.mem_len))\n",
    "\n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, mem_switched, max_files, encoder, block_size, max_set_len, num_induce, embed_dim, num_layers, num_heads, mem_len, dropout_rate, num_seeds, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.mem_switched = mem_switched\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.block_size = block_size\n",
    "        self.max_set_len = max_set_len\n",
    "        self.num_induce = num_induce\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.mem_len = mem_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_seeds = num_seeds\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.pre_layernorm = pre_layernorm\n",
    "        self.use_keras_mha = use_keras_mha\n",
    "        \n",
    "        self.embedding_layer = keras.layers.TimeDistributed(self.encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(self.embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(self.mem_switched,\n",
    "                                            self.num_layers,\n",
    "                                             self.num_induce,\n",
    "                                             self.embed_dim,\n",
    "                                             self.num_heads,\n",
    "                                             self.dropout_rate,\n",
    "                                             self.mem_len,\n",
    "                                             self.use_layernorm,\n",
    "                                             self.pre_layernorm,\n",
    "                                             self.use_keras_mha)\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=self.num_seeds,embed_dim=self.embed_dim,num_heads=self.num_heads,use_layernorm=self.use_layernorm,pre_layernorm=self.pre_layernorm, use_keras_mha=self.use_keras_mha, is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((self.embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    " \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.mem_len, self.embed_dim))\n",
    "    \n",
    "        # embeddings = self.embedding_layer(x)\n",
    "        embeddings = x\n",
    "        linear_transform = self.linear_layer(embeddings)\n",
    "\n",
    "        for i in range(0, self.max_set_len, self.block_size):\n",
    "            block = linear_transform[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems = self.transformer_xl(content_stream=block, state=mems)\n",
    "        \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters\n",
    "encoder = pretrained_encoder\n",
    "mem_switched = False\n",
    "num_induce = 10\n",
    "embed_dim = 64\n",
    "num_layers = 4\n",
    "num_heads = 4\n",
    "mem_len = 200\n",
    "dropout_rate = 0.01\n",
    "num_seeds = 1\n",
    "use_layernorm = True\n",
    "pre_layernorm = True\n",
    "use_keras_mha = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(mem_switched, max_files, encoder, block_size, max_set_len, num_induce, embed_dim, num_layers, num_heads, mem_len, dropout_rate, num_seeds, use_layernorm, pre_layernorm, use_keras_mha)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Adam(1e-3), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ce0932b-5077-4562-90e1-fb1749e32939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_with_class_token/embedding/embeddings:0': 2,\n",
       " 'dense/kernel:0': 2,\n",
       " 'dense/bias:0': 2,\n",
       " 'dense_1/kernel:0': 2,\n",
       " 'dense_1/bias:0': 2,\n",
       " 'relative_transformer_block/layer_normalization/gamma:0': 2,\n",
       " 'relative_transformer_block/layer_normalization/beta:0': 2,\n",
       " 'relative_transformer_block/layer_normalization_1/gamma:0': 2,\n",
       " 'relative_transformer_block/layer_normalization_1/beta:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/query/kernel:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/query/bias:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/key/kernel:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/key/bias:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/value/kernel:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/value/bias:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block/relative_multi_head_attention/attention_output/bias:0': 2,\n",
       " 'dense_2/kernel:0': 2,\n",
       " 'dense_2/bias:0': 2,\n",
       " 'dense_3/kernel:0': 2,\n",
       " 'dense_3/bias:0': 2,\n",
       " 'relative_transformer_block_1/layer_normalization_2/gamma:0': 2,\n",
       " 'relative_transformer_block_1/layer_normalization_2/beta:0': 2,\n",
       " 'relative_transformer_block_1/layer_normalization_3/gamma:0': 2,\n",
       " 'relative_transformer_block_1/layer_normalization_3/beta:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/query/kernel:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/query/bias:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/key/kernel:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/key/bias:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/value/kernel:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/value/bias:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block_1/relative_multi_head_attention_1/attention_output/bias:0': 2,\n",
       " 'dense_4/kernel:0': 2,\n",
       " 'dense_4/bias:0': 2,\n",
       " 'dense_5/kernel:0': 2,\n",
       " 'dense_5/bias:0': 2,\n",
       " 'relative_transformer_block_2/layer_normalization_4/gamma:0': 2,\n",
       " 'relative_transformer_block_2/layer_normalization_4/beta:0': 2,\n",
       " 'relative_transformer_block_2/layer_normalization_5/gamma:0': 2,\n",
       " 'relative_transformer_block_2/layer_normalization_5/beta:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/query/kernel:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/query/bias:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/key/kernel:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/key/bias:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/value/kernel:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/value/bias:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block_2/relative_multi_head_attention_2/attention_output/bias:0': 2,\n",
       " 'dense_6/kernel:0': 2,\n",
       " 'dense_6/bias:0': 2,\n",
       " 'dense_7/kernel:0': 2,\n",
       " 'dense_7/bias:0': 2,\n",
       " 'relative_transformer_block_3/layer_normalization_6/gamma:0': 2,\n",
       " 'relative_transformer_block_3/layer_normalization_6/beta:0': 2,\n",
       " 'relative_transformer_block_3/layer_normalization_7/gamma:0': 2,\n",
       " 'relative_transformer_block_3/layer_normalization_7/beta:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/query/kernel:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/query/bias:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/key/kernel:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/key/bias:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/value/kernel:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/value/bias:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block_3/relative_multi_head_attention_3/attention_output/bias:0': 2,\n",
       " 'dense_8/kernel:0': 2,\n",
       " 'dense_8/bias:0': 2,\n",
       " 'dense_9/kernel:0': 2,\n",
       " 'dense_9/bias:0': 2,\n",
       " 'relative_transformer_block_4/layer_normalization_8/gamma:0': 2,\n",
       " 'relative_transformer_block_4/layer_normalization_8/beta:0': 2,\n",
       " 'relative_transformer_block_4/layer_normalization_9/gamma:0': 2,\n",
       " 'relative_transformer_block_4/layer_normalization_9/beta:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/query/kernel:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/query/bias:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/key/kernel:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/key/bias:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/value/kernel:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/value/bias:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block_4/relative_multi_head_attention_4/attention_output/bias:0': 2,\n",
       " 'dense_10/kernel:0': 2,\n",
       " 'dense_10/bias:0': 2,\n",
       " 'dense_11/kernel:0': 2,\n",
       " 'dense_11/bias:0': 2,\n",
       " 'relative_transformer_block_5/layer_normalization_10/gamma:0': 2,\n",
       " 'relative_transformer_block_5/layer_normalization_10/beta:0': 2,\n",
       " 'relative_transformer_block_5/layer_normalization_11/gamma:0': 2,\n",
       " 'relative_transformer_block_5/layer_normalization_11/beta:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/query/kernel:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/query/bias:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/key/kernel:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/key/bias:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/value/kernel:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/value/bias:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/attention_output/kernel:0': 2,\n",
       " 'relative_transformer_block_5/relative_multi_head_attention_5/attention_output/bias:0': 2,\n",
       " 'dense_12/kernel:0': 2,\n",
       " 'dense_12/bias:0': 2,\n",
       " 'dense_13/kernel:0': 2,\n",
       " 'dense_13/bias:0': 2,\n",
       " 'relative_transformer_block_6/layer_normalization_12/gamma:0': 2,\n",
       " 'relative_transformer_block_6/layer_normalization_12/beta:0': 2,\n",
       " 'relative_transformer_block_6/layer_normalization_13/gamma:0': 2,\n",
       " 'relative_transformer_block_6/layer_normalization_13/beta:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/relative_embeddings:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/query/kernel:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/query/bias:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/key/kernel:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/key/bias:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/value/kernel:0': 2,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/value/bias:0': 1,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/attention_output/kernel:0': 1,\n",
       " 'relative_transformer_block_6/relative_multi_head_attention_6/attention_output/bias:0': 1,\n",
       " 'dense_14/kernel:0': 1,\n",
       " 'dense_14/bias:0': 1,\n",
       " 'dense_15/kernel:0': 1,\n",
       " 'dense_15/bias:0': 1,\n",
       " 'relative_transformer_block_7/layer_normalization_14/gamma:0': 1,\n",
       " 'relative_transformer_block_7/layer_normalization_14/beta:0': 1,\n",
       " 'relative_transformer_block_7/layer_normalization_15/gamma:0': 1,\n",
       " 'relative_transformer_block_7/layer_normalization_15/beta:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/relative_embeddings:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/query/kernel:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/query/bias:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/key/kernel:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/key/bias:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/value/kernel:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/value/bias:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/attention_output/kernel:0': 1,\n",
       " 'relative_transformer_block_7/relative_multi_head_attention_7/attention_output/bias:0': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_dataset[0][0])\n",
    "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
    "weights = model.get_weights()\n",
    "\n",
    "name_counts = {}\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    if name not in name_counts:\n",
    "        name_counts[name] = 0\n",
    "    name_counts[name] += 1\n",
    "name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "908df1af-de17-477b-8677-993e9b9f2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"save.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ddcc096-cb9a-4c19-a838-0aa92a6a13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf130da-8b95-403f-8161-3ee8fcb49e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14f63abf-74f0-41ec-99d1-e20c0e79a342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.132155179977417"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_dataset[0][0]\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c02cd50a-66e7-4049-b226-cd2737a5a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727.5390625"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20000*149*64*4/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f31b35a-abdf-4a8e-896c-b35b7e8cb977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 5s 258ms/step\n"
     ]
    }
   ],
   "source": [
    "inputs = encoder.predict(tf.reshape(train_dataset[0][0], (-1, 148)), batch_size=1000).reshape((20, 1000, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "892cb747-6b29-4812-b55f-7bdb3c422bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2700774669647217"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "model(inputs)\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afca68c-b383-4f9a-8a6b-7b1109a20d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xl_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dna_bert_encoder_model (Dna  multiple                 683968    \n",
      " BertEncoderModel)                                               \n",
      "                                                                 \n",
      " create__embeddings (Create_  multiple                 683968    \n",
      " Embeddings)                                                     \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  4160      \n",
      "                                                                 \n",
      " transformer_xl (Transformer  multiple                 600064    \n",
      " XL)                                                             \n",
      "                                                                 \n",
      " pooling_by_multi_head_atten  multiple                 74752     \n",
      " tion (PoolingByMultiHeadAtt                                     \n",
      " ention)                                                         \n",
      "                                                                 \n",
      " reshape (Reshape)           multiple                  0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            multiple                  260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,363,204\n",
      "Trainable params: 679,236\n",
      "Non-trainable params: 683,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a4e79fc-5cbf-4807-a782-ed7cbe4e4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435adf74-c8b0-490d-a52b-171360d0a396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

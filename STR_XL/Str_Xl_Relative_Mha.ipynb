{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccea5cd-89de-452b-afa6-703df9e9a604",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7f7df1d5f9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/deep-learning-dna/dnabert-pretrain-ablation-dim:8dim\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples:v1, 4086.55MB. 1260 files... Done. 0:6:5.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples:v1\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20, 5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len,kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0a881-4dc6-4916-a18c-8c59e026e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 200\n",
    "seq_len = set_len\n",
    "maxlen = set_len\n",
    "vocab_size = 5\n",
    "num_chars_data = set_len*sequence_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > seq_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxlen)\n",
    "print(vocab_size)\n",
    "print(num_chars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b66c98-f8b5-4b80-9736-66a9769cc966",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af4ac04-1eab-4d74-bfc0-716408efeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_initializer(initializer):\n",
    "    if isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer.__class__.from_config(initializer.get_config())\n",
    "    return initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if reuse_length > 0:\n",
    "            current_state = current_state[:, :reuse_length, :]\n",
    "\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3126b9-a96e-4d6a-ae65-3c9579514cf1",
   "metadata": {},
   "source": [
    "---\n",
    "# MultiHead Relative Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b32faad-fd06-4448-b817-b3a1f5943aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadRelativeAttention(tf.keras.layers.MultiHeadAttention):\n",
    "    def __init__(self,\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 **kwargs):\n",
    "        super().__init__(kernel_initializer=kernel_initializer,\n",
    "                                         **kwargs)\n",
    "\n",
    "    def _build_from_signature(self, query, value, key=None):\n",
    "        super(MultiHeadRelativeAttention, self)._build_from_signature(\n",
    "                query=query,\n",
    "                value=value,\n",
    "                key=key)\n",
    "        if hasattr(value, \"shape\"):\n",
    "            value_shape = tf.TensorShape(value.shape)\n",
    "        else:\n",
    "            value_shape = value\n",
    "        if key is None:\n",
    "            key_shape = value_shape\n",
    "        elif hasattr(key, \"shape\"):\n",
    "            key_shape = tf.TensorShape(key.shape)\n",
    "        else:\n",
    "            key_shape = key\n",
    "\n",
    "        common_kwargs = dict(\n",
    "                kernel_initializer=self._kernel_initializer,\n",
    "                bias_initializer=self._bias_initializer,\n",
    "                kernel_regularizer=self._kernel_regularizer,\n",
    "                bias_regularizer=self._bias_regularizer,\n",
    "                activity_regularizer=self._activity_regularizer,\n",
    "                kernel_constraint=self._kernel_constraint,\n",
    "                bias_constraint=self._bias_constraint)\n",
    "\n",
    "        with tf.init_scope():\n",
    "            einsum_equation, _, output_rank = _build_proj_equation(\n",
    "                    key_shape.rank - 1, bound_dims=1, output_dims=2)\n",
    "            self._encoding_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                    einsum_equation,\n",
    "                    output_shape=_get_output_shape(\n",
    "                        output_rank - 1,\n",
    "                        [self._num_heads, self._key_dim]),\n",
    "                        bias_axes=None,\n",
    "                        name=\"encoding\",\n",
    "                        **common_kwargs)\n",
    "\n",
    "    def compute_attention(\n",
    "        self,\n",
    "        query,\n",
    "        key,\n",
    "        value,\n",
    "        position,\n",
    "        content_attention_bias,\n",
    "        positional_attention_bias,\n",
    "        attention_mask=None\n",
    "    ):\n",
    "        attention_mask = None\n",
    "        \n",
    "        #AC\n",
    "        content_attention = tf.einsum(self._dot_product_equation, key, query + content_attention_bias)\n",
    "        \n",
    "        attention_sum = content_attention\n",
    "\n",
    "        attention_scores = tf.multiply(attention_sum, 1.0 / math.sqrt(float(self._key_dim)))\n",
    "\n",
    "        attention_scores = self._masked_softmax(attention_scores, attention_mask)\n",
    "\n",
    "        attention_output = self._dropout_layer(attention_scores)\n",
    "\n",
    "        attention_output = tf.einsum(self._combine_equation, attention_output, value)\n",
    "        \n",
    "        return attention_output\n",
    "\n",
    "    def call(self,\n",
    "             query,\n",
    "             value,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             key=None,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             attention_mask=None):\n",
    "        \n",
    "        attention_mask = None\n",
    "        \n",
    "        \n",
    "        if not self._built_from_signature:\n",
    "            self._build_from_signature(query, value, key=key)\n",
    "        if key is None:\n",
    "            key = value\n",
    "        if state is not None and state.shape.ndims > 1:\n",
    "            value = tf.concat([state, value], 1)\n",
    "            key = tf.concat([state, key], 1)\n",
    "\n",
    "        query = self._query_dense(query)\n",
    "\n",
    "        key = self._key_dense(key)\n",
    "\n",
    "        value = self._value_dense(value)\n",
    "        position = None\n",
    "        \n",
    "        attention_output = self.compute_attention(\n",
    "                query=query,\n",
    "                key=key,\n",
    "                value=value,\n",
    "                position=position,\n",
    "                content_attention_bias=content_attention_bias,\n",
    "                positional_attention_bias=positional_attention_bias,\n",
    "                attention_mask=attention_mask)\n",
    "\n",
    "        attention_output = self._output_dense(attention_output)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a026fd-2cbe-45b7-88f7-a3ffd3548806",
   "metadata": {},
   "source": [
    "---\n",
    "# Build Einsum Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5102422c-82af-49d4-a8d5-5081262b21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHR_IDX = string.ascii_lowercase\n",
    "\n",
    "def _build_proj_equation(free_dims, bound_dims, output_dims):\n",
    "    input_str = \"\"\n",
    "    kernel_str = \"\"\n",
    "    output_str = \"\"\n",
    "    bias_axes = \"\"\n",
    "    letter_offset = 0\n",
    "    for i in range(free_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        input_str += char\n",
    "        output_str += char\n",
    "\n",
    "    letter_offset += free_dims\n",
    "    for i in range(bound_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        input_str += char\n",
    "        kernel_str += char\n",
    "\n",
    "    letter_offset += bound_dims\n",
    "    for i in range(output_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        kernel_str += char\n",
    "        output_str += char\n",
    "        bias_axes += char\n",
    "    equation = \"%s,%s->%s\" % (input_str, kernel_str, output_str)\n",
    "\n",
    "    return equation, bias_axes, len(output_str)\n",
    "\n",
    "\n",
    "def _get_output_shape(output_rank, known_last_dims):\n",
    "    return [None] * (output_rank - len(known_last_dims)) + list(known_last_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 hidden_size,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 norm_epsilon=1e-12,\n",
    "                 inner_activation=\"relu\",\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 inner_dropout=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__(**kwargs)\n",
    "        self._vocab_size = vocab_size\n",
    "        self._num_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._inner_size = inner_size\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._inner_activation = inner_activation\n",
    "        self._norm_epsilon = norm_epsilon\n",
    "        self._kernel_initializer = kernel_initializer\n",
    "        self._inner_dropout = inner_dropout\n",
    "        self._attention_layer_type = MultiHeadRelativeAttention\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape\n",
    "        input_tensor_shape = tf.TensorShape(input_tensor)\n",
    "        if len(input_tensor_shape.as_list()) != 3:\n",
    "            raise ValueError(\"TransformerLayer expects a three-dimensional input of \"\n",
    "                                             \"shape [batch, sequence, width].\")\n",
    "        batch_size, sequence_length, hidden_size = input_tensor_shape\n",
    "\n",
    "        if hidden_size % self._num_heads != 0:\n",
    "            raise ValueError(\n",
    "                    \"The input size (%d) is not a multiple of the number of attention \"\n",
    "                    \"heads (%d)\" % (hidden_size, self._num_heads))\n",
    "            \n",
    "\n",
    "        self._attention_layer = self._attention_layer_type(\n",
    "                num_heads=self._num_heads,\n",
    "                key_dim=self._head_size,\n",
    "                value_dim=self._head_size,\n",
    "                dropout=self._attention_dropout_rate,\n",
    "                use_bias=False,\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer),\n",
    "                name=\"rel_attn\")\n",
    "        \n",
    "        self._attention_dropout = tf.keras.layers.Dropout(\n",
    "                rate=self._attention_dropout_rate)\n",
    "        self._attention_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"self_attention_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon,\n",
    "                dtype=tf.float32)\n",
    "        self._inner_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, self._inner_size),\n",
    "                bias_axes=\"d\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer),\n",
    "                name=\"inner\")\n",
    "\n",
    "        self._inner_activation_layer = tf.keras.layers.Activation(\n",
    "                self._inner_activation)\n",
    "        self._inner_dropout_layer = tf.keras.layers.Dropout(\n",
    "                rate=self._inner_dropout)\n",
    "        self._output_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, hidden_size),\n",
    "                bias_axes=\"d\",\n",
    "                name=\"output\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer))\n",
    "        self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "        self._output_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"output_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon)\n",
    "\n",
    "        super(TransformerXLBlock, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        attention_kwargs = dict(\n",
    "                query=content_stream,\n",
    "                value=content_stream,\n",
    "                key=content_stream,\n",
    "                attention_mask=content_attention_mask)\n",
    "\n",
    "        common_attention_kwargs = dict(\n",
    "                content_attention_bias=content_attention_bias,\n",
    "                relative_position_encoding=relative_position_encoding,\n",
    "                positional_attention_bias=positional_attention_bias,\n",
    "                state=state)\n",
    "\n",
    "        attention_kwargs.update(common_attention_kwargs)\n",
    "        attention_output = self._attention_layer(**attention_kwargs)\n",
    "        \n",
    "        attention_stream = attention_output\n",
    "        input_stream = content_stream\n",
    "        attention_key = \"content_attention\"\n",
    "        attention_output = {}\n",
    "        \n",
    "        attention_stream = self._attention_dropout(attention_stream)\n",
    "        attention_stream = self._attention_layer_norm(attention_stream + input_stream)\n",
    "        inner_output = self._inner_dense(attention_stream)\n",
    "        inner_output = self._inner_activation_layer(\n",
    "                inner_output)\n",
    "        inner_output = self._inner_dropout_layer(\n",
    "                inner_output)\n",
    "        layer_output = self._output_dense(inner_output)\n",
    "        layer_output = self._output_dropout(layer_output)\n",
    "        layer_output = self._output_layer_norm(layer_output + attention_stream)\n",
    "        attention_output[attention_key] = layer_output\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 hidden_size,\n",
    "                 maxlen,\n",
    "                 embed_dim,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 initializer,\n",
    "                 tie_attention_biases=True,\n",
    "                 memory_length=None,\n",
    "                 reuse_length=None,\n",
    "                 inner_activation=\"relu\",\n",
    "                 **kwargs):\n",
    "        super(TransformerXL, self).__init__(**kwargs)\n",
    "\n",
    "        self._vocab_size = vocab_size\n",
    "        self._initializer = initializer\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._num_attention_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._inner_size = inner_size\n",
    "        self._inner_activation = inner_activation\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._tie_attention_biases = tie_attention_biases\n",
    "\n",
    "        self._memory_length = memory_length\n",
    "        self._reuse_length = reuse_length\n",
    "\n",
    "        if self._tie_attention_biases:\n",
    "            attention_bias_shape = [self._num_attention_heads, self._head_size]\n",
    "        else:\n",
    "            attention_bias_shape = [self._num_layers, self._num_attention_heads, self._head_size]\n",
    "\n",
    "        self.content_attention_bias = self.add_weight(\n",
    "                \"content_attention_bias\",\n",
    "                shape=attention_bias_shape,\n",
    "                dtype=tf.float32,\n",
    "                initializer=clone_initializer(self._initializer))\n",
    "        self.positional_attention_bias = self.add_weight(\n",
    "                \"positional_attention_bias\",\n",
    "                shape=attention_bias_shape,\n",
    "                dtype=tf.float32,\n",
    "                initializer=clone_initializer(self._initializer))\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        for i in range(self._num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(\n",
    "                            vocab_size=self._vocab_size,\n",
    "                            hidden_size=self._head_size * self._num_attention_heads,\n",
    "                            num_attention_heads=self._num_attention_heads,\n",
    "                            head_size=self._head_size,\n",
    "                            inner_size=self._inner_size,\n",
    "                            dropout_rate=self._dropout_rate,\n",
    "                            attention_dropout_rate=self._attention_dropout_rate,\n",
    "                            norm_epsilon=1e-12,\n",
    "                            inner_activation=self._inner_activation,\n",
    "                            kernel_initializer=\"variance_scaling\",\n",
    "                            name=\"layer_%d\" % i))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             relative_position_encoding,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        content_attention_mask = None\n",
    "        query_attention_mask = None\n",
    "        \n",
    "        if state is None:\n",
    "            state = [None] * self._num_layers\n",
    "        for i in range(self._num_layers):\n",
    "            # cache new mems\n",
    "            new_mems.append( _cache_memory(content_stream, state[i], self._memory_length, self._reuse_length))\n",
    "\n",
    "            if self._tie_attention_biases:\n",
    "                content_attention_bias = self.content_attention_bias\n",
    "            else:\n",
    "                content_attention_bias = self.content_attention_bias[i]\n",
    "\n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(\n",
    "                    content_stream=content_stream,\n",
    "                    content_attention_bias=content_attention_bias,\n",
    "                    positional_attention_bias=None,\n",
    "                    relative_position_encoding=None,\n",
    "                    state=state[i],\n",
    "                    content_attention_mask=None,\n",
    "                    query_attention_mask=None,\n",
    "                    target_mapping=target_mapping)\n",
    "            content_stream = transformer_xl_output[\"content_attention\"]\n",
    "            \n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, max_files, encoder, block_size, seq_len_padded, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.seq_len_padded = seq_len_padded\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxlen = maxlen\n",
    "        self.memory_length = memory_length\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.isabs = []\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                maxlen=maxlen,\n",
    "                embed_dim=embed_dim,\n",
    "                memory_length=memory_length,\n",
    "                reuse_length=reuse_length,\n",
    "                head_size=head_size,\n",
    "                inner_size=inner_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                attention_dropout_rate=attention_dropout_rate,\n",
    "                initializer=initializer, \n",
    "            )\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=True,pre_layernorm=True, use_keras_mha=True,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    " \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.memory_length, self.embed_dim))\n",
    "        \n",
    "        embeddings = self.embedding_layer(x)\n",
    "            \n",
    "        linear_transform = self.linear_layer(embeddings)    \n",
    "            \n",
    "        for i in range(0, self.seq_len_padded, self.block_size):\n",
    "            block = embeddings[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems = self.transformer_xl(content_stream=block, relative_position_encoding=None, state=mems)\n",
    "                \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters \n",
    "embed_dim = 8\n",
    "num_layers = 8\n",
    "hidden_size = 32\n",
    "num_attention_heads = 8\n",
    "memory_length = 200\n",
    "reuse_length = 0\n",
    "head_size = 8\n",
    "inner_size = 32\n",
    "dropout_rate = 0.01\n",
    "attention_dropout_rate = 0.01\n",
    "initializer = keras.initializers.RandomNormal(stddev=0.1) \n",
    "\n",
    "encoder = pretrained_encoder\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(max_files, encoder, block_size, seq_len, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Nadam(1e-4), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362b312-29ec-44ca-9918-7dcc8caf3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "20/20 [==============================] - 115s 6s/step - loss: 3.4273 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.5008 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4516 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.4523 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4351 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4490 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4450 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.4377 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4538 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3878 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4176 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4133 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4133 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3845 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4264 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.4511 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4108 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4020 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4202 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3924 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4018 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4113 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4141 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4157 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4118 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4171 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3991 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4042 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4245 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4673 - val_sparse_categorical_accuracy: 0.0400\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3834 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3566 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4002 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3425 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3908 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.4457 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3780 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4202 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4108 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.3991 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3607 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4215 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3739 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3566 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3681 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.4023 - val_sparse_categorical_accuracy: 0.0400\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3716 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4180 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3646 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.4424 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3405 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.3960 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3569 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3050 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3862 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4023 - val_sparse_categorical_accuracy: 0.0400\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3266 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.3302 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3533 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.4063 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3378 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4294 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3371 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3919 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3582 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3553 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3630 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3324 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3364 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3823 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 36/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3355 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3242 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 37/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3200 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.4179 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 38/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2984 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.4006 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 39/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3431 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3279 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 40/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3290 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.3400 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 41/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3471 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3719 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 42/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3177 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3252 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 43/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3221 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.3603 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 44/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3137 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.3203 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 45/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3154 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3725 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 46/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3074 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3884 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 47/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3147 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3491 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 48/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2732 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.4390 - val_sparse_categorical_accuracy: 0.0500\n",
      "Epoch 49/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2740 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3536 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 50/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3018 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.2680 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 51/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2982 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.3242 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 52/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2933 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3003 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 53/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3131 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3158 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 54/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3185 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2866 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 55/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2688 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.2921 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 56/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3141 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3412 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 57/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3246 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2633 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 58/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2826 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2588 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 59/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2929 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3821 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 60/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2923 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2989 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 61/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2711 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2767 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 62/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2838 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.2411 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 63/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2967 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3718 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 64/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2621 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2675 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 65/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2451 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.3317 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 66/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2492 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.3169 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 67/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2620 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3070 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 68/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2842 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2121 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 69/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2421 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2505 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 70/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2570 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2489 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 71/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2547 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2592 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 72/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2280 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.2994 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 73/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2482 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2667 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 74/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2647 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2404 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 75/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2593 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.3316 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 76/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2277 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2755 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 77/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2391 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2504 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 78/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2370 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2575 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 79/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2514 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.3106 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 80/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2375 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2625 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 81/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2362 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.3017 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 82/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2219 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.2248 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 83/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2481 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2642 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 84/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2485 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.2996 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 85/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2319 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1588 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 86/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2039 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.2956 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 87/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2198 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.2306 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 88/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2330 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.2616 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 89/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2218 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2437 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 90/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2046 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.3250 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 91/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2160 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.3396 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 92/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2202 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.3048 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 93/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2043 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2811 - val_sparse_categorical_accuracy: 0.0400\n",
      "Epoch 94/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2175 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2475 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 95/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2097 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2329 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 96/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2135 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3194 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 97/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1893 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1438 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 98/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2020 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2365 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 99/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2033 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2068 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 100/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1951 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2424 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 101/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1964 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2098 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 102/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1905 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2150 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 103/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1928 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1903 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 104/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1377 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2309 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 105/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1867 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.1763 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 106/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1848 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2275 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 107/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2035 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2346 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 108/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1856 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.2530 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 109/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1882 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2580 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 110/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1634 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1902 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 111/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2213 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.1920 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 112/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1492 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1568 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 113/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1645 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.2803 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 114/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1607 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.3079 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 115/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1781 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.1628 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 116/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1813 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2116 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 117/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1975 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.2640 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 118/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1562 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1904 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 119/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1527 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2136 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 120/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1443 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.2322 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 121/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1799 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2079 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 122/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1428 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.0951 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 123/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1254 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.2090 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 124/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1391 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.2011 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 125/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1745 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.1767 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 126/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1640 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.2255 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 127/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1375 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1450 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 128/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1525 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1804 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 129/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1250 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1827 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 130/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1354 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1646 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 131/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1593 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1628 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 132/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1431 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1914 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 133/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1304 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1448 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 134/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1647 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0745 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 135/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1198 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.1798 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 136/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1243 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2312 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 137/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1341 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1274 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 138/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1161 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1760 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 139/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1263 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.1451 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 140/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1395 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1470 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 141/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1102 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1663 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 142/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0918 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.1166 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 143/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1446 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1297 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 144/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1375 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2006 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 145/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1287 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1451 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 146/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1074 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2102 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 147/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1139 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1267 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 148/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1132 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1401 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 149/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1343 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1879 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 150/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0809 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0726 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 151/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1208 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1336 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 152/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1319 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1374 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 153/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1091 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1017 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 154/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0916 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.1478 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 155/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1042 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0965 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 156/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0896 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.1628 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 157/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1106 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.1783 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 158/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0594 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0608 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 159/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0838 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1254 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 160/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0839 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1513 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 161/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0943 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.2567 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 162/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0884 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1640 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 163/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0797 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0594 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 164/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0736 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0672 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 165/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0542 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1533 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 166/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1360 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1583 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 167/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0839 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0818 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 168/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0917 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1112 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 169/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0636 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0621 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 170/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0669 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.1205 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 171/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0606 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0548 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 172/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0664 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1484 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 173/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0826 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0991 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 174/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0580 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0588 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 175/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0470 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.0940 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 176/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0632 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.1531 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 177/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0876 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1425 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 178/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0726 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0708 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 179/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0382 - sparse_categorical_accuracy: 0.1825 - val_loss: 3.1480 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 180/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0673 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1109 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 181/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0692 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0737 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 182/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0994 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1431 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 183/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0397 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.1143 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 184/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0452 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0837 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 185/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0625 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.1256 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 186/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0480 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0229 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 187/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0631 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1372 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 188/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0548 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.1340 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 189/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0208 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0328 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 190/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0742 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.0852 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 191/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0541 - sparse_categorical_accuracy: 0.1225 - val_loss: 2.9806 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 192/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0460 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.1177 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 193/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0417 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.1068 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 194/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0796 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0206 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 195/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0580 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1618 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 196/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0319 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0620 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 197/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0316 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.0876 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 198/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0611 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0147 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 199/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0276 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0269 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 200/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0569 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0822 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 201/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0554 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0532 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 202/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0122 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.1000 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 203/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0542 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.0420 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 204/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0754 - sparse_categorical_accuracy: 0.1200 - val_loss: 2.9876 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 205/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0391 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9913 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 206/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0185 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0975 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 207/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0199 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0983 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 208/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0320 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0859 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 209/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0588 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.1331 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 210/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0039 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0706 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 211/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9825 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0867 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 212/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9858 - sparse_categorical_accuracy: 0.1700 - val_loss: 2.9868 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 213/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0099 - sparse_categorical_accuracy: 0.1750 - val_loss: 3.1747 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 214/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9843 - sparse_categorical_accuracy: 0.1725 - val_loss: 3.0325 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 215/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0028 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1466 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 216/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9867 - sparse_categorical_accuracy: 0.1800 - val_loss: 3.0684 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 217/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9741 - sparse_categorical_accuracy: 0.1775 - val_loss: 3.0678 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 218/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9951 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0165 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 219/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9845 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0850 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 220/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0240 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.1062 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 221/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0027 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0566 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 222/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9847 - sparse_categorical_accuracy: 0.1750 - val_loss: 3.0582 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 223/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0202 - sparse_categorical_accuracy: 0.1600 - val_loss: 3.0431 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 224/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9671 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.8974 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 225/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9752 - sparse_categorical_accuracy: 0.1725 - val_loss: 3.0051 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 226/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9819 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.1292 - val_sparse_categorical_accuracy: 0.0800\n",
      "Epoch 227/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9658 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.1118 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 228/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9977 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0604 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 229/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9745 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9662 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 230/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9863 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0891 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 231/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9749 - sparse_categorical_accuracy: 0.1725 - val_loss: 3.0373 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 232/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0141 - sparse_categorical_accuracy: 0.1600 - val_loss: 3.0793 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 233/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0031 - sparse_categorical_accuracy: 0.1400 - val_loss: 2.9555 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 234/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0008 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.0323 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 235/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9840 - sparse_categorical_accuracy: 0.1775 - val_loss: 3.0286 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 236/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0036 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.0852 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 237/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9823 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.0177 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 238/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9582 - sparse_categorical_accuracy: 0.1850 - val_loss: 3.0323 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 239/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9886 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.1419 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 240/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9697 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0430 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 241/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9625 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9978 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 242/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9725 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9673 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 243/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9024 - sparse_categorical_accuracy: 0.1975 - val_loss: 3.0045 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 244/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9654 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9384 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 245/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9380 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0344 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 246/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9596 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0546 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 247/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9772 - sparse_categorical_accuracy: 0.1950 - val_loss: 3.0324 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 248/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9821 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.0113 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 249/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9450 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.9550 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 250/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0066 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0697 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 251/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9684 - sparse_categorical_accuracy: 0.1725 - val_loss: 2.9988 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 252/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9410 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.9306 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 253/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9750 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0345 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 254/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9491 - sparse_categorical_accuracy: 0.1600 - val_loss: 3.0141 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 255/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9324 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9763 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 256/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9319 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0712 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 257/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9652 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.9894 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 258/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9405 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.9769 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 259/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9421 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0162 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 260/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9571 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.9092 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 261/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9743 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0028 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 262/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9137 - sparse_categorical_accuracy: 0.1800 - val_loss: 3.0638 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 263/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9500 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.9979 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 264/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9869 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0130 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 265/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9555 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.9831 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 266/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9302 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.9764 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 267/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9115 - sparse_categorical_accuracy: 0.1750 - val_loss: 3.0201 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 268/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9481 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0347 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 269/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9392 - sparse_categorical_accuracy: 0.1875 - val_loss: 3.0820 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 270/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9309 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.8997 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 271/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9978 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9901 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 272/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9089 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0044 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 273/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9248 - sparse_categorical_accuracy: 0.1875 - val_loss: 3.0528 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 274/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8907 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.9630 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 275/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9095 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0587 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 276/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9072 - sparse_categorical_accuracy: 0.1975 - val_loss: 2.9681 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 277/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9366 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.9768 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 278/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9155 - sparse_categorical_accuracy: 0.1900 - val_loss: 3.0343 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 279/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8996 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0624 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 280/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9208 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0146 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 281/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8978 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.9979 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 282/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9443 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.9479 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 283/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9554 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0379 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 284/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9463 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.8591 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 285/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9087 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9668 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 286/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9709 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9377 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 287/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8835 - sparse_categorical_accuracy: 0.2175 - val_loss: 3.0326 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 288/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9284 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.8903 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 289/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9271 - sparse_categorical_accuracy: 0.1775 - val_loss: 3.0088 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 290/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8753 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9782 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 291/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8972 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9013 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 292/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9536 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9648 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 293/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9101 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0067 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 294/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9103 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.8533 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 295/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8820 - sparse_categorical_accuracy: 0.1950 - val_loss: 3.1081 - val_sparse_categorical_accuracy: 0.0600\n",
      "Epoch 296/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8617 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8693 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 297/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9088 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.9098 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 298/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9155 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.9337 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 299/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8388 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9742 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 300/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8820 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.9799 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 301/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9160 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.8661 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 302/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8723 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.9090 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 303/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8590 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9279 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 304/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9271 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.8925 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 305/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8762 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9829 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 306/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8614 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.9754 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 307/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8891 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9772 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 308/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8735 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9814 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 309/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8589 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.9446 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 310/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8793 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9317 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 311/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8823 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9475 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 312/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9203 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.9549 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 313/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8754 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.9198 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 314/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9271 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.8454 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 315/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8673 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9149 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 316/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8822 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9901 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 317/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9106 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.9073 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 318/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8420 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.9645 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 319/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8615 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.9761 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 320/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8321 - sparse_categorical_accuracy: 0.2000 - val_loss: 3.0467 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 321/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8508 - sparse_categorical_accuracy: 0.2050 - val_loss: 3.0239 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 322/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8377 - sparse_categorical_accuracy: 0.1950 - val_loss: 2.9263 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 323/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9083 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9454 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 324/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8532 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.8205 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 325/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8244 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.8333 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 326/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8608 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.9843 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 327/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8689 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9735 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 328/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9322 - sparse_categorical_accuracy: 0.1375 - val_loss: 2.9643 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 329/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8598 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9084 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 330/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8466 - sparse_categorical_accuracy: 0.1725 - val_loss: 2.9189 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 331/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8413 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.8569 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 332/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8533 - sparse_categorical_accuracy: 0.1950 - val_loss: 2.8801 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 333/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8122 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8142 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 334/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8232 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9085 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 335/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7875 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.8351 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 336/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8703 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.8953 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 337/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8342 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.9124 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 338/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8010 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.9839 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 339/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8507 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.8732 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 340/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8192 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8231 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 341/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8008 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.8274 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 342/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8000 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.9032 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 343/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8310 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.9568 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 344/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7582 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.7801 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 345/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8551 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.0268 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 346/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8016 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.9180 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 347/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7931 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9111 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 348/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8483 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.8758 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 349/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8744 - sparse_categorical_accuracy: 0.1900 - val_loss: 3.0897 - val_sparse_categorical_accuracy: 0.0200\n",
      "Epoch 350/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8857 - sparse_categorical_accuracy: 0.1375 - val_loss: 2.8559 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 351/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8345 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.7818 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 352/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8309 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.9150 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 353/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8142 - sparse_categorical_accuracy: 0.1725 - val_loss: 2.8298 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 354/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7318 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.9253 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 355/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8062 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.7638 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 356/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8061 - sparse_categorical_accuracy: 0.2025 - val_loss: 3.0078 - val_sparse_categorical_accuracy: 0.0700\n",
      "Epoch 357/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7973 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.9384 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 358/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8187 - sparse_categorical_accuracy: 0.2075 - val_loss: 3.0212 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 359/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8258 - sparse_categorical_accuracy: 0.1950 - val_loss: 2.9203 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 360/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8340 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8508 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 361/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8778 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.8700 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 362/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7728 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.8156 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 363/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7708 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.9093 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 364/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8006 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.9231 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 365/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7551 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9412 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 366/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7875 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8661 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 367/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8290 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.9685 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 368/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8020 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.9186 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 369/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7708 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.8930 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 370/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7787 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.8404 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 371/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8429 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.9576 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 372/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8208 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.8452 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 373/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8556 - sparse_categorical_accuracy: 0.1800 - val_loss: 2.8614 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 374/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8055 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8777 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 375/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7903 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.9476 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 376/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7683 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.8318 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 377/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7752 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.9043 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 378/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7363 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.9439 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 379/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7502 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.9774 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 380/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7818 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.9055 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 381/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7892 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.9329 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 382/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7982 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.8812 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 383/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7096 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.8332 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 384/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7481 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.9548 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 385/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8400 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9355 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 386/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8068 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8406 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 387/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7935 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.8185 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 388/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7948 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.9647 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 389/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7828 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.9252 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 390/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8189 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.8603 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 391/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7942 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.8874 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 392/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7454 - sparse_categorical_accuracy: 0.1975 - val_loss: 2.7350 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 393/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7664 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.8327 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 394/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7584 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.9336 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 395/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7319 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.8033 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 396/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7321 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.9254 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 397/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7715 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.7791 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 398/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8445 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.8664 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 399/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7979 - sparse_categorical_accuracy: 0.1950 - val_loss: 2.8515 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 400/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7759 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.9430 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 401/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7361 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.8591 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 402/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7156 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.8516 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 403/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7547 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9087 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 404/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7876 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.8877 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 405/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7429 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.8376 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 406/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7067 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.8432 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 407/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7368 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.8765 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 408/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7455 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.9919 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 409/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7830 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8894 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 410/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7706 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.8481 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 411/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7474 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.8291 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 412/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7366 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.7975 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 413/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7274 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.9336 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 414/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7163 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.9190 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 415/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7084 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.8719 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 416/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7603 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8369 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 417/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7099 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.7511 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 418/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7541 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.8059 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 419/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7433 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.8341 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 420/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7123 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.7008 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 421/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7669 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.7890 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 422/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7360 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.8034 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 423/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7500 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.8587 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 424/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7108 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.8642 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 425/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7277 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.7918 - val_sparse_categorical_accuracy: 0.2700\n",
      "Epoch 426/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7382 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.7819 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 427/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7285 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.8189 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 428/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7238 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.8783 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 429/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7375 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.7190 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 430/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7391 - sparse_categorical_accuracy: 0.2075 - val_loss: 2.8345 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 431/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6710 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7022 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 432/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7246 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.7648 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 433/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7240 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.8259 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 434/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7326 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.7932 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 435/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6737 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7906 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 436/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7026 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.7555 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 437/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6812 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.9308 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 438/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7494 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.9025 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 439/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6902 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.7473 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 440/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6895 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.7538 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 441/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7654 - sparse_categorical_accuracy: 0.1975 - val_loss: 2.8681 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 442/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7104 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.8908 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 443/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6392 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.7385 - val_sparse_categorical_accuracy: 0.2700\n",
      "Epoch 444/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7149 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.7678 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 445/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7154 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.9012 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 446/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7142 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.7519 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 447/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6876 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.6845 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 448/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7413 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.7234 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 449/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6980 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.7975 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 450/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6469 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7864 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 451/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6636 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.7945 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 452/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6706 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.8083 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 453/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7256 - sparse_categorical_accuracy: 0.1975 - val_loss: 2.7657 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 454/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6355 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.6893 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 455/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7552 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.7932 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 456/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6509 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.8381 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 457/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6880 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7476 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 458/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7400 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.7978 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 459/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6565 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.6835 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 460/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7004 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.7128 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 461/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6148 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.7756 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 462/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6695 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.7373 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 463/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6585 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.8017 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 464/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6598 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.7186 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 465/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6817 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.7497 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 466/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6415 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.9115 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 467/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7132 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.8819 - val_sparse_categorical_accuracy: 0.1200\n",
      "Epoch 468/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6862 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.6383 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 469/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6752 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.7794 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 470/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6264 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.7870 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 471/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6706 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.8276 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 472/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6815 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.8151 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 473/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6563 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7545 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 474/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6572 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.7400 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 475/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7301 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.9044 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 476/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6633 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.7781 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 477/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.6547 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7629 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 478/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6697 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.6792 - val_sparse_categorical_accuracy: 0.2700\n",
      "Epoch 479/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6877 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.7624 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 480/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6842 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.8591 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 481/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6762 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.7389 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 482/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6985 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.7344 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 483/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6380 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.7404 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 484/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6066 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.8292 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 485/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6958 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.6914 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 486/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.7257 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.7807 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 487/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6106 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.6981 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 488/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6513 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.8414 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 489/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6689 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.8249 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 490/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6796 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.7958 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 491/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6585 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.6958 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 492/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6700 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.8659 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 493/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6547 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.7955 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 494/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6827 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.6086 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 495/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6326 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.7105 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 496/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5863 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.7002 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 497/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6477 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.7206 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 498/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6713 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.7695 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 499/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6757 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.7446 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 500/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6613 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.9147 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 501/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6418 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.6749 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 502/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6074 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.6825 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 503/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6264 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.6716 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 504/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5956 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.7949 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 505/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6139 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7413 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 506/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6141 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.7292 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 507/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6174 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.7067 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 508/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6315 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.7877 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 509/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6418 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.7234 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 510/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6236 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7243 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 511/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5918 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.5735 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 512/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6342 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.8301 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 513/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6272 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.8397 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 514/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6257 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.8044 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 515/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6048 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.7059 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 516/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6076 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.6617 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 517/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6399 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.7573 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 518/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6539 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.6833 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 519/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6320 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.6590 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 520/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6000 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.7654 - val_sparse_categorical_accuracy: 0.1600\n",
      "Epoch 521/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6655 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.5693 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 522/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5892 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.6776 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 523/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6254 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.7131 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 524/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5815 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.6310 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 525/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6219 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.6166 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 526/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6090 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.7458 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 527/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6107 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.7380 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 528/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6132 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.7858 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 529/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5909 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.6881 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 530/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6448 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.7840 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 531/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5666 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.7002 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 532/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5968 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.7227 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 533/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5856 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.8067 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 534/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5520 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.6737 - val_sparse_categorical_accuracy: 0.2100\n",
      "Epoch 535/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5598 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.7270 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 536/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6257 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.7235 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 537/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5987 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.6444 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 538/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5943 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.6671 - val_sparse_categorical_accuracy: 0.2700\n",
      "Epoch 539/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5751 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.6178 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 540/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6308 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.6576 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 541/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5755 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7312 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 542/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5689 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.5734 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 543/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6045 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.6798 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 544/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6065 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.6947 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 545/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6182 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.7487 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 546/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6241 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.6730 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 547/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6058 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.9002 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 548/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5681 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.7288 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 549/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6170 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.6113 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 550/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5350 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7222 - val_sparse_categorical_accuracy: 0.1400\n",
      "Epoch 551/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5919 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.7614 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 552/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.6293 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.7498 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 553/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5723 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.6829 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 554/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5515 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.7273 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 555/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5747 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.6908 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 556/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5744 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.7579 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 557/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5913 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.5835 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 558/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5428 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.6902 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 559/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5503 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.6966 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 560/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5982 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.6652 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 561/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.4937 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.6321 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 562/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5499 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.8670 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 563/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5438 - sparse_categorical_accuracy: 0.2900 - val_loss: 2.7452 - val_sparse_categorical_accuracy: 0.1300\n",
      "Epoch 564/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5266 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.8449 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 565/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5880 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.7218 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 566/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5620 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.7303 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 567/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5765 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.8341 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 568/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5528 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.6127 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 569/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5146 - sparse_categorical_accuracy: 0.3075 - val_loss: 2.6567 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 570/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5644 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.6950 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 571/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5647 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.5971 - val_sparse_categorical_accuracy: 0.2400\n",
      "Epoch 572/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5307 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.6803 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 573/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.4742 - sparse_categorical_accuracy: 0.3175 - val_loss: 2.7585 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 574/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5889 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.6100 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 575/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5426 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.6841 - val_sparse_categorical_accuracy: 0.2200\n",
      "Epoch 576/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5376 - sparse_categorical_accuracy: 0.2875 - val_loss: 2.6629 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 577/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.4869 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.6251 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 578/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5213 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.8358 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 579/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5381 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.6996 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 580/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5414 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.5420 - val_sparse_categorical_accuracy: 0.2700\n",
      "Epoch 581/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.5218 - sparse_categorical_accuracy: 0.2525"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3dbd08-bd28-4afc-aa1d-ac099c09b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf7f88d-ae35-46c4-bae6-40902afffcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_Xl_Relative.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "623c7a6b-92d8-4aed-a6a0-596dde6b1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Str_Xl_Relative.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(train_dataset[3][0], train_dataset[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14637244-b7df-41fb-b181-cd5e16282503",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0feaa-ccf4-4352-bddc-728529531858",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3f83-2d73-4c19-a50e-eb8a5c636edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ebaae-0583-4553-a957-7d1f45958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909efb30-b3da-43cd-a526-bd971ba15bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

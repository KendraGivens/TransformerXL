{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccea5cd-89de-452b-afa6-703df9e9a604",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b9dc42-734e-4950-91d3-bb3ba48a1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7fdf70c1fdc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-8dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... Done. 0:0:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n",
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n"
     ]
    }
   ],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len,kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac0a881-4dc6-4916-a18c-8c59e026e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Apr2016_S84_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes5-5-CCE_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MR-Apr2016_S13_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Sep2015_S43_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley012-HN-051120_S151_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Sep2015_S91_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Sep2015_S52_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes26-8-AG_S27_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Jul2016_S22_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes25-8-MU_S26_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Oct2016_S63_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes3-5-TCR_S4_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-May2015_S160_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Oct2016_S80_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Jul2015_S74_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Sep2015_S35_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-CCW-Sep2015_S28_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Oct2016_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HF-Jul2015_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-May2015_S73_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Apr2016_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Apr2016_S85_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes20-8-HF_S21_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes38-10-WH_S39_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley047-SF-100420_S186_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley055-HAP-051120_S194_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley006-HLP-051220_S145_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes39-10-HF_S40_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-Jul2016_S38_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley035-HLP2-072820_S174_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes13-5-HLP_S14_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-May2015_S17_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley005-HF-051220_S144_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes47-10-FC_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-May2015_S152_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley045-HLP-100420_S184_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley033-MU-072820_S172_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley043-L-100420_S182_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes48-10-CCW_S49_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Sep2015_S44_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley010-HW-051120_S149_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes36-8-HW_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley011-Ag-051120_S150_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley027-HLP-072820_S166_L001_R1_001.db']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 200\n",
    "seq_len = set_len\n",
    "maxlen = set_len\n",
    "vocab_size = 5\n",
    "num_chars_data = set_len*sequence_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > seq_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(maxlen)\n",
    "print(vocab_size)\n",
    "print(num_chars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b66c98-f8b5-4b80-9736-66a9769cc966",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af4ac04-1eab-4d74-bfc0-716408efeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_initializer(initializer):\n",
    "    if isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer.__class__.from_config(initializer.get_config())\n",
    "    return initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if reuse_length > 0:\n",
    "            current_state = current_state[:, :reuse_length, :]\n",
    "\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3126b9-a96e-4d6a-ae65-3c9579514cf1",
   "metadata": {},
   "source": [
    "---\n",
    "# MultiHead Relative Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b32faad-fd06-4448-b817-b3a1f5943aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadRelativeAttention(tf.keras.layers.MultiHeadAttention):\n",
    "    def __init__(self,\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 **kwargs):\n",
    "        super().__init__(kernel_initializer=kernel_initializer,\n",
    "                                         **kwargs)\n",
    "\n",
    "    def _build_from_signature(self, query, value, key=None):\n",
    "        super(MultiHeadRelativeAttention, self)._build_from_signature(\n",
    "                query=query,\n",
    "                value=value,\n",
    "                key=key)\n",
    "        if hasattr(value, \"shape\"):\n",
    "            value_shape = tf.TensorShape(value.shape)\n",
    "        else:\n",
    "            value_shape = value\n",
    "        if key is None:\n",
    "            key_shape = value_shape\n",
    "        elif hasattr(key, \"shape\"):\n",
    "            key_shape = tf.TensorShape(key.shape)\n",
    "        else:\n",
    "            key_shape = key\n",
    "\n",
    "        common_kwargs = dict(\n",
    "                kernel_initializer=self._kernel_initializer,\n",
    "                bias_initializer=self._bias_initializer,\n",
    "                kernel_regularizer=self._kernel_regularizer,\n",
    "                bias_regularizer=self._bias_regularizer,\n",
    "                activity_regularizer=self._activity_regularizer,\n",
    "                kernel_constraint=self._kernel_constraint,\n",
    "                bias_constraint=self._bias_constraint)\n",
    "\n",
    "        with tf.init_scope():\n",
    "            einsum_equation, _, output_rank = _build_proj_equation(\n",
    "                    key_shape.rank - 1, bound_dims=1, output_dims=2)\n",
    "            self._encoding_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                    einsum_equation,\n",
    "                    output_shape=_get_output_shape(\n",
    "                        output_rank - 1,\n",
    "                        [self._num_heads, self._key_dim]),\n",
    "                        bias_axes=None,\n",
    "                        name=\"encoding\",\n",
    "                        **common_kwargs)\n",
    "\n",
    "    def compute_attention(\n",
    "        self,\n",
    "        query,\n",
    "        key,\n",
    "        value,\n",
    "        position,\n",
    "        content_attention_bias,\n",
    "        positional_attention_bias,\n",
    "        attention_mask=None\n",
    "    ):\n",
    "        attention_mask = None\n",
    "        \n",
    "        #AC\n",
    "        content_attention = tf.einsum(self._dot_product_equation, key, query + content_attention_bias)\n",
    "        \n",
    "        attention_sum = content_attention\n",
    "\n",
    "        attention_scores = tf.multiply(attention_sum, 1.0 / math.sqrt(float(self._key_dim)))\n",
    "\n",
    "        attention_scores = self._masked_softmax(attention_scores, attention_mask)\n",
    "\n",
    "        attention_output = self._dropout_layer(attention_scores)\n",
    "\n",
    "        attention_output = tf.einsum(self._combine_equation, attention_output, value)\n",
    "        \n",
    "        return attention_output\n",
    "\n",
    "    def call(self,\n",
    "             query,\n",
    "             value,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             key=None,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             attention_mask=None):\n",
    "        \n",
    "        attention_mask = None\n",
    "        \n",
    "        \n",
    "        if not self._built_from_signature:\n",
    "            self._build_from_signature(query, value, key=key)\n",
    "        if key is None:\n",
    "            key = value\n",
    "        if state is not None and state.shape.ndims > 1:\n",
    "            value = tf.concat([state, value], 1)\n",
    "            key = tf.concat([state, key], 1)\n",
    "\n",
    "        query = self._query_dense(query)\n",
    "\n",
    "        key = self._key_dense(key)\n",
    "\n",
    "        value = self._value_dense(value)\n",
    "        position = None\n",
    "        \n",
    "        attention_output = self.compute_attention(\n",
    "                query=query,\n",
    "                key=key,\n",
    "                value=value,\n",
    "                position=position,\n",
    "                content_attention_bias=content_attention_bias,\n",
    "                positional_attention_bias=positional_attention_bias,\n",
    "                attention_mask=attention_mask)\n",
    "\n",
    "        attention_output = self._output_dense(attention_output)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a026fd-2cbe-45b7-88f7-a3ffd3548806",
   "metadata": {},
   "source": [
    "---\n",
    "# Build Einsum Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5102422c-82af-49d4-a8d5-5081262b21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHR_IDX = string.ascii_lowercase\n",
    "\n",
    "def _build_proj_equation(free_dims, bound_dims, output_dims):\n",
    "    input_str = \"\"\n",
    "    kernel_str = \"\"\n",
    "    output_str = \"\"\n",
    "    bias_axes = \"\"\n",
    "    letter_offset = 0\n",
    "    for i in range(free_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        input_str += char\n",
    "        output_str += char\n",
    "\n",
    "    letter_offset += free_dims\n",
    "    for i in range(bound_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        input_str += char\n",
    "        kernel_str += char\n",
    "\n",
    "    letter_offset += bound_dims\n",
    "    for i in range(output_dims):\n",
    "        char = _CHR_IDX[i + letter_offset]\n",
    "        kernel_str += char\n",
    "        output_str += char\n",
    "        bias_axes += char\n",
    "    equation = \"%s,%s->%s\" % (input_str, kernel_str, output_str)\n",
    "\n",
    "    return equation, bias_axes, len(output_str)\n",
    "\n",
    "\n",
    "def _get_output_shape(output_rank, known_last_dims):\n",
    "    return [None] * (output_rank - len(known_last_dims)) + list(known_last_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 hidden_size,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 norm_epsilon=1e-12,\n",
    "                 inner_activation=\"relu\",\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 inner_dropout=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__(**kwargs)\n",
    "        self._vocab_size = vocab_size\n",
    "        self._num_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._inner_size = inner_size\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._inner_activation = inner_activation\n",
    "        self._norm_epsilon = norm_epsilon\n",
    "        self._kernel_initializer = kernel_initializer\n",
    "        self._inner_dropout = inner_dropout\n",
    "        self._attention_layer_type = MultiHeadRelativeAttention\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape\n",
    "        input_tensor_shape = tf.TensorShape(input_tensor)\n",
    "        if len(input_tensor_shape.as_list()) != 3:\n",
    "            raise ValueError(\"TransformerLayer expects a three-dimensional input of \"\n",
    "                                             \"shape [batch, sequence, width].\")\n",
    "        batch_size, sequence_length, hidden_size = input_tensor_shape\n",
    "\n",
    "        if hidden_size % self._num_heads != 0:\n",
    "            raise ValueError(\n",
    "                    \"The input size (%d) is not a multiple of the number of attention \"\n",
    "                    \"heads (%d)\" % (hidden_size, self._num_heads))\n",
    "            \n",
    "\n",
    "        self._attention_layer = self._attention_layer_type(\n",
    "                num_heads=self._num_heads,\n",
    "                key_dim=self._head_size,\n",
    "                value_dim=self._head_size,\n",
    "                dropout=self._attention_dropout_rate,\n",
    "                use_bias=False,\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer),\n",
    "                name=\"rel_attn\")\n",
    "        \n",
    "        self._attention_dropout = tf.keras.layers.Dropout(\n",
    "                rate=self._attention_dropout_rate)\n",
    "        self._attention_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"self_attention_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon,\n",
    "                dtype=tf.float32)\n",
    "        self._inner_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, self._inner_size),\n",
    "                bias_axes=\"d\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer),\n",
    "                name=\"inner\")\n",
    "\n",
    "        self._inner_activation_layer = tf.keras.layers.Activation(\n",
    "                self._inner_activation)\n",
    "        self._inner_dropout_layer = tf.keras.layers.Dropout(\n",
    "                rate=self._inner_dropout)\n",
    "        self._output_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, hidden_size),\n",
    "                bias_axes=\"d\",\n",
    "                name=\"output\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer))\n",
    "        self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "        self._output_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"output_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon)\n",
    "\n",
    "        super(TransformerXLBlock, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        attention_kwargs = dict(\n",
    "                query=content_stream,\n",
    "                value=content_stream,\n",
    "                key=content_stream,\n",
    "                attention_mask=content_attention_mask)\n",
    "\n",
    "        common_attention_kwargs = dict(\n",
    "                content_attention_bias=content_attention_bias,\n",
    "                relative_position_encoding=relative_position_encoding,\n",
    "                positional_attention_bias=positional_attention_bias,\n",
    "                state=state)\n",
    "\n",
    "        attention_kwargs.update(common_attention_kwargs)\n",
    "        attention_output = self._attention_layer(**attention_kwargs)\n",
    "        \n",
    "        attention_stream = attention_output\n",
    "        input_stream = content_stream\n",
    "        attention_key = \"content_attention\"\n",
    "        attention_output = {}\n",
    "        \n",
    "        attention_stream = self._attention_dropout(attention_stream)\n",
    "        attention_stream = self._attention_layer_norm(attention_stream + input_stream)\n",
    "        inner_output = self._inner_dense(attention_stream)\n",
    "        inner_output = self._inner_activation_layer(\n",
    "                inner_output)\n",
    "        inner_output = self._inner_dropout_layer(\n",
    "                inner_output)\n",
    "        layer_output = self._output_dense(inner_output)\n",
    "        layer_output = self._output_dropout(layer_output)\n",
    "        layer_output = self._output_layer_norm(layer_output + attention_stream)\n",
    "        attention_output[attention_key] = layer_output\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 hidden_size,\n",
    "                 maxlen,\n",
    "                 embed_dim,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 initializer,\n",
    "                 tie_attention_biases=True,\n",
    "                 memory_length=None,\n",
    "                 reuse_length=None,\n",
    "                 inner_activation=\"relu\",\n",
    "                 **kwargs):\n",
    "        super(TransformerXL, self).__init__(**kwargs)\n",
    "\n",
    "        self._vocab_size = vocab_size\n",
    "        self._initializer = initializer\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._num_attention_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._inner_size = inner_size\n",
    "        self._inner_activation = inner_activation\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._tie_attention_biases = tie_attention_biases\n",
    "\n",
    "        self._memory_length = memory_length\n",
    "        self._reuse_length = reuse_length\n",
    "\n",
    "        if self._tie_attention_biases:\n",
    "            attention_bias_shape = [self._num_attention_heads, self._head_size]\n",
    "        else:\n",
    "            attention_bias_shape = [self._num_layers, self._num_attention_heads, self._head_size]\n",
    "\n",
    "        self.content_attention_bias = self.add_weight(\n",
    "                \"content_attention_bias\",\n",
    "                shape=attention_bias_shape,\n",
    "                dtype=tf.float32,\n",
    "                initializer=clone_initializer(self._initializer))\n",
    "        self.positional_attention_bias = self.add_weight(\n",
    "                \"positional_attention_bias\",\n",
    "                shape=attention_bias_shape,\n",
    "                dtype=tf.float32,\n",
    "                initializer=clone_initializer(self._initializer))\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        for i in range(self._num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(\n",
    "                            vocab_size=self._vocab_size,\n",
    "                            hidden_size=self._head_size * self._num_attention_heads,\n",
    "                            num_attention_heads=self._num_attention_heads,\n",
    "                            head_size=self._head_size,\n",
    "                            inner_size=self._inner_size,\n",
    "                            dropout_rate=self._dropout_rate,\n",
    "                            attention_dropout_rate=self._attention_dropout_rate,\n",
    "                            norm_epsilon=1e-12,\n",
    "                            inner_activation=self._inner_activation,\n",
    "                            kernel_initializer=\"variance_scaling\",\n",
    "                            name=\"layer_%d\" % i))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             relative_position_encoding,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        content_attention_mask = None\n",
    "        query_attention_mask = None\n",
    "        \n",
    "        if state is None:\n",
    "            state = [None] * self._num_layers\n",
    "        for i in range(self._num_layers):\n",
    "            # cache new mems\n",
    "            new_mems.append( _cache_memory(content_stream, state[i], self._memory_length, self._reuse_length))\n",
    "\n",
    "            if self._tie_attention_biases:\n",
    "                content_attention_bias = self.content_attention_bias\n",
    "            else:\n",
    "                content_attention_bias = self.content_attention_bias[i]\n",
    "\n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(\n",
    "                    content_stream=content_stream,\n",
    "                    content_attention_bias=content_attention_bias,\n",
    "                    positional_attention_bias=None,\n",
    "                    relative_position_encoding=None,\n",
    "                    state=state[i],\n",
    "                    content_attention_mask=None,\n",
    "                    query_attention_mask=None,\n",
    "                    target_mapping=target_mapping)\n",
    "            content_stream = transformer_xl_output[\"content_attention\"]\n",
    "            \n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, max_files, encoder, block_size, seq_len_padded, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.seq_len_padded = seq_len_padded\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxlen = maxlen\n",
    "        self.memory_length = memory_length\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.isabs = []\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                maxlen=maxlen,\n",
    "                embed_dim=embed_dim,\n",
    "                memory_length=memory_length,\n",
    "                reuse_length=reuse_length,\n",
    "                head_size=head_size,\n",
    "                inner_size=inner_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                attention_dropout_rate=attention_dropout_rate,\n",
    "                initializer=initializer, \n",
    "            )\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=True,pre_layernorm=True, use_keras_mha=True,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    " \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.memory_length, self.embed_dim))\n",
    "        \n",
    "        embeddings = self.embedding_layer(x)\n",
    "            \n",
    "        linear_transform = self.linear_layer(embeddings)    \n",
    "            \n",
    "        for i in range(0, self.seq_len_padded, self.block_size):\n",
    "            block = embeddings[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems = self.transformer_xl(content_stream=block, relative_position_encoding=None, state=mems)\n",
    "                \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters \n",
    "embed_dim = 8\n",
    "num_layers = 8\n",
    "hidden_size = 32\n",
    "num_attention_heads = 8\n",
    "memory_length = 200\n",
    "reuse_length = 0\n",
    "head_size = 8\n",
    "inner_size = 32\n",
    "dropout_rate = 0.01\n",
    "attention_dropout_rate = 0.01\n",
    "initializer = keras.initializers.RandomNormal(stddev=0.1) \n",
    "\n",
    "encoder = pretrained_encoder\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6da827b1-cb0c-4a44-b54d-5587e226866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = dict(\n",
    "    embed_dim = 8,\n",
    "    num_layers = 8,\n",
    "    hidden_size = 32,\n",
    "    num_attention_heads = 8,\n",
    "    memory_length = 200,\n",
    "    reuse_length = 0,\n",
    "    head_size = 8,\n",
    "    inner_size = 32,\n",
    "    dropout_rate = 0.01,\n",
    "    attention_dropout_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "650eec24-5463-4d8c-a3ed-62c88ebcc441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkendragivens\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/TransformerXL/STR_XL/wandb/run-20220724_122711-1l663epn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kendragivens/Str_XL_Relative_Mha/runs/1l663epn\" target=\"_blank\">dashing-flower-5</a></strong> to <a href=\"https://wandb.ai/kendragivens/Str_XL_Relative_Mha\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Str_XL_Relative_Mha\", config=Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(max_files, encoder, block_size, seq_len, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Nadam(1e-4), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362b312-29ec-44ca-9918-7dcc8caf3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0', 'positional_attention_bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0', 'positional_attention_bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "20/20 [==============================] - 131s 6s/step - loss: 3.9999 - sparse_categorical_accuracy: 0.0125 - val_loss: 4.0035 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658683771.0000 - _runtime: 140.0000\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9990 - sparse_categorical_accuracy: 0.0075 - val_loss: 4.0085 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658683884.0000 - _runtime: 253.0000\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9732 - sparse_categorical_accuracy: 0.0125 - val_loss: 3.9174 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658683997.0000 - _runtime: 366.0000\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.9680 - sparse_categorical_accuracy: 0.0125 - val_loss: 3.9689 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658684109.0000 - _runtime: 478.0000\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.9654 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.9732 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658684222.0000 - _runtime: 591.0000\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.9537 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.9800 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658684334.0000 - _runtime: 703.0000\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.9516 - sparse_categorical_accuracy: 0.0125 - val_loss: 4.0158 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658684447.0000 - _runtime: 816.0000\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9494 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9167 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658684559.0000 - _runtime: 928.0000\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9396 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9958 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658684672.0000 - _runtime: 1041.0000\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9367 - sparse_categorical_accuracy: 0.0250 - val_loss: 3.8637 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658684785.0000 - _runtime: 1154.0000\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.9506 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.9175 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658684897.0000 - _runtime: 1266.0000\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9130 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9248 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658685010.0000 - _runtime: 1379.0000\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8926 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.9309 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685122.0000 - _runtime: 1491.0000\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8597 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.9481 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658685235.0000 - _runtime: 1604.0000\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8534 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.8615 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658685347.0000 - _runtime: 1716.0000\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9118 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8615 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685460.0000 - _runtime: 1829.0000\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8451 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.8351 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658685573.0000 - _runtime: 1942.0000\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8901 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8327 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658685686.0000 - _runtime: 2055.0000\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8324 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.8846 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685798.0000 - _runtime: 2167.0000\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8522 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.7633 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658685911.0000 - _runtime: 2280.0000\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8391 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.7920 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658686023.0000 - _runtime: 2392.0000\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8532 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.8558 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658686136.0000 - _runtime: 2505.0000\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.7878 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.8115 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658686249.0000 - _runtime: 2618.0000\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8035 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.8172 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658686361.0000 - _runtime: 2730.0000\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8195 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.8057 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658686474.0000 - _runtime: 2843.0000\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.8067 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.8010 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658686586.0000 - _runtime: 2955.0000\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7963 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.7609 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686699.0000 - _runtime: 3068.0000\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.8004 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.8669 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658686811.0000 - _runtime: 3180.0000\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.7846 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.8344 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686924.0000 - _runtime: 3293.0000\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.7549 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.7758 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658687036.0000 - _runtime: 3405.0000\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7798 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.7404 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658687149.0000 - _runtime: 3518.0000\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7356 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.7246 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658687262.0000 - _runtime: 3631.0000\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7814 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.6982 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658687375.0000 - _runtime: 3744.0000\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6994 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.6881 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658687488.0000 - _runtime: 3857.0000\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7195 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.7687 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687601.0000 - _runtime: 3970.0000\n",
      "Epoch 36/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7060 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.7604 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687714.0000 - _runtime: 4083.0000\n",
      "Epoch 37/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7486 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.7155 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658687827.0000 - _runtime: 4196.0000\n",
      "Epoch 38/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6753 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.6691 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658687939.0000 - _runtime: 4308.0000\n",
      "Epoch 39/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.7313 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.6775 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688052.0000 - _runtime: 4421.0000\n",
      "Epoch 40/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6722 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.6704 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658688165.0000 - _runtime: 4534.0000\n",
      "Epoch 41/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6822 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.7367 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658688278.0000 - _runtime: 4647.0000\n",
      "Epoch 42/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6942 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.6566 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658688390.0000 - _runtime: 4759.0000\n",
      "Epoch 43/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6580 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.5933 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658688503.0000 - _runtime: 4872.0000\n",
      "Epoch 44/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6617 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.5844 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658688617.0000 - _runtime: 4986.0000\n",
      "Epoch 45/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6643 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.6712 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658688730.0000 - _runtime: 5099.0000\n",
      "Epoch 46/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6454 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.6038 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658688842.0000 - _runtime: 5211.0000\n",
      "Epoch 47/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6444 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.6350 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658688955.0000 - _runtime: 5324.0000\n",
      "Epoch 48/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6239 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.6141 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658689068.0000 - _runtime: 5437.0000\n",
      "Epoch 49/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6307 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.6140 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658689181.0000 - _runtime: 5550.0000\n",
      "Epoch 50/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6515 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.5607 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658689293.0000 - _runtime: 5662.0000\n",
      "Epoch 51/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5868 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.5890 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658689406.0000 - _runtime: 5775.0000\n",
      "Epoch 52/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.6220 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.6391 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658689519.0000 - _runtime: 5888.0000\n",
      "Epoch 53/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5919 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.6339 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658689632.0000 - _runtime: 6001.0000\n",
      "Epoch 54/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5798 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.5938 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658689744.0000 - _runtime: 6113.0000\n",
      "Epoch 55/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5908 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5580 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658689857.0000 - _runtime: 6226.0000\n",
      "Epoch 56/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5803 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.6320 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658689970.0000 - _runtime: 6339.0000\n",
      "Epoch 57/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5552 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5759 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690083.0000 - _runtime: 6452.0000\n",
      "Epoch 58/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5700 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.5863 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690196.0000 - _runtime: 6565.0000\n",
      "Epoch 59/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5568 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.5789 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690308.0000 - _runtime: 6677.0000\n",
      "Epoch 60/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5699 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4765 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658690421.0000 - _runtime: 6790.0000\n",
      "Epoch 61/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.5378 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.5615 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658690533.0000 - _runtime: 6902.0000\n",
      "Epoch 62/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5488 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5639 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658690646.0000 - _runtime: 7015.0000\n",
      "Epoch 63/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5313 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.5982 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690759.0000 - _runtime: 7128.0000\n",
      "Epoch 64/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5318 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.4639 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658690871.0000 - _runtime: 7240.0000\n",
      "Epoch 65/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5475 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.5805 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658690984.0000 - _runtime: 7353.0000\n",
      "Epoch 66/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5101 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.5434 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658691097.0000 - _runtime: 7466.0000\n",
      "Epoch 67/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.5051 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.5294 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658691210.0000 - _runtime: 7579.0000\n",
      "Epoch 68/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4766 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5210 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658691322.0000 - _runtime: 7691.0000\n",
      "Epoch 69/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4893 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4549 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658691435.0000 - _runtime: 7804.0000\n",
      "Epoch 70/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4785 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.5036 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658691547.0000 - _runtime: 7916.0000\n",
      "Epoch 71/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4754 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.5507 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658691659.0000 - _runtime: 8028.0000\n",
      "Epoch 72/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4990 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.4944 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658691772.0000 - _runtime: 8141.0000\n",
      "Epoch 73/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4815 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4894 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658691884.0000 - _runtime: 8253.0000\n",
      "Epoch 74/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4738 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4546 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658691997.0000 - _runtime: 8366.0000\n",
      "Epoch 75/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4871 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.5406 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658692110.0000 - _runtime: 8479.0000\n",
      "Epoch 76/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4891 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4540 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658692222.0000 - _runtime: 8591.0000\n",
      "Epoch 77/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4723 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.4885 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692335.0000 - _runtime: 8704.0000\n",
      "Epoch 78/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4313 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.4992 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692448.0000 - _runtime: 8817.0000\n",
      "Epoch 79/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4389 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4443 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692561.0000 - _runtime: 8930.0000\n",
      "Epoch 80/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4205 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.4771 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658692674.0000 - _runtime: 9043.0000\n",
      "Epoch 81/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4362 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4863 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692786.0000 - _runtime: 9155.0000\n",
      "Epoch 82/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4328 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4848 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658692899.0000 - _runtime: 9268.0000\n",
      "Epoch 83/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4571 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.4503 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693012.0000 - _runtime: 9381.0000\n",
      "Epoch 84/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4200 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4386 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693124.0000 - _runtime: 9493.0000\n",
      "Epoch 85/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4084 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4441 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658693237.0000 - _runtime: 9606.0000\n",
      "Epoch 86/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4286 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4428 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658693349.0000 - _runtime: 9718.0000\n",
      "Epoch 87/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4150 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4113 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693462.0000 - _runtime: 9831.0000\n",
      "Epoch 88/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4176 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.4049 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693575.0000 - _runtime: 9944.0000\n",
      "Epoch 89/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4170 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.4266 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658693688.0000 - _runtime: 10057.0000\n",
      "Epoch 90/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4114 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4358 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693800.0000 - _runtime: 10169.0000\n",
      "Epoch 91/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4477 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.4234 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693913.0000 - _runtime: 10282.0000\n",
      "Epoch 92/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.4113 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.4340 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658694025.0000 - _runtime: 10394.0000\n",
      "Epoch 93/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.4187 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3921 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658694138.0000 - _runtime: 10507.0000\n",
      "Epoch 94/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3868 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4520 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658694251.0000 - _runtime: 10620.0000\n",
      "Epoch 95/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3936 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3881 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658694363.0000 - _runtime: 10732.0000\n",
      "Epoch 96/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3798 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.3683 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658694476.0000 - _runtime: 10845.0000\n",
      "Epoch 97/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3728 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3997 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658694589.0000 - _runtime: 10958.0000\n",
      "Epoch 98/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3770 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.4005 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658694702.0000 - _runtime: 11071.0000\n",
      "Epoch 99/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3856 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3858 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658694815.0000 - _runtime: 11184.0000\n",
      "Epoch 100/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3829 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4361 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658694927.0000 - _runtime: 11296.0000\n",
      "Epoch 101/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3525 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3328 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658695040.0000 - _runtime: 11409.0000\n",
      "Epoch 102/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3696 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.2929 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658695153.0000 - _runtime: 11522.0000\n",
      "Epoch 103/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3809 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.3653 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658695266.0000 - _runtime: 11635.0000\n",
      "Epoch 104/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3667 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3734 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658695379.0000 - _runtime: 11748.0000\n",
      "Epoch 105/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3786 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.3623 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658695492.0000 - _runtime: 11861.0000\n",
      "Epoch 106/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3410 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.4364 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658695605.0000 - _runtime: 11974.0000\n",
      "Epoch 107/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3596 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3319 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658695717.0000 - _runtime: 12086.0000\n",
      "Epoch 108/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3443 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.3633 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658695830.0000 - _runtime: 12199.0000\n",
      "Epoch 109/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3323 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3535 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658695943.0000 - _runtime: 12312.0000\n",
      "Epoch 110/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3326 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3456 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658696056.0000 - _runtime: 12425.0000\n",
      "Epoch 111/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3483 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.3487 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658696168.0000 - _runtime: 12537.0000\n",
      "Epoch 112/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3172 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.3705 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658696281.0000 - _runtime: 12650.0000\n",
      "Epoch 113/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3517 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.3280 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658696393.0000 - _runtime: 12762.0000\n",
      "Epoch 114/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3297 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3298 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658696506.0000 - _runtime: 12875.0000\n",
      "Epoch 115/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3567 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.3507 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658696619.0000 - _runtime: 12988.0000\n",
      "Epoch 116/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3383 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3474 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658696731.0000 - _runtime: 13100.0000\n",
      "Epoch 117/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2939 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3320 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658696844.0000 - _runtime: 13213.0000\n",
      "Epoch 118/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3300 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.3254 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658696956.0000 - _runtime: 13325.0000\n",
      "Epoch 119/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2995 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.4366 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658697069.0000 - _runtime: 13438.0000\n",
      "Epoch 120/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3158 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3317 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697181.0000 - _runtime: 13550.0000\n",
      "Epoch 121/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3038 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697294.0000 - _runtime: 13663.0000\n",
      "Epoch 122/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3148 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.2736 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697406.0000 - _runtime: 13775.0000\n",
      "Epoch 123/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.3105 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.3242 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697519.0000 - _runtime: 13888.0000\n",
      "Epoch 124/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2891 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2784 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697632.0000 - _runtime: 14001.0000\n",
      "Epoch 125/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.3106 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.2645 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658697744.0000 - _runtime: 14113.0000\n",
      "Epoch 126/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2919 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.3423 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697857.0000 - _runtime: 14226.0000\n",
      "Epoch 127/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2992 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3114 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697970.0000 - _runtime: 14339.0000\n",
      "Epoch 128/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2855 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3003 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658698083.0000 - _runtime: 14452.0000\n",
      "Epoch 129/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2400 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2561 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658698195.0000 - _runtime: 14564.0000\n",
      "Epoch 130/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2612 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3057 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658698308.0000 - _runtime: 14677.0000\n",
      "Epoch 131/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2771 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3205 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658698421.0000 - _runtime: 14790.0000\n",
      "Epoch 132/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2560 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.3742 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658698533.0000 - _runtime: 14902.0000\n",
      "Epoch 133/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2685 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3269 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658698646.0000 - _runtime: 15015.0000\n",
      "Epoch 134/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2753 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.2874 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658698759.0000 - _runtime: 15128.0000\n",
      "Epoch 135/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2699 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.2459 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658698872.0000 - _runtime: 15241.0000\n",
      "Epoch 136/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2589 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.2604 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658698984.0000 - _runtime: 15353.0000\n",
      "Epoch 137/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2522 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3104 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658699097.0000 - _runtime: 15466.0000\n",
      "Epoch 138/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2270 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2621 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658699210.0000 - _runtime: 15579.0000\n",
      "Epoch 139/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2607 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2586 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658699322.0000 - _runtime: 15691.0000\n",
      "Epoch 140/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2519 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3117 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658699435.0000 - _runtime: 15804.0000\n",
      "Epoch 141/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2699 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.2995 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658699547.0000 - _runtime: 15916.0000\n",
      "Epoch 142/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2632 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.2566 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658699660.0000 - _runtime: 16029.0000\n",
      "Epoch 143/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2587 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3046 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658699772.0000 - _runtime: 16141.0000\n",
      "Epoch 144/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2586 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.2734 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658699885.0000 - _runtime: 16254.0000\n",
      "Epoch 145/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2639 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.2240 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658699997.0000 - _runtime: 16366.0000\n",
      "Epoch 146/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2538 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3167 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658700110.0000 - _runtime: 16479.0000\n",
      "Epoch 147/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2596 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.2678 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658700223.0000 - _runtime: 16592.0000\n",
      "Epoch 148/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2468 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2342 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658700336.0000 - _runtime: 16705.0000\n",
      "Epoch 149/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2024 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2297 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658700449.0000 - _runtime: 16818.0000\n",
      "Epoch 150/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2188 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2347 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658700561.0000 - _runtime: 16930.0000\n",
      "Epoch 151/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2134 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.2500 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658700674.0000 - _runtime: 17043.0000\n",
      "Epoch 152/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2170 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2204 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658700786.0000 - _runtime: 17155.0000\n",
      "Epoch 153/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2070 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2495 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658700899.0000 - _runtime: 17268.0000\n",
      "Epoch 154/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2273 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.1719 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658701012.0000 - _runtime: 17381.0000\n",
      "Epoch 155/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1864 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2460 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658701125.0000 - _runtime: 17494.0000\n",
      "Epoch 156/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2314 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2407 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658701237.0000 - _runtime: 17606.0000\n",
      "Epoch 157/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2030 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.2494 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658701350.0000 - _runtime: 17719.0000\n",
      "Epoch 158/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2282 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.3079 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658701462.0000 - _runtime: 17831.0000\n",
      "Epoch 159/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1996 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2240 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658701575.0000 - _runtime: 17944.0000\n",
      "Epoch 160/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2193 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2183 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658701687.0000 - _runtime: 18056.0000\n",
      "Epoch 161/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1960 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2615 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658701800.0000 - _runtime: 18169.0000\n",
      "Epoch 162/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.2044 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.1767 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658701913.0000 - _runtime: 18282.0000\n",
      "Epoch 163/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1831 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2221 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658702025.0000 - _runtime: 18394.0000\n",
      "Epoch 164/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1853 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1547 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658702138.0000 - _runtime: 18507.0000\n",
      "Epoch 165/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.2241 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.1541 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658702251.0000 - _runtime: 18620.0000\n",
      "Epoch 166/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1922 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1945 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658702364.0000 - _runtime: 18733.0000\n",
      "Epoch 167/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1672 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2062 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658702477.0000 - _runtime: 18846.0000\n",
      "Epoch 168/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1928 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.0819 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658702589.0000 - _runtime: 18958.0000\n",
      "Epoch 169/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1680 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.2185 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658702702.0000 - _runtime: 19071.0000\n",
      "Epoch 170/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1850 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2876 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658702815.0000 - _runtime: 19184.0000\n",
      "Epoch 171/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1655 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1802 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658702927.0000 - _runtime: 19296.0000\n",
      "Epoch 172/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1612 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2431 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703040.0000 - _runtime: 19409.0000\n",
      "Epoch 173/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1756 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1513 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658703153.0000 - _runtime: 19522.0000\n",
      "Epoch 174/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1803 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1590 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703265.0000 - _runtime: 19634.0000\n",
      "Epoch 175/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1696 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1867 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703378.0000 - _runtime: 19747.0000\n",
      "Epoch 176/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1582 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2267 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658703490.0000 - _runtime: 19859.0000\n",
      "Epoch 177/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1477 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1907 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658703603.0000 - _runtime: 19972.0000\n",
      "Epoch 178/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1702 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1681 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658703715.0000 - _runtime: 20084.0000\n",
      "Epoch 179/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1464 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1447 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658703828.0000 - _runtime: 20197.0000\n",
      "Epoch 180/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1414 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1010 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658703941.0000 - _runtime: 20310.0000\n",
      "Epoch 181/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1427 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1598 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704053.0000 - _runtime: 20422.0000\n",
      "Epoch 182/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1677 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.0757 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658704166.0000 - _runtime: 20535.0000\n",
      "Epoch 183/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1566 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1317 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658704279.0000 - _runtime: 20648.0000\n",
      "Epoch 184/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1854 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.1996 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658704392.0000 - _runtime: 20761.0000\n",
      "Epoch 185/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1379 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1861 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658704504.0000 - _runtime: 20873.0000\n",
      "Epoch 186/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1629 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1534 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658704617.0000 - _runtime: 20986.0000\n",
      "Epoch 187/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1018 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1983 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658704730.0000 - _runtime: 21099.0000\n",
      "Epoch 188/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1139 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1891 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658704842.0000 - _runtime: 21211.0000\n",
      "Epoch 189/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1606 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.0777 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658704955.0000 - _runtime: 21324.0000\n",
      "Epoch 190/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1342 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1174 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658705068.0000 - _runtime: 21437.0000\n",
      "Epoch 191/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1393 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1478 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658705180.0000 - _runtime: 21549.0000\n",
      "Epoch 192/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1033 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1021 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658705293.0000 - _runtime: 21662.0000\n",
      "Epoch 193/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1098 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.0653 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705405.0000 - _runtime: 21774.0000\n",
      "Epoch 194/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1135 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1450 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658705518.0000 - _runtime: 21887.0000\n",
      "Epoch 195/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1300 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1370 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658705631.0000 - _runtime: 22000.0000\n",
      "Epoch 196/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1469 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0941 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658705744.0000 - _runtime: 22113.0000\n",
      "Epoch 197/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1145 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1298 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705856.0000 - _runtime: 22225.0000\n",
      "Epoch 198/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0983 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1440 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705969.0000 - _runtime: 22338.0000\n",
      "Epoch 199/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1163 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1299 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658706082.0000 - _runtime: 22451.0000\n",
      "Epoch 200/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0948 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1442 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658706194.0000 - _runtime: 22563.0000\n",
      "Epoch 201/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1012 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1241 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658706307.0000 - _runtime: 22676.0000\n",
      "Epoch 202/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0953 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1657 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658706420.0000 - _runtime: 22789.0000\n",
      "Epoch 203/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1135 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.0776 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658706533.0000 - _runtime: 22902.0000\n",
      "Epoch 204/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1096 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1661 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658706645.0000 - _runtime: 23014.0000\n",
      "Epoch 205/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1131 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1554 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658706758.0000 - _runtime: 23127.0000\n",
      "Epoch 206/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0992 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1328 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658706871.0000 - _runtime: 23240.0000\n",
      "Epoch 207/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0777 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.2048 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658706983.0000 - _runtime: 23352.0000\n",
      "Epoch 208/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1026 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1594 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658707096.0000 - _runtime: 23465.0000\n",
      "Epoch 209/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0753 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0394 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658707209.0000 - _runtime: 23578.0000\n",
      "Epoch 210/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0909 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1395 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658707322.0000 - _runtime: 23691.0000\n",
      "Epoch 211/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1118 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1330 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658707435.0000 - _runtime: 23804.0000\n",
      "Epoch 212/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0736 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.0403 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658707547.0000 - _runtime: 23916.0000\n",
      "Epoch 213/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.1044 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.1386 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658707660.0000 - _runtime: 24029.0000\n",
      "Epoch 214/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0712 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.0305 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658707773.0000 - _runtime: 24142.0000\n",
      "Epoch 215/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0818 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1076 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658707886.0000 - _runtime: 24255.0000\n",
      "Epoch 216/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.1141 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.1255 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658707998.0000 - _runtime: 24367.0000\n",
      "Epoch 217/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0692 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.1389 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658708110.0000 - _runtime: 24479.0000\n",
      "Epoch 218/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0656 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1148 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658708223.0000 - _runtime: 24592.0000\n",
      "Epoch 219/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0918 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1252 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658708336.0000 - _runtime: 24705.0000\n",
      "Epoch 220/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0480 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.1597 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658708448.0000 - _runtime: 24817.0000\n",
      "Epoch 221/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0537 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.1515 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658708561.0000 - _runtime: 24930.0000\n",
      "Epoch 222/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0689 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.1181 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658708674.0000 - _runtime: 25043.0000\n",
      "Epoch 223/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0648 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0853 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658708787.0000 - _runtime: 25156.0000\n",
      "Epoch 224/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0649 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.1367 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658708899.0000 - _runtime: 25268.0000\n",
      "Epoch 225/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0768 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1090 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658709012.0000 - _runtime: 25381.0000\n",
      "Epoch 226/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0424 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0404 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658709124.0000 - _runtime: 25493.0000\n",
      "Epoch 227/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0631 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.2431 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658709237.0000 - _runtime: 25606.0000\n",
      "Epoch 228/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0459 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0803 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658709350.0000 - _runtime: 25719.0000\n",
      "Epoch 229/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0591 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.1832 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658709463.0000 - _runtime: 25832.0000\n",
      "Epoch 230/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0556 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1129 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658709575.0000 - _runtime: 25944.0000\n",
      "Epoch 231/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0569 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0769 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658709688.0000 - _runtime: 26057.0000\n",
      "Epoch 232/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0544 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1156 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658709801.0000 - _runtime: 26170.0000\n",
      "Epoch 233/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0463 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.0592 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658709913.0000 - _runtime: 26282.0000\n",
      "Epoch 234/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0122 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1056 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658710026.0000 - _runtime: 26395.0000\n",
      "Epoch 235/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0059 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0047 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658710139.0000 - _runtime: 26508.0000\n",
      "Epoch 236/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9768 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.0619 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658710251.0000 - _runtime: 26620.0000\n",
      "Epoch 237/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0039 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1398 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658710364.0000 - _runtime: 26733.0000\n",
      "Epoch 238/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0314 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0076 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658710477.0000 - _runtime: 26846.0000\n",
      "Epoch 239/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0014 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0732 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658710590.0000 - _runtime: 26959.0000\n",
      "Epoch 240/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0024 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0301 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658710702.0000 - _runtime: 27071.0000\n",
      "Epoch 241/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0058 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.1221 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658710815.0000 - _runtime: 27184.0000\n",
      "Epoch 242/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0012 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0844 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658710927.0000 - _runtime: 27296.0000\n",
      "Epoch 243/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0066 - sparse_categorical_accuracy: 0.1275 - val_loss: 2.9838 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658711040.0000 - _runtime: 27409.0000\n",
      "Epoch 244/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9915 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0271 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658711153.0000 - _runtime: 27522.0000\n",
      "Epoch 245/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9913 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0556 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658711265.0000 - _runtime: 27634.0000\n",
      "Epoch 246/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9958 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.1428 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658711378.0000 - _runtime: 27747.0000\n",
      "Epoch 247/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9785 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.9856 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658711490.0000 - _runtime: 27859.0000\n",
      "Epoch 248/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.0353 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0163 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658711603.0000 - _runtime: 27972.0000\n",
      "Epoch 249/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9309 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0628 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658711715.0000 - _runtime: 28084.0000\n",
      "Epoch 250/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9950 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.0006 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658711828.0000 - _runtime: 28197.0000\n",
      "Epoch 251/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9830 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0470 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658711940.0000 - _runtime: 28309.0000\n",
      "Epoch 252/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9873 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0094 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658712053.0000 - _runtime: 28422.0000\n",
      "Epoch 253/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 3.0234 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0857 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658712166.0000 - _runtime: 28535.0000\n",
      "Epoch 254/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9376 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0989 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658712278.0000 - _runtime: 28647.0000\n",
      "Epoch 255/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9914 - sparse_categorical_accuracy: 0.1400 - val_loss: 2.9844 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658712391.0000 - _runtime: 28760.0000\n",
      "Epoch 256/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9814 - sparse_categorical_accuracy: 0.1225 - val_loss: 2.9204 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658712503.0000 - _runtime: 28872.0000\n",
      "Epoch 257/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9680 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0823 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658712616.0000 - _runtime: 28985.0000\n",
      "Epoch 258/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9565 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0215 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658712729.0000 - _runtime: 29098.0000\n",
      "Epoch 259/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9340 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9678 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658712842.0000 - _runtime: 29211.0000\n",
      "Epoch 260/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9593 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0140 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658712955.0000 - _runtime: 29324.0000\n",
      "Epoch 261/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9570 - sparse_categorical_accuracy: 0.1075 - val_loss: 2.9174 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658713067.0000 - _runtime: 29436.0000\n",
      "Epoch 262/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9841 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9732 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658713180.0000 - _runtime: 29549.0000\n",
      "Epoch 263/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9633 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0813 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658713293.0000 - _runtime: 29662.0000\n",
      "Epoch 264/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9552 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0638 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658713406.0000 - _runtime: 29775.0000\n",
      "Epoch 265/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9457 - sparse_categorical_accuracy: 0.1275 - val_loss: 2.9897 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658713518.0000 - _runtime: 29887.0000\n",
      "Epoch 266/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9422 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0898 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658713631.0000 - _runtime: 30000.0000\n",
      "Epoch 267/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9051 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0785 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658713744.0000 - _runtime: 30113.0000\n",
      "Epoch 268/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9485 - sparse_categorical_accuracy: 0.1425 - val_loss: 2.9946 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658713857.0000 - _runtime: 30226.0000\n",
      "Epoch 269/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9552 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9750 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658713969.0000 - _runtime: 30338.0000\n",
      "Epoch 270/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9135 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1027 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658714081.0000 - _runtime: 30450.0000\n",
      "Epoch 271/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9364 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.8936 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658714194.0000 - _runtime: 30563.0000\n",
      "Epoch 272/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9741 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0244 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658714307.0000 - _runtime: 30676.0000\n",
      "Epoch 273/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9236 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0290 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658714420.0000 - _runtime: 30789.0000\n",
      "Epoch 274/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9702 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.0439 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658714533.0000 - _runtime: 30902.0000\n",
      "Epoch 275/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9479 - sparse_categorical_accuracy: 0.1200 - val_loss: 2.9748 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658714645.0000 - _runtime: 31014.0000\n",
      "Epoch 276/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9327 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.9638 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658714758.0000 - _runtime: 31127.0000\n",
      "Epoch 277/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9644 - sparse_categorical_accuracy: 0.1425 - val_loss: 2.9681 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658714871.0000 - _runtime: 31240.0000\n",
      "Epoch 278/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8942 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.9864 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658714984.0000 - _runtime: 31353.0000\n",
      "Epoch 279/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9586 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9809 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658715096.0000 - _runtime: 31465.0000\n",
      "Epoch 280/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9355 - sparse_categorical_accuracy: 0.1100 - val_loss: 2.9947 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658715209.0000 - _runtime: 31578.0000\n",
      "Epoch 281/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9389 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9898 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658715321.0000 - _runtime: 31690.0000\n",
      "Epoch 282/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9067 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0180 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658715434.0000 - _runtime: 31803.0000\n",
      "Epoch 283/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8969 - sparse_categorical_accuracy: 0.1400 - val_loss: 2.9067 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658715547.0000 - _runtime: 31916.0000\n",
      "Epoch 284/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9289 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0070 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658715659.0000 - _runtime: 32028.0000\n",
      "Epoch 285/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8893 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9219 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658715772.0000 - _runtime: 32141.0000\n",
      "Epoch 286/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9242 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1009 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658715885.0000 - _runtime: 32254.0000\n",
      "Epoch 287/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9128 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0777 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658715998.0000 - _runtime: 32367.0000\n",
      "Epoch 288/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9120 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9945 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658716110.0000 - _runtime: 32479.0000\n",
      "Epoch 289/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8802 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0605 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658716223.0000 - _runtime: 32592.0000\n",
      "Epoch 290/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8812 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9501 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658716335.0000 - _runtime: 32704.0000\n",
      "Epoch 291/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9309 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.9971 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658716448.0000 - _runtime: 32817.0000\n",
      "Epoch 292/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.9372 - sparse_categorical_accuracy: 0.1300 - val_loss: 2.8511 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658716561.0000 - _runtime: 32930.0000\n",
      "Epoch 293/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9138 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9545 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658716673.0000 - _runtime: 33042.0000\n",
      "Epoch 294/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8848 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.9463 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658716786.0000 - _runtime: 33155.0000\n",
      "Epoch 295/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.9024 - sparse_categorical_accuracy: 0.1075 - val_loss: 2.9879 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658716898.0000 - _runtime: 33267.0000\n",
      "Epoch 296/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8940 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0051 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658717011.0000 - _runtime: 33380.0000\n",
      "Epoch 297/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8706 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0542 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658717124.0000 - _runtime: 33493.0000\n",
      "Epoch 298/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8811 - sparse_categorical_accuracy: 0.1175 - val_loss: 2.9660 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658717236.0000 - _runtime: 33605.0000\n",
      "Epoch 299/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8926 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.8332 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658717349.0000 - _runtime: 33718.0000\n",
      "Epoch 300/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8728 - sparse_categorical_accuracy: 0.1175 - val_loss: 2.9406 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658717462.0000 - _runtime: 33831.0000\n",
      "Epoch 301/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8903 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9737 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658717574.0000 - _runtime: 33943.0000\n",
      "Epoch 302/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8479 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9399 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658717687.0000 - _runtime: 34056.0000\n",
      "Epoch 303/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8956 - sparse_categorical_accuracy: 0.0850 - val_loss: 2.8854 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658717799.0000 - _runtime: 34168.0000\n",
      "Epoch 304/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8577 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.8479 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658717912.0000 - _runtime: 34281.0000\n",
      "Epoch 305/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8750 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0139 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658718024.0000 - _runtime: 34393.0000\n",
      "Epoch 306/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8603 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.8824 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658718137.0000 - _runtime: 34506.0000\n",
      "Epoch 307/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8791 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0927 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658718250.0000 - _runtime: 34619.0000\n",
      "Epoch 308/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8619 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.9241 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658718362.0000 - _runtime: 34731.0000\n",
      "Epoch 309/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8525 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9137 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658718475.0000 - _runtime: 34844.0000\n",
      "Epoch 310/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8698 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9882 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658718588.0000 - _runtime: 34957.0000\n",
      "Epoch 311/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8863 - sparse_categorical_accuracy: 0.1200 - val_loss: 2.8845 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658718700.0000 - _runtime: 35069.0000\n",
      "Epoch 312/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8583 - sparse_categorical_accuracy: 0.1425 - val_loss: 2.8724 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658718813.0000 - _runtime: 35182.0000\n",
      "Epoch 313/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8374 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9190 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658718926.0000 - _runtime: 35295.0000\n",
      "Epoch 314/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8508 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.9115 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658719038.0000 - _runtime: 35407.0000\n",
      "Epoch 315/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8323 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9649 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658719151.0000 - _runtime: 35520.0000\n",
      "Epoch 316/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8838 - sparse_categorical_accuracy: 0.1275 - val_loss: 2.8592 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658719264.0000 - _runtime: 35633.0000\n",
      "Epoch 317/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8386 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.9373 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658719376.0000 - _runtime: 35745.0000\n",
      "Epoch 318/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.7966 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9664 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658719489.0000 - _runtime: 35858.0000\n",
      "Epoch 319/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8636 - sparse_categorical_accuracy: 0.1225 - val_loss: 2.8134 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658719602.0000 - _runtime: 35971.0000\n",
      "Epoch 320/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8512 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.9263 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658719715.0000 - _runtime: 36084.0000\n",
      "Epoch 321/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8800 - sparse_categorical_accuracy: 0.1375 - val_loss: 2.9717 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658719827.0000 - _runtime: 36196.0000\n",
      "Epoch 322/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8412 - sparse_categorical_accuracy: 0.1125 - val_loss: 2.9275 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658719940.0000 - _runtime: 36309.0000\n",
      "Epoch 323/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.8400 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.8777 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658720052.0000 - _runtime: 36421.0000\n",
      "Epoch 324/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.8356 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9550 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658720165.0000 - _runtime: 36534.0000\n",
      "Epoch 325/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.7941 - sparse_categorical_accuracy: 0.1625"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1, callbacks=[wandb.keras.WandbCallback(save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4ed7-fe5b-40a0-9881-e7435e5dcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3dbd08-bd28-4afc-aa1d-ac099c09b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7f88d-ae35-46c4-bae6-40902afffcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_Xl_Relative.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "623c7a6b-92d8-4aed-a6a0-596dde6b1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Str_Xl_Relative.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(train_dataset[3][0], train_dataset[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14637244-b7df-41fb-b181-cd5e16282503",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0feaa-ccf4-4352-bddc-728529531858",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3f83-2d73-4c19-a50e-eb8a5c636edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ebaae-0583-4553-a957-7d1f45958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909efb30-b3da-43cd-a526-bd971ba15bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

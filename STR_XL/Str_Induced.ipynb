{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477b0698-1d5c-4d85-b5a5-0c4cc9766421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665026fc-9622-4dc3-972e-4e8c3de33e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a20b11-1a27-4f59-8054-f4686a12e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "487d6841-517e-4726-aefd-ba8e7c6d33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4198c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "from Attention import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dae2ca0-69c8-442c-8bee-da802a6b26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4300b2-d429-48f4-85ed-68772465def6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d6bf42-0914-487c-922f-b54f2712adee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7ff0a8fdde70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-8dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc98b4a9-90f8-442f-8f7e-7633b6f117cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... Done. 0:0:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae0979-85aa-46e8-9cc4-61380710728e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate batches\n",
    "split_ratios = [0.8, 0.2]\n",
    "subsample_length = 1000\n",
    "sequence_length = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613ec15a-94ea-40f6-83c4-593956d79975",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfd656b-2de3-4a36-a0d6-9be8c1492d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:5], split_ratios=split_ratios, subsample_length=subsample_length, sequence_length=sequence_length,kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81aba5f7-0fd3-4017-8eeb-cd955c99b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7e12c7-d792-4e37-9ab2-3db8658b5814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae445919-6300-44ff-b3c2-fd2d9828335b",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5928c7f-92ab-4952-ab8b-477e0e457959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder= dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6fc1685-c320-40f5-bb4a-1c217be25963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47f6fd-2a44-46f8-8b46-15fc33786e13",
   "metadata": {},
   "source": [
    "---\n",
    "# Set Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11e396d-98b4-47ce-903a-c342ec73e234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Set_Transformer_Model(keras.Model):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha, seq_len, encoder, output_shape):\n",
    "        super(Set_Transformer_Model, self).__init__()\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.isabs = []\n",
    "        \n",
    "        for i in range(stack):\n",
    "            self.isabs.append(Set_Transformer.InducedSetAttentionBlock(embed_dim=embed_dim,num_heads=num_heads,num_induce=num_induce,use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha))\n",
    "      \n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=num_heads,use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "        \n",
    "        self.output_layer = keras.layers.Dense(output_shape)\n",
    "    \n",
    "    def call(self, data):\n",
    "        \n",
    "            embeddings = self.embedding_layer(data)\n",
    "            \n",
    "            linear_transform = self.linear_layer(embeddings)\n",
    "            \n",
    "            attention = linear_transform\n",
    "            \n",
    "            for isab in self.isabs:\n",
    "                attention = isab([attention, None])\n",
    "                \n",
    "            pooling = self.pooling_layer(attention)\n",
    "        \n",
    "            reshape = self.reshape_layer(pooling)\n",
    "            \n",
    "            output = self.output_layer(reshape)    \n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c8632-97aa-46b0-9af1-afee2c87613f",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b79d89-3c83-41f0-954f-86419d612032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_induce = 48\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "stack = 4\n",
    "use_layernorm = True\n",
    "pre_layernorm = True\n",
    "use_keras_mha = True\n",
    "seq_len = 148\n",
    "encoder = pretrained_encoder\n",
    "output_shape = max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d174e7c1-fd3c-466b-a211-79555706313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = dict(\n",
    "    num_induce = 48,\n",
    "    embed_dim = 64,\n",
    "    num_heads = 8,\n",
    "    stack = 4,\n",
    "    use_layernorm = True,\n",
    "    pre_layernorm = True,\n",
    "    use_keras_mha = True,\n",
    "    seq_len = 148,\n",
    "    output_shape = max_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef28007c-fa3c-4608-befb-9e6b0a4f0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkendragivens\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/TransformerXL/STR_XL/wandb/run-20220731_183133-2qsdm0g6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kendragivens/Str_Induced/runs/2qsdm0g6\" target=\"_blank\">stellar-jazz-12</a></strong> to <a href=\"https://wandb.ai/kendragivens/Str_Induced\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Str_Induced\", config=Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a8fa23-80d6-47e7-9f5d-39e6d55c6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Set_Transformer_Model(num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha, seq_len, encoder, output_shape)\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51fbd3f6-ad09-4e86-a5e4-27703b9e21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7dbf382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "20/20 [==============================] - 153s 7s/step - loss: 1.2608 - sparse_categorical_accuracy: 0.3725 - val_loss: 0.9501 - val_sparse_categorical_accuracy: 0.3900 - _timestamp: 1659310475.0000 - _runtime: 181.0000\n",
      "Epoch 2/10000\n",
      " 2/20 [==>...........................] - ETA: 2:09 - loss: 0.9675 - sparse_categorical_accuracy: 0.5750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWandbCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1, callbacks=[wandb.keras.WandbCallback(save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "547d0269-2b98-46af-8084-742c2e254389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.259 MB of 5.259 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▆▆▅▄▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>sparse_categorical_accuracy</td><td>▁▁▂▂▂▃▃▄▄▄▅▄▆▆▅▆▇▇▇▇▆▇▇▇█▇▇▇██▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>██▇▇▆▇▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▁</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>▁▁▂▂▂▁▃▄▄▃▅▅▅▆▆▆▆▆▆▅▅▇▇▆▆▇▆▆▇█▆▇███▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>601</td></tr><tr><td>best_val_loss</td><td>0.30924</td></tr><tr><td>epoch</td><td>692</td></tr><tr><td>loss</td><td>0.5201</td></tr><tr><td>sparse_categorical_accuracy</td><td>0.7925</td></tr><tr><td>val_loss</td><td>0.56667</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>0.79</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glad-shadow-11</strong>: <a href=\"https://wandb.ai/kendragivens/Str_Induced/runs/3rbkrt6l\" target=\"_blank\">https://wandb.ai/kendragivens/Str_Induced/runs/3rbkrt6l</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220726_172135-3rbkrt6l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea7d585f-8f1a-455d-a812-4b1931ab19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_Induced_Run2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24ec60e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Plot history and accuracy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m211\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot history and accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae52ab4-742c-4cc1-bdc7-feb96529a535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

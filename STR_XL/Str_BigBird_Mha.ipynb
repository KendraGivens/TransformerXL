{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccea5cd-89de-452b-afa6-703df9e9a604",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f894fa-f426-4f51-a312-5a7365ff1da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import BigBird\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(1, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7fc21042b070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-8dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... Done. 0:0:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n",
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n"
     ]
    }
   ],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len,kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac0a881-4dc6-4916-a18c-8c59e026e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Apr2016_S84_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes5-5-CCE_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MR-Apr2016_S13_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Sep2015_S43_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley012-HN-051120_S151_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Sep2015_S91_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Sep2015_S52_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes26-8-AG_S27_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Jul2016_S22_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes25-8-MU_S26_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Oct2016_S63_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes3-5-TCR_S4_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-May2015_S160_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Oct2016_S80_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Jul2015_S74_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Sep2015_S35_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-CCW-Sep2015_S28_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Oct2016_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HF-Jul2015_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-May2015_S73_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Apr2016_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Apr2016_S85_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes20-8-HF_S21_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes38-10-WH_S39_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley047-SF-100420_S186_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley055-HAP-051120_S194_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley006-HLP-051220_S145_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes39-10-HF_S40_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-Jul2016_S38_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley035-HLP2-072820_S174_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes13-5-HLP_S14_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-May2015_S17_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley005-HF-051220_S144_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes47-10-FC_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-May2015_S152_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley045-HLP-100420_S184_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley033-MU-072820_S172_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley043-L-100420_S182_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes48-10-CCW_S49_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Sep2015_S44_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley010-HW-051120_S149_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes36-8-HW_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley011-Ag-051120_S150_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley027-HLP-072820_S166_L001_R1_001.db']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 200\n",
    "seq_len = set_len\n",
    "maxlen = set_len\n",
    "vocab_size = 5\n",
    "num_chars_data = set_len*sequence_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > seq_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(maxlen)\n",
    "print(vocab_size)\n",
    "print(num_chars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b66c98-f8b5-4b80-9736-66a9769cc966",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af4ac04-1eab-4d74-bfc0-716408efeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_initializer(initializer):\n",
    "    if isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer.__class__.from_config(initializer.get_config())\n",
    "    return initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bab6629e-6cd9-4385-9233-0644a3d65da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.ones(tf.shape(train_dataset[0][0])[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d7969-7c66-4214-a6cf-1a8847ea43a4",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Big Bird Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced87cd5-8b88-4e09-8b12-3ad35ce88fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_BigBird_Masks(keras.layers.Layer):\n",
    "    def __init__(self, attention_block_size):\n",
    "        super(Create_BigBird_Masks, self).__init__()\n",
    "            \n",
    "        self.mask_layer = BigBird.BigBirdMasks(block_size=attention_block_size)\n",
    "        \n",
    "    def call(self, one_batch):\n",
    "\n",
    "        mask = tf.ones(tf.shape(one_batch)[:-1])\n",
    "                       \n",
    "        masks = self.mask_layer(one_batch, mask)      \n",
    "        \n",
    "        return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if reuse_length > 0:\n",
    "            current_state = current_state[:, :reuse_length, :]\n",
    "\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 hidden_size,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 norm_epsilon=1e-12,\n",
    "                 inner_activation=\"relu\",\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 inner_dropout=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__(**kwargs)\n",
    "        self._vocab_size = vocab_size\n",
    "        self._num_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._inner_size = inner_size\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._inner_activation = inner_activation\n",
    "        self._norm_epsilon = norm_epsilon\n",
    "        self._kernel_initializer = kernel_initializer\n",
    "        self._inner_dropout = inner_dropout\n",
    "        self._attention_layer_type = BigBird.BigBirdAttention\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape\n",
    "        input_tensor_shape = tf.TensorShape(input_tensor)\n",
    "        if len(input_tensor_shape.as_list()) != 3:\n",
    "            raise ValueError(\"TransformerLayer expects a three-dimensional input of \"\n",
    "                                             \"shape [batch, sequence, width].\")\n",
    "        batch_size, sequence_length, hidden_size = input_tensor_shape\n",
    "\n",
    "        if len(input_shape) == 2:\n",
    "            mask_tensor_shape = tf.TensorShape(input_shape[1])\n",
    "            expected_mask_tensor_shape = tf.TensorShape(\n",
    "                    [batch_size, sequence_length, sequence_length])\n",
    "            if not expected_mask_tensor_shape.is_compatible_with(mask_tensor_shape):\n",
    "                raise ValueError(\"When passing a mask tensor to TransformerXLBlock, \"\n",
    "                                                 \"the mask tensor must be of shape [batch, \"\n",
    "                                                 \"sequence_length, sequence_length] (here %s). Got a \"\n",
    "                                                 \"mask tensor of shape %s.\" %\n",
    "                                                 (expected_mask_tensor_shape, mask_tensor_shape))\n",
    "        if hidden_size % self._num_heads != 0:\n",
    "            raise ValueError(\n",
    "                    \"The input size (%d) is not a multiple of the number of attention \"\n",
    "                    \"heads (%d)\" % (hidden_size, self._num_heads))\n",
    "            \n",
    "\n",
    "        self._attention_layer = self._attention_layer_type(num_heads=8,key_dim=32, num_rand_blocks=8,from_block_size=8,to_block_size=8,max_rand_mask_length=set_len)\n",
    "        \n",
    "        self._attention_dropout = tf.keras.layers.Dropout(\n",
    "                rate=self._attention_dropout_rate)\n",
    "        self._attention_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"self_attention_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon,\n",
    "                dtype=tf.float32)\n",
    "        self._inner_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, self._inner_size),\n",
    "                bias_axes=\"d\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer),\n",
    "                name=\"inner\")\n",
    "\n",
    "        self._inner_activation_layer = tf.keras.layers.Activation(\n",
    "                self._inner_activation)\n",
    "        self._inner_dropout_layer = tf.keras.layers.Dropout(\n",
    "                rate=self._inner_dropout)\n",
    "        self._output_dense = tf.keras.layers.experimental.EinsumDense(\n",
    "                \"abc,cd->abd\",\n",
    "                output_shape=(None, hidden_size),\n",
    "                bias_axes=\"d\",\n",
    "                name=\"output\",\n",
    "                kernel_initializer=clone_initializer(self._kernel_initializer))\n",
    "        self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "        self._output_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "                name=\"output_layer_norm\",\n",
    "                axis=-1,\n",
    "                epsilon=self._norm_epsilon)\n",
    "\n",
    "        super(TransformerXLBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             mask = None,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        attention_kwargs = dict(\n",
    "                query=content_stream,\n",
    "                value=content_stream,\n",
    "                key=content_stream,\n",
    "                state = None,\n",
    "                attention_mask=mask)\n",
    "\n",
    "        attention_output = self._attention_layer(**attention_kwargs)\n",
    "        \n",
    "        attention_stream = attention_output\n",
    "        input_stream = content_stream\n",
    "        attention_key = \"content_attention\"\n",
    "        attention_output = {}\n",
    "        \n",
    "        attention_stream = self._attention_dropout(attention_stream)\n",
    "        attention_stream = self._attention_layer_norm(attention_stream + input_stream)\n",
    "        inner_output = self._inner_dense(attention_stream)\n",
    "        inner_output = self._inner_activation_layer(\n",
    "                inner_output)\n",
    "        inner_output = self._inner_dropout_layer(\n",
    "                inner_output)\n",
    "        layer_output = self._output_dense(inner_output)\n",
    "        layer_output = self._output_dropout(layer_output)\n",
    "        layer_output = self._output_layer_norm(layer_output + attention_stream)\n",
    "        attention_output[attention_key] = layer_output\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 hidden_size,\n",
    "                 maxlen,\n",
    "                 embed_dim,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 initializer,\n",
    "                 tie_attention_biases=True,\n",
    "                 memory_length=None,\n",
    "                 reuse_length=None,\n",
    "                 inner_activation=\"relu\",\n",
    "                 **kwargs):\n",
    "        super(TransformerXL, self).__init__(**kwargs)\n",
    "\n",
    "        self._vocab_size = vocab_size\n",
    "        self._initializer = initializer\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._num_attention_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._inner_size = inner_size\n",
    "        self._inner_activation = inner_activation\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._tie_attention_biases = tie_attention_biases\n",
    "\n",
    "        self._memory_length = memory_length\n",
    "        self._reuse_length = reuse_length\n",
    "\n",
    "        if self._tie_attention_biases:\n",
    "            attention_bias_shape = [self._num_attention_heads, self._head_size]\n",
    "        else:\n",
    "            attention_bias_shape = [self._num_layers, self._num_attention_heads, self._head_size]\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        \n",
    "        for i in range(self._num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(\n",
    "                            vocab_size=self._vocab_size,\n",
    "                            hidden_size=self._head_size * self._num_attention_heads,\n",
    "                            num_attention_heads=self._num_attention_heads,\n",
    "                            head_size=self._head_size,\n",
    "                            inner_size=self._inner_size,\n",
    "                            dropout_rate=self._dropout_rate,\n",
    "                            attention_dropout_rate=self._attention_dropout_rate,\n",
    "                            norm_epsilon=1e-12,\n",
    "                            inner_activation=self._inner_activation,\n",
    "                            kernel_initializer=\"variance_scaling\",\n",
    "                            name=\"layer_%d\" % i))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             relative_position_encoding,\n",
    "             mask, \n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        if state is None:\n",
    "            state = [None] * self._num_layers\n",
    "        for i in range(self._num_layers):\n",
    "            # cache new mems\n",
    "            new_mems.append(_cache_memory(content_stream, state[i], self._memory_length, self._reuse_length))\n",
    "\n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(\n",
    "                    content_stream=content_stream,\n",
    "                    mask=mask,\n",
    "                    relative_position_encoding=relative_position_encoding,\n",
    "                    state=state[i],\n",
    "                    content_attention_mask=content_attention_mask,\n",
    "                    query_attention_mask=query_attention_mask,\n",
    "                    target_mapping=target_mapping)\n",
    "            content_stream = transformer_xl_output[\"content_attention\"]\n",
    "\n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, attention_block_size, max_files, encoder, block_size, seq_len_padded, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.seq_len_padded = seq_len_padded\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxlen = maxlen\n",
    "        self.memory_length = memory_length\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.isabs = []\n",
    "        \n",
    "        self.mask_layer = Create_BigBird_Masks(attention_block_size)\n",
    "            \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(self.embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(\n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                maxlen=maxlen,\n",
    "                embed_dim=embed_dim,\n",
    "                memory_length=memory_length,\n",
    "                reuse_length=reuse_length,\n",
    "                head_size=head_size,\n",
    "                inner_size=inner_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                attention_dropout_rate=attention_dropout_rate,\n",
    "                initializer=initializer, \n",
    "            )\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=True,pre_layernorm=True, use_keras_mha=True,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    "\n",
    "        #mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.memory_length, self.embed_dim))\n",
    "        \n",
    "        embeddings = self.embedding_layer(x)\n",
    "            \n",
    "        linear_transform = self.linear_layer(embeddings)    \n",
    "        \n",
    "#         for i in range(0, self.seq_len_padded, self.block_size):\n",
    "            \n",
    "#             block = embeddings[:,i:i+self.block_size]\n",
    "            \n",
    "#             mask = self.mask_layer(block)\n",
    "            \n",
    "#             output, mems = self.transformer_xl(content_stream=block, mask=mask, relative_position_encoding=None, state=None)\n",
    "\n",
    "            \n",
    "        mask = self.mask_layer(embeddings)\n",
    "\n",
    "        output, mems = self.transformer_xl(content_stream=embeddings, mask=mask, relative_position_encoding=None, state=None)\n",
    "                \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c5f07-9b1f-4e57-9b7f-b50072830335",
   "metadata": {},
   "source": [
    "---\n",
    "# Attention Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4db7acd-d6d6-4a07-92a7-f13d312aa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_block_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters \n",
    "embed_dim = 8\n",
    "num_layers = 10\n",
    "hidden_size = 32\n",
    "num_attention_heads = 4\n",
    "memory_length = 200\n",
    "reuse_length = 0\n",
    "head_size = 8\n",
    "inner_size = 32\n",
    "dropout_rate = 0.01\n",
    "attention_dropout_rate = 0.01\n",
    "initializer = keras.initializers.RandomNormal(stddev=0.1) \n",
    "\n",
    "encoder = pretrained_encoder\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1c4ae1c-e48b-4a07-9635-a10235992544",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = dict(\n",
    "    embed_dim = 8,\n",
    "    num_layers = 10,\n",
    "    hidden_size = 32,\n",
    "    num_attention_heads = 4,\n",
    "    memory_length = 200,\n",
    "    reuse_length = 0,\n",
    "    head_size = 8,\n",
    "    inner_size = 32,\n",
    "    dropout_rate = 0.01,\n",
    "    attention_dropout_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13ccb499-5775-4d1d-9606-3cde222f28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkendragivens\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/TransformerXL/STR_XL/wandb/run-20220724_125127-170chj5v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kendragivens/Str_BigBird_Mha/runs/170chj5v\" target=\"_blank\">logical-river-5</a></strong> to <a href=\"https://wandb.ai/kendragivens/Str_BigBird_Mha\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Str_BigBird_Mha\", config=Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(attention_block_size, max_files, encoder, block_size, seq_len, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Nadam(1e-4), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362b312-29ec-44ca-9918-7dcc8caf3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "20/20 [==============================] - 155s 6s/step - loss: 3.9962 - sparse_categorical_accuracy: 0.0175 - val_loss: 4.0270 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658685252.0000 - _runtime: 165.0000\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9879 - sparse_categorical_accuracy: 0.0100 - val_loss: 3.9938 - val_sparse_categorical_accuracy: 0.0000e+00 - _timestamp: 1658685374.0000 - _runtime: 287.0000\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9659 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.9522 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685496.0000 - _runtime: 409.0000\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9094 - sparse_categorical_accuracy: 0.0100 - val_loss: 3.9471 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658685619.0000 - _runtime: 532.0000\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9514 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.9195 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658685741.0000 - _runtime: 654.0000\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9583 - sparse_categorical_accuracy: 0.0050 - val_loss: 3.9724 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658685864.0000 - _runtime: 777.0000\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9173 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.9693 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685986.0000 - _runtime: 899.0000\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.9248 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.8501 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658686108.0000 - _runtime: 1021.0000\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9262 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.9571 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686231.0000 - _runtime: 1144.0000\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9219 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9043 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686353.0000 - _runtime: 1266.0000\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8767 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.9343 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658686475.0000 - _runtime: 1388.0000\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8566 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8974 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658686597.0000 - _runtime: 1510.0000\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9257 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.9564 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658686720.0000 - _runtime: 1633.0000\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9064 - sparse_categorical_accuracy: 0.0150 - val_loss: 3.9395 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658686842.0000 - _runtime: 1755.0000\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8957 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.8786 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658686964.0000 - _runtime: 1877.0000\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8895 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.9065 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658687087.0000 - _runtime: 2000.0000\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.8717 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.7973 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658687209.0000 - _runtime: 2122.0000\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8750 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.9018 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658687332.0000 - _runtime: 2245.0000\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8771 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8825 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658687454.0000 - _runtime: 2367.0000\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8587 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8199 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658687576.0000 - _runtime: 2489.0000\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.9169 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.7750 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658687698.0000 - _runtime: 2611.0000\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.8758 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.7487 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658687821.0000 - _runtime: 2734.0000\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8315 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.8567 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687943.0000 - _runtime: 2856.0000\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8736 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8158 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658688065.0000 - _runtime: 2978.0000\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8595 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.8588 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658688188.0000 - _runtime: 3101.0000\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8299 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.8654 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688310.0000 - _runtime: 3223.0000\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8377 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.7801 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688432.0000 - _runtime: 3345.0000\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8560 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.8370 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658688555.0000 - _runtime: 3468.0000\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8156 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8523 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658688677.0000 - _runtime: 3590.0000\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8255 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.7857 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688799.0000 - _runtime: 3712.0000\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8139 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.8438 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688921.0000 - _runtime: 3834.0000\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8420 - sparse_categorical_accuracy: 0.0300 - val_loss: 3.8031 - val_sparse_categorical_accuracy: 0.0000e+00 - _timestamp: 1658689043.0000 - _runtime: 3956.0000\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.8096 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.7897 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658689165.0000 - _runtime: 4078.0000\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7696 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.7556 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658689287.0000 - _runtime: 4200.0000\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.7908 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.7000 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658689410.0000 - _runtime: 4323.0000\n",
      "Epoch 36/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7698 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.7689 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658689532.0000 - _runtime: 4445.0000\n",
      "Epoch 37/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7681 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.7246 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658689655.0000 - _runtime: 4568.0000\n",
      "Epoch 38/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7290 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.7999 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658689777.0000 - _runtime: 4690.0000\n",
      "Epoch 39/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7422 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.7330 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658689899.0000 - _runtime: 4812.0000\n",
      "Epoch 40/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7150 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.7529 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658690021.0000 - _runtime: 4934.0000\n",
      "Epoch 41/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7192 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.7323 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658690144.0000 - _runtime: 5057.0000\n",
      "Epoch 42/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7071 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.7885 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658690266.0000 - _runtime: 5179.0000\n",
      "Epoch 43/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7113 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.6466 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658690388.0000 - _runtime: 5301.0000\n",
      "Epoch 44/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7211 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.6930 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658690510.0000 - _runtime: 5423.0000\n",
      "Epoch 45/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7178 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.7791 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658690632.0000 - _runtime: 5545.0000\n",
      "Epoch 46/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6826 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.6269 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658690754.0000 - _runtime: 5667.0000\n",
      "Epoch 47/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6946 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.6607 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658690877.0000 - _runtime: 5790.0000\n",
      "Epoch 48/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.7153 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.7147 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658690999.0000 - _runtime: 5912.0000\n",
      "Epoch 49/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6732 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.6167 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658691121.0000 - _runtime: 6034.0000\n",
      "Epoch 50/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6563 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.6536 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658691244.0000 - _runtime: 6157.0000\n",
      "Epoch 51/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6881 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.6513 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658691366.0000 - _runtime: 6279.0000\n",
      "Epoch 52/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6764 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.6280 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658691488.0000 - _runtime: 6401.0000\n",
      "Epoch 53/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6423 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.7040 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658691610.0000 - _runtime: 6523.0000\n",
      "Epoch 54/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6590 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.6517 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658691732.0000 - _runtime: 6645.0000\n",
      "Epoch 55/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6549 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.5892 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658691854.0000 - _runtime: 6767.0000\n",
      "Epoch 56/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6121 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.6036 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658691977.0000 - _runtime: 6890.0000\n",
      "Epoch 57/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6173 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.6352 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658692099.0000 - _runtime: 7012.0000\n",
      "Epoch 58/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5891 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.6209 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692221.0000 - _runtime: 7134.0000\n",
      "Epoch 59/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6189 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.6410 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692343.0000 - _runtime: 7256.0000\n",
      "Epoch 60/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.6245 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.5818 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658692466.0000 - _runtime: 7379.0000\n",
      "Epoch 61/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.6129 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5560 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692588.0000 - _runtime: 7501.0000\n",
      "Epoch 62/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5982 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.5404 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692711.0000 - _runtime: 7624.0000\n",
      "Epoch 63/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5917 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.5458 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658692833.0000 - _runtime: 7746.0000\n",
      "Epoch 64/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5480 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.5459 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658692955.0000 - _runtime: 7868.0000\n",
      "Epoch 65/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5591 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.5268 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693077.0000 - _runtime: 7990.0000\n",
      "Epoch 66/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5683 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.5704 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658693200.0000 - _runtime: 8113.0000\n",
      "Epoch 67/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5379 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4681 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658693322.0000 - _runtime: 8235.0000\n",
      "Epoch 68/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5515 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.5059 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658693444.0000 - _runtime: 8357.0000\n",
      "Epoch 69/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5256 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.5040 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693566.0000 - _runtime: 8479.0000\n",
      "Epoch 70/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5202 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.6030 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658693689.0000 - _runtime: 8602.0000\n",
      "Epoch 71/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5348 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.5576 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693811.0000 - _runtime: 8724.0000\n",
      "Epoch 72/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4970 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4996 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658693933.0000 - _runtime: 8846.0000\n",
      "Epoch 73/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5177 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.5506 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658694055.0000 - _runtime: 8968.0000\n",
      "Epoch 74/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5322 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.5569 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658694178.0000 - _runtime: 9091.0000\n",
      "Epoch 75/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5097 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4766 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694300.0000 - _runtime: 9213.0000\n",
      "Epoch 76/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5050 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.4872 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658694422.0000 - _runtime: 9335.0000\n",
      "Epoch 77/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5041 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.5473 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658694545.0000 - _runtime: 9458.0000\n",
      "Epoch 78/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5160 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.5010 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694667.0000 - _runtime: 9580.0000\n",
      "Epoch 79/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.5132 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4661 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658694789.0000 - _runtime: 9702.0000\n",
      "Epoch 80/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4663 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.5397 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694912.0000 - _runtime: 9825.0000\n",
      "Epoch 81/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4804 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.4477 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658695034.0000 - _runtime: 9947.0000\n",
      "Epoch 82/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4829 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.4247 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658695156.0000 - _runtime: 10069.0000\n",
      "Epoch 83/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4721 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.4598 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658695279.0000 - _runtime: 10192.0000\n",
      "Epoch 84/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4308 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.4775 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658695401.0000 - _runtime: 10314.0000\n",
      "Epoch 85/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4410 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.4563 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658695523.0000 - _runtime: 10436.0000\n",
      "Epoch 86/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4173 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4699 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658695645.0000 - _runtime: 10558.0000\n",
      "Epoch 87/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4568 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.4364 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658695767.0000 - _runtime: 10680.0000\n",
      "Epoch 88/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3942 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.4218 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658695889.0000 - _runtime: 10802.0000\n",
      "Epoch 89/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4273 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.4001 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658696012.0000 - _runtime: 10925.0000\n",
      "Epoch 90/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4372 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.4134 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658696134.0000 - _runtime: 11047.0000\n",
      "Epoch 91/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4328 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.5141 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658696256.0000 - _runtime: 11169.0000\n",
      "Epoch 92/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4012 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3962 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658696378.0000 - _runtime: 11291.0000\n",
      "Epoch 93/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4322 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.4297 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658696501.0000 - _runtime: 11414.0000\n",
      "Epoch 94/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4049 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.3854 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658696623.0000 - _runtime: 11536.0000\n",
      "Epoch 95/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4146 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.4721 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658696745.0000 - _runtime: 11658.0000\n",
      "Epoch 96/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.4278 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.4543 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658696867.0000 - _runtime: 11780.0000\n",
      "Epoch 97/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.3873 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3227 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658696990.0000 - _runtime: 11903.0000\n",
      "Epoch 98/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3740 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3586 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697112.0000 - _runtime: 12025.0000\n",
      "Epoch 99/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3894 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3975 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658697234.0000 - _runtime: 12147.0000\n",
      "Epoch 100/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3594 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3469 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697356.0000 - _runtime: 12269.0000\n",
      "Epoch 101/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3605 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.3495 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697478.0000 - _runtime: 12391.0000\n",
      "Epoch 102/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3652 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3683 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658697601.0000 - _runtime: 12514.0000\n",
      "Epoch 103/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3565 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.3770 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658697723.0000 - _runtime: 12636.0000\n",
      "Epoch 104/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3562 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.3690 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658697845.0000 - _runtime: 12758.0000\n",
      "Epoch 105/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3577 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2939 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658697967.0000 - _runtime: 12880.0000\n",
      "Epoch 106/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3419 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.3436 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658698089.0000 - _runtime: 13002.0000\n",
      "Epoch 107/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3543 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.3138 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658698211.0000 - _runtime: 13124.0000\n",
      "Epoch 108/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3449 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3308 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658698334.0000 - _runtime: 13247.0000\n",
      "Epoch 109/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3404 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3162 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658698456.0000 - _runtime: 13369.0000\n",
      "Epoch 110/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3476 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3039 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658698578.0000 - _runtime: 13491.0000\n",
      "Epoch 111/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3467 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2768 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658698700.0000 - _runtime: 13613.0000\n",
      "Epoch 112/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3457 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3546 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658698822.0000 - _runtime: 13735.0000\n",
      "Epoch 113/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3460 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.2798 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658698944.0000 - _runtime: 13857.0000\n",
      "Epoch 114/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2999 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.3075 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658699066.0000 - _runtime: 13979.0000\n",
      "Epoch 115/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3083 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2749 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658699188.0000 - _runtime: 14101.0000\n",
      "Epoch 116/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3218 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2877 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658699311.0000 - _runtime: 14224.0000\n",
      "Epoch 117/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3253 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658699433.0000 - _runtime: 14346.0000\n",
      "Epoch 118/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2885 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.3258 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658699555.0000 - _runtime: 14468.0000\n",
      "Epoch 119/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3167 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3065 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658699678.0000 - _runtime: 14591.0000\n",
      "Epoch 120/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2804 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.3074 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658699800.0000 - _runtime: 14713.0000\n",
      "Epoch 121/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.3018 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2679 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658699922.0000 - _runtime: 14835.0000\n",
      "Epoch 122/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2882 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3299 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658700044.0000 - _runtime: 14957.0000\n",
      "Epoch 123/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2941 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.2907 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658700166.0000 - _runtime: 15079.0000\n",
      "Epoch 124/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2818 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2940 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658700288.0000 - _runtime: 15201.0000\n",
      "Epoch 125/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2929 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.2758 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658700410.0000 - _runtime: 15323.0000\n",
      "Epoch 126/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2911 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2227 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658700533.0000 - _runtime: 15446.0000\n",
      "Epoch 127/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2863 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2486 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658700655.0000 - _runtime: 15568.0000\n",
      "Epoch 128/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2734 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2466 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658700777.0000 - _runtime: 15690.0000\n",
      "Epoch 129/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2404 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.3107 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658700899.0000 - _runtime: 15812.0000\n",
      "Epoch 130/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2609 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2358 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658701021.0000 - _runtime: 15934.0000\n",
      "Epoch 131/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2455 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2646 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658701143.0000 - _runtime: 16056.0000\n",
      "Epoch 132/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2570 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.2362 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658701266.0000 - _runtime: 16179.0000\n",
      "Epoch 133/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2835 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2029 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658701388.0000 - _runtime: 16301.0000\n",
      "Epoch 134/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2507 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2006 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658701510.0000 - _runtime: 16423.0000\n",
      "Epoch 135/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2598 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2299 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658701633.0000 - _runtime: 16546.0000\n",
      "Epoch 136/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2535 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2095 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658701755.0000 - _runtime: 16668.0000\n",
      "Epoch 137/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2495 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2810 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658701877.0000 - _runtime: 16790.0000\n",
      "Epoch 138/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2378 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.2423 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658701999.0000 - _runtime: 16912.0000\n",
      "Epoch 139/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2326 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2082 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658702121.0000 - _runtime: 17034.0000\n",
      "Epoch 140/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2058 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.2472 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658702244.0000 - _runtime: 17157.0000\n",
      "Epoch 141/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.2276 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1413 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658702366.0000 - _runtime: 17279.0000\n",
      "Epoch 142/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2126 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1564 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658702488.0000 - _runtime: 17401.0000\n",
      "Epoch 143/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2377 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2008 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658702610.0000 - _runtime: 17523.0000\n",
      "Epoch 144/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2332 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.2056 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658702733.0000 - _runtime: 17646.0000\n",
      "Epoch 145/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1914 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.2357 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658702855.0000 - _runtime: 17768.0000\n",
      "Epoch 146/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2192 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.2302 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658702977.0000 - _runtime: 17890.0000\n",
      "Epoch 147/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2189 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1825 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658703099.0000 - _runtime: 18012.0000\n",
      "Epoch 148/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2031 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1910 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658703222.0000 - _runtime: 18135.0000\n",
      "Epoch 149/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1930 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.1378 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703344.0000 - _runtime: 18257.0000\n",
      "Epoch 150/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1930 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1281 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658703466.0000 - _runtime: 18379.0000\n",
      "Epoch 151/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2114 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2334 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658703589.0000 - _runtime: 18502.0000\n",
      "Epoch 152/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.2046 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2581 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658703711.0000 - _runtime: 18624.0000\n",
      "Epoch 153/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1797 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.2426 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658703834.0000 - _runtime: 18747.0000\n",
      "Epoch 154/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1933 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.2182 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658703956.0000 - _runtime: 18869.0000\n",
      "Epoch 155/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1761 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1814 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704078.0000 - _runtime: 18991.0000\n",
      "Epoch 156/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1670 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.2043 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704200.0000 - _runtime: 19113.0000\n",
      "Epoch 157/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.1805 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1227 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658704323.0000 - _runtime: 19236.0000\n",
      "Epoch 158/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1821 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.1729 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658704446.0000 - _runtime: 19359.0000\n",
      "Epoch 159/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1591 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1489 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658704568.0000 - _runtime: 19481.0000\n",
      "Epoch 160/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1793 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.2091 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658704691.0000 - _runtime: 19604.0000\n",
      "Epoch 161/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1446 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.2049 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658704813.0000 - _runtime: 19726.0000\n",
      "Epoch 162/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1466 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1628 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658704935.0000 - _runtime: 19848.0000\n",
      "Epoch 163/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1388 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1555 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658705058.0000 - _runtime: 19971.0000\n",
      "Epoch 164/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1499 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1314 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658705180.0000 - _runtime: 20093.0000\n",
      "Epoch 165/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1514 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1801 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658705302.0000 - _runtime: 20215.0000\n",
      "Epoch 166/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1744 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1820 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705424.0000 - _runtime: 20337.0000\n",
      "Epoch 167/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1282 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.1503 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658705547.0000 - _runtime: 20460.0000\n",
      "Epoch 168/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1154 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.1865 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658705669.0000 - _runtime: 20582.0000\n",
      "Epoch 169/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1534 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1985 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705792.0000 - _runtime: 20705.0000\n",
      "Epoch 170/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1497 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.1921 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658705914.0000 - _runtime: 20827.0000\n",
      "Epoch 171/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1004 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.1393 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658706036.0000 - _runtime: 20949.0000\n",
      "Epoch 172/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.1273 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1120 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658706158.0000 - _runtime: 21071.0000\n",
      "Epoch 173/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1156 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0824 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658706281.0000 - _runtime: 21194.0000\n",
      "Epoch 174/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1333 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.1707 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658706403.0000 - _runtime: 21316.0000\n",
      "Epoch 175/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1074 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1220 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658706526.0000 - _runtime: 21439.0000\n",
      "Epoch 176/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1008 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1250 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658706648.0000 - _runtime: 21561.0000\n",
      "Epoch 177/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1130 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.1171 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658706770.0000 - _runtime: 21683.0000\n",
      "Epoch 178/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1096 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.1270 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658706892.0000 - _runtime: 21805.0000\n",
      "Epoch 179/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1130 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.1592 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658707015.0000 - _runtime: 21928.0000\n",
      "Epoch 180/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1106 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0771 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658707137.0000 - _runtime: 22050.0000\n",
      "Epoch 181/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1169 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.1354 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658707259.0000 - _runtime: 22172.0000\n",
      "Epoch 182/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0973 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.1329 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658707381.0000 - _runtime: 22294.0000\n",
      "Epoch 183/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0809 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0942 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658707504.0000 - _runtime: 22417.0000\n",
      "Epoch 184/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0887 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0809 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658707626.0000 - _runtime: 22539.0000\n",
      "Epoch 185/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0973 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0822 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658707748.0000 - _runtime: 22661.0000\n",
      "Epoch 186/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0681 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0545 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658707870.0000 - _runtime: 22783.0000\n",
      "Epoch 187/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0700 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.0427 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658707993.0000 - _runtime: 22906.0000\n",
      "Epoch 188/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.1011 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0405 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658708115.0000 - _runtime: 23028.0000\n",
      "Epoch 189/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0957 - sparse_categorical_accuracy: 0.1400 - val_loss: 3.0686 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658708238.0000 - _runtime: 23151.0000\n",
      "Epoch 190/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0850 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0983 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658708360.0000 - _runtime: 23273.0000\n",
      "Epoch 191/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0589 - sparse_categorical_accuracy: 0.1575 - val_loss: 3.0362 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658708482.0000 - _runtime: 23395.0000\n",
      "Epoch 192/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0554 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0853 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658708604.0000 - _runtime: 23517.0000\n",
      "Epoch 193/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0447 - sparse_categorical_accuracy: 0.1750 - val_loss: 3.0667 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658708727.0000 - _runtime: 23640.0000\n",
      "Epoch 194/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0690 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0596 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658708849.0000 - _runtime: 23762.0000\n",
      "Epoch 195/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0749 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0685 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658708971.0000 - _runtime: 23884.0000\n",
      "Epoch 196/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0427 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0861 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658709093.0000 - _runtime: 24006.0000\n",
      "Epoch 197/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0408 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0636 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658709215.0000 - _runtime: 24128.0000\n",
      "Epoch 198/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0400 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.0729 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658709337.0000 - _runtime: 24250.0000\n",
      "Epoch 199/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0787 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0652 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658709459.0000 - _runtime: 24372.0000\n",
      "Epoch 200/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0471 - sparse_categorical_accuracy: 0.1600 - val_loss: 3.0849 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658709582.0000 - _runtime: 24495.0000\n",
      "Epoch 201/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 3.0307 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.0143 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658709704.0000 - _runtime: 24617.0000\n",
      "Epoch 202/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0290 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0785 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658709826.0000 - _runtime: 24739.0000\n",
      "Epoch 203/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0169 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0437 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658709949.0000 - _runtime: 24862.0000\n",
      "Epoch 204/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0419 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.0242 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658710071.0000 - _runtime: 24984.0000\n",
      "Epoch 205/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0339 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0149 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658710193.0000 - _runtime: 25106.0000\n",
      "Epoch 206/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0447 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0833 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658710315.0000 - _runtime: 25228.0000\n",
      "Epoch 207/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0215 - sparse_categorical_accuracy: 0.1825 - val_loss: 2.9814 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658710437.0000 - _runtime: 25350.0000\n",
      "Epoch 208/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0472 - sparse_categorical_accuracy: 0.1225 - val_loss: 2.9886 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658710560.0000 - _runtime: 25473.0000\n",
      "Epoch 209/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9935 - sparse_categorical_accuracy: 0.1650 - val_loss: 3.0100 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658710682.0000 - _runtime: 25595.0000\n",
      "Epoch 210/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0363 - sparse_categorical_accuracy: 0.1125 - val_loss: 2.9951 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658710804.0000 - _runtime: 25717.0000\n",
      "Epoch 211/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0361 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0110 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658710926.0000 - _runtime: 25839.0000\n",
      "Epoch 212/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0281 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0672 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658711048.0000 - _runtime: 25961.0000\n",
      "Epoch 213/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0073 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9704 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658711170.0000 - _runtime: 26083.0000\n",
      "Epoch 214/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0306 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0506 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658711293.0000 - _runtime: 26206.0000\n",
      "Epoch 215/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0257 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.0554 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658711415.0000 - _runtime: 26328.0000\n",
      "Epoch 216/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0262 - sparse_categorical_accuracy: 0.1375 - val_loss: 3.0292 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658711537.0000 - _runtime: 26450.0000\n",
      "Epoch 217/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9899 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.9974 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658711660.0000 - _runtime: 26573.0000\n",
      "Epoch 218/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0281 - sparse_categorical_accuracy: 0.1200 - val_loss: 2.9697 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658711782.0000 - _runtime: 26695.0000\n",
      "Epoch 219/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0122 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9941 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658711905.0000 - _runtime: 26818.0000\n",
      "Epoch 220/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9954 - sparse_categorical_accuracy: 0.1825 - val_loss: 3.0399 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658712027.0000 - _runtime: 26940.0000\n",
      "Epoch 221/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0395 - sparse_categorical_accuracy: 0.1050 - val_loss: 2.9816 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658712149.0000 - _runtime: 27062.0000\n",
      "Epoch 222/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9833 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0314 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658712271.0000 - _runtime: 27184.0000\n",
      "Epoch 223/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9519 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.0108 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658712393.0000 - _runtime: 27306.0000\n",
      "Epoch 224/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9907 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9818 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658712515.0000 - _runtime: 27428.0000\n",
      "Epoch 225/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9496 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.9966 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658712638.0000 - _runtime: 27551.0000\n",
      "Epoch 226/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 3.0000 - sparse_categorical_accuracy: 0.1550 - val_loss: 3.0018 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658712760.0000 - _runtime: 27673.0000\n",
      "Epoch 227/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9875 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0778 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658712882.0000 - _runtime: 27795.0000\n",
      "Epoch 228/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9840 - sparse_categorical_accuracy: 0.1400 - val_loss: 2.9786 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658713004.0000 - _runtime: 27917.0000\n",
      "Epoch 229/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9793 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0204 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658713126.0000 - _runtime: 28039.0000\n",
      "Epoch 230/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9361 - sparse_categorical_accuracy: 0.1850 - val_loss: 3.0002 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658713249.0000 - _runtime: 28162.0000\n",
      "Epoch 231/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 2.9717 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.9018 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658713371.0000 - _runtime: 28284.0000\n",
      "Epoch 232/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9971 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9476 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658713494.0000 - _runtime: 28407.0000\n",
      "Epoch 233/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9827 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9698 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658713616.0000 - _runtime: 28529.0000\n",
      "Epoch 234/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9546 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0628 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658713738.0000 - _runtime: 28651.0000\n",
      "Epoch 235/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9404 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9850 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658713860.0000 - _runtime: 28773.0000\n",
      "Epoch 236/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9561 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0304 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658713982.0000 - _runtime: 28895.0000\n",
      "Epoch 237/10000\n",
      "20/20 [==============================] - 123s 6s/step - loss: 2.9526 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.9585 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658714105.0000 - _runtime: 29018.0000\n",
      "Epoch 238/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9686 - sparse_categorical_accuracy: 0.1475 - val_loss: 3.0546 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658714227.0000 - _runtime: 29140.0000\n",
      "Epoch 239/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9333 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9587 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658714349.0000 - _runtime: 29262.0000\n",
      "Epoch 240/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9642 - sparse_categorical_accuracy: 0.1300 - val_loss: 2.9229 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658714471.0000 - _runtime: 29384.0000\n",
      "Epoch 241/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9416 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.0019 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658714593.0000 - _runtime: 29506.0000\n",
      "Epoch 242/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9349 - sparse_categorical_accuracy: 0.1700 - val_loss: 3.0776 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658714715.0000 - _runtime: 29628.0000\n",
      "Epoch 243/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9717 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9949 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658714837.0000 - _runtime: 29750.0000\n",
      "Epoch 244/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9246 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.0100 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658714960.0000 - _runtime: 29873.0000\n",
      "Epoch 245/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9440 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.9541 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658715082.0000 - _runtime: 29995.0000\n",
      "Epoch 246/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9461 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.8707 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658715204.0000 - _runtime: 30117.0000\n",
      "Epoch 247/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9351 - sparse_categorical_accuracy: 0.1475 - val_loss: 2.9562 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658715326.0000 - _runtime: 30239.0000\n",
      "Epoch 248/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9480 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.8896 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658715449.0000 - _runtime: 30362.0000\n",
      "Epoch 249/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9080 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9419 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658715571.0000 - _runtime: 30484.0000\n",
      "Epoch 250/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9441 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.8871 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658715693.0000 - _runtime: 30606.0000\n",
      "Epoch 251/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8959 - sparse_categorical_accuracy: 0.1800 - val_loss: 3.0570 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658715815.0000 - _runtime: 30728.0000\n",
      "Epoch 252/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8935 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.9109 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658715937.0000 - _runtime: 30850.0000\n",
      "Epoch 253/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8993 - sparse_categorical_accuracy: 0.1800 - val_loss: 2.8979 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658716059.0000 - _runtime: 30972.0000\n",
      "Epoch 254/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9203 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9244 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658716181.0000 - _runtime: 31094.0000\n",
      "Epoch 255/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9175 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9373 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658716303.0000 - _runtime: 31216.0000\n",
      "Epoch 256/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9335 - sparse_categorical_accuracy: 0.1350 - val_loss: 2.9032 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658716426.0000 - _runtime: 31339.0000\n",
      "Epoch 257/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9239 - sparse_categorical_accuracy: 0.1450 - val_loss: 2.9007 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658716548.0000 - _runtime: 31461.0000\n",
      "Epoch 258/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9086 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9541 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658716670.0000 - _runtime: 31583.0000\n",
      "Epoch 259/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9109 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9285 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658716792.0000 - _runtime: 31705.0000\n",
      "Epoch 260/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9363 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9842 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658716915.0000 - _runtime: 31828.0000\n",
      "Epoch 261/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8784 - sparse_categorical_accuracy: 0.1925 - val_loss: 2.9591 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658717037.0000 - _runtime: 31950.0000\n",
      "Epoch 262/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8872 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9561 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658717159.0000 - _runtime: 32072.0000\n",
      "Epoch 263/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9067 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9109 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658717281.0000 - _runtime: 32194.0000\n",
      "Epoch 264/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8799 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.9341 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658717403.0000 - _runtime: 32316.0000\n",
      "Epoch 265/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9156 - sparse_categorical_accuracy: 0.1600 - val_loss: 2.9582 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658717526.0000 - _runtime: 32439.0000\n",
      "Epoch 266/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9063 - sparse_categorical_accuracy: 0.1575 - val_loss: 2.9929 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658717648.0000 - _runtime: 32561.0000\n",
      "Epoch 267/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9001 - sparse_categorical_accuracy: 0.1525 - val_loss: 2.9352 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658717771.0000 - _runtime: 32684.0000\n",
      "Epoch 268/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9002 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.9028 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658717893.0000 - _runtime: 32806.0000\n",
      "Epoch 269/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8398 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.9295 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658718015.0000 - _runtime: 32928.0000\n",
      "Epoch 270/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.9030 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9376 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658718138.0000 - _runtime: 33051.0000\n",
      "Epoch 271/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8516 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8917 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658718260.0000 - _runtime: 33173.0000\n",
      "Epoch 272/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8961 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.8042 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658718382.0000 - _runtime: 33295.0000\n",
      "Epoch 273/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8735 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.9341 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658718504.0000 - _runtime: 33417.0000\n",
      "Epoch 274/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8764 - sparse_categorical_accuracy: 0.1850 - val_loss: 2.9107 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658718626.0000 - _runtime: 33539.0000\n",
      "Epoch 275/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8925 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.8366 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658718749.0000 - _runtime: 33662.0000\n",
      "Epoch 276/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8639 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.8347 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658718871.0000 - _runtime: 33784.0000\n",
      "Epoch 277/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8439 - sparse_categorical_accuracy: 0.1625 - val_loss: 2.8668 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658718993.0000 - _runtime: 33906.0000\n",
      "Epoch 278/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8495 - sparse_categorical_accuracy: 0.1650 - val_loss: 2.9582 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658719115.0000 - _runtime: 34028.0000\n",
      "Epoch 279/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8672 - sparse_categorical_accuracy: 0.1800 - val_loss: 2.7907 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658719237.0000 - _runtime: 34150.0000\n",
      "Epoch 280/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8640 - sparse_categorical_accuracy: 0.1775 - val_loss: 2.8379 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658719360.0000 - _runtime: 34273.0000\n",
      "Epoch 281/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8559 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.8686 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658719482.0000 - _runtime: 34395.0000\n",
      "Epoch 282/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8655 - sparse_categorical_accuracy: 0.1725 - val_loss: 2.8782 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658719605.0000 - _runtime: 34518.0000\n",
      "Epoch 283/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8124 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.8175 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658719727.0000 - _runtime: 34640.0000\n",
      "Epoch 284/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8382 - sparse_categorical_accuracy: 0.1500 - val_loss: 2.9109 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658719849.0000 - _runtime: 34762.0000\n",
      "Epoch 285/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8521 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.8611 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658719971.0000 - _runtime: 34884.0000\n",
      "Epoch 286/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8476 - sparse_categorical_accuracy: 0.1975 - val_loss: 2.9466 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658720094.0000 - _runtime: 35007.0000\n",
      "Epoch 287/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8354 - sparse_categorical_accuracy: 0.1675 - val_loss: 2.8431 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658720216.0000 - _runtime: 35129.0000\n",
      "Epoch 288/10000\n",
      "20/20 [==============================] - 122s 6s/step - loss: 2.8166 - sparse_categorical_accuracy: 0.1875 - val_loss: 2.9859 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658720338.0000 - _runtime: 35251.0000\n",
      "Epoch 289/10000\n",
      " 3/20 [===>..........................] - ETA: 1:23 - loss: 2.8297 - sparse_categorical_accuracy: 0.2333"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1, callbacks=[wandb.keras.WandbCallback(save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756fbdb-98fe-4005-8afb-b9e987d7ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8caaa-0c58-44e3-ae73-7f97b97571eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820ca4f-23b3-4a42-978d-ef2c37ae54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_BigBird.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(dataset[3][0], dataset[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0feaa-ccf4-4352-bddc-728529531858",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.predict(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3f83-2d73-4c19-a50e-eb8a5c636edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ebaae-0583-4553-a957-7d1f45958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eef17b-b311-4277-9bb7-87f05d897473",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909efb30-b3da-43cd-a526-bd971ba15bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

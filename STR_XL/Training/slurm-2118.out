2023-05-06 20:19:51.354744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/klg6z/work/TransformerXL/STR_XL/Training/wandb/run-20230506_201957-voti6i7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-darkness-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kendragivens/StrXL_Compressed
wandb: üöÄ View run at https://wandb.ai/kendragivens/StrXL_Compressed/runs/voti6i7s
wandb: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... 
wandb: \ 1 of 420 files downloaded...wandb: | 21 of 420 files downloaded...wandb: / 46 of 420 files downloaded...wandb: - 61 of 420 files downloaded...wandb: \ 65 of 420 files downloaded...wandb: | 82 of 420 files downloaded...wandb: / 116 of 420 files downloaded...wandb: - 121 of 420 files downloaded...wandb: \ 129 of 420 files downloaded...wandb: | 133 of 420 files downloaded...wandb: / 160 of 420 files downloaded...wandb: - 166 of 420 files downloaded...wandb: \ 172 of 420 files downloaded...wandb: | 188 of 420 files downloaded...wandb: / 201 of 420 files downloaded...wandb: - 215 of 420 files downloaded...wandb: \ 231 of 420 files downloaded...wandb: | 245 of 420 files downloaded...wandb: / 253 of 420 files downloaded...wandb: - 278 of 420 files downloaded...wandb: \ 287 of 420 files downloaded...wandb: | 312 of 420 files downloaded...wandb: / 358 of 420 files downloaded...wandb: - 390 of 420 files downloaded...wandb: \ 395 of 420 files downloaded...wandb: | 411 of 420 files downloaded...wandb: / 419 of 420 files downloaded...wandb:   420 of 420 files downloaded.  
Done. 0:0:4.3
wandb:   5 of 5 files downloaded.  
WARNING:tensorflow:Gradients do not exist for variables ['Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/attention_output/bias:0', 'dense_20/kernel:0', 'dense_20/bias:0', 'dense_21/kernel:0', 'dense_21/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/attention_output/bias:0', 'dense_24/kernel:0', 'dense_24/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/attention_output/bias:0', 'dense_28/kernel:0', 'dense_28/bias:0', 'dense_29/kernel:0', 'dense_29/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/attention_output/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/attention_output/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/attention_output/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/attention_output/bias:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/attention_output/bias:0', 'dense_48/kernel:0', 'dense_48/bias:0', 'dense_49/kernel:0', 'dense_49/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
WARNING:tensorflow:Gradients do not exist for variables ['Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention/multi_head_attention_block/multi_head_attention_1/attention_output/bias:0', 'dense_20/kernel:0', 'dense_20/bias:0', 'dense_21/kernel:0', 'dense_21/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_1/multi_head_attention_block_1/multi_head_attention_3/attention_output/bias:0', 'dense_24/kernel:0', 'dense_24/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_2/multi_head_attention_block_2/multi_head_attention_5/attention_output/bias:0', 'dense_28/kernel:0', 'dense_28/bias:0', 'dense_29/kernel:0', 'dense_29/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_3/multi_head_attention_block_3/multi_head_attention_7/attention_output/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_4/multi_head_attention_block_4/multi_head_attention_9/attention_output/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_5/multi_head_attention_block_5/multi_head_attention_11/attention_output/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_6/multi_head_attention_block_6/multi_head_attention_13/attention_output/bias:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0', 'Seeds:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/query/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/query/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/key/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/key/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/value/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/value/bias:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/attention_output/kernel:0', 'xl_model/transformer_xl/pooling_by_multi_head_attention_7/multi_head_attention_block_7/multi_head_attention_15/attention_output/bias:0', 'dense_48/kernel:0', 'dense_48/bias:0', 'dense_49/kernel:0', 'dense_49/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
Using GPU Strategy. Selected GPUs: [0]
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley049-SB-100420_S188_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley056-NegCtrl_S195_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes44-PCRblank3_S45_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
 1/20 [>.............................] - ETA: 12:09 - loss: 5.6315 - sparse_categorical_accuracy: 0.0000e+00 2/20 [==>...........................] - ETA: 2:00 - loss: 5.5583 - sparse_categorical_accuracy: 0.0000e+00  3/20 [===>..........................] - ETA: 1:53 - loss: 5.5799 - sparse_categorical_accuracy: 0.0000e+00 4/20 [=====>........................] - ETA: 1:47 - loss: 5.5685 - sparse_categorical_accuracy: 0.0000e+00 5/20 [======>.......................] - ETA: 1:40 - loss: 5.5176 - sparse_categorical_accuracy: 0.0000e+00 6/20 [========>.....................] - ETA: 1:33 - loss: 5.4789 - sparse_categorical_accuracy: 0.0000e+00 7/20 [=========>....................] - ETA: 1:26 - loss: 5.4848 - sparse_categorical_accuracy: 0.0000e+00 8/20 [===========>..................] - ETA: 1:20 - loss: 5.4869 - sparse_categorical_accuracy: 0.0000e+00 9/20 [============>.................] - ETA: 1:13 - loss: 5.4780 - sparse_categorical_accuracy: 0.0000e+0010/20 [==============>...............] - ETA: 1:06 - loss: 5.4842 - sparse_categorical_accuracy: 0.0000e+0011/20 [===============>..............] - ETA: 1:00 - loss: 5.4747 - sparse_categorical_accuracy: 0.0000e+0012/20 [=================>............] - ETA: 53s - loss: 5.4835 - sparse_categorical_accuracy: 0.0000e+00 13/20 [==================>...........] - ETA: 46s - loss: 5.4945 - sparse_categorical_accuracy: 0.0000e+0014/20 [====================>.........] - ETA: 40s - loss: 5.4795 - sparse_categorical_accuracy: 0.0000e+0015/20 [=====================>........] - ETA: 33s - loss: 5.4704 - sparse_categorical_accuracy: 0.0000e+0016/20 [=======================>......] - ETA: 26s - loss: 5.4592 - sparse_categorical_accuracy: 0.0000e+0017/20 [========================>.....] - ETA: 20s - loss: 5.4607 - sparse_categorical_accuracy: 0.0029    18/20 [==========================>...] - ETA: 13s - loss: 5.4670 - sparse_categorical_accuracy: 0.002819/20 [===========================>..] - ETA: 6s - loss: 5.4559 - sparse_categorical_accuracy: 0.0053 20/20 [==============================] - ETA: 0s - loss: 5.4563 - sparse_categorical_accuracy: 0.005020/20 [==============================] - 210s 9s/step - loss: 5.4563 - sparse_categorical_accuracy: 0.0050 - val_loss: 5.5165 - val_sparse_categorical_accuracy: 0.0000e+00
Traceback (most recent call last):
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 135, in <module>
    sys.exit(tfu.scripting.boot(main, sys.argv))
  File "/home/klg6z/.local/lib/python3.10/site-packages/tf_utilities/scripting.py", line 106, in boot
    return job(*args, **kwargs) or 0
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 132, in main
    train(config, model_path)
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 118, in train
    model.save_weights(tfu.scripting.path_to(config.save_to.format(**config.__dict__)) + ".h5")
  File "/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py", line 161, in create_dataset
    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)
  File "/opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py", line 156, in make_new_dset
    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 87, in h5py.h5d.create
ValueError: Unable to create dataset (name already exists)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.005 MB of 7.857 MB uploaded (0.000 MB deduped)wandb: \ 7.857 MB of 7.857 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                           epoch ‚ñÅ
wandb:                            loss ‚ñÅ
wandb:     sparse_categorical_accuracy ‚ñÅ
wandb:                        val_loss ‚ñÅ
wandb: val_sparse_categorical_accuracy ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                      best_epoch 0
wandb:                   best_val_loss 5.51652
wandb:                           epoch 0
wandb:                            loss 5.45629
wandb:     sparse_categorical_accuracy 0.005
wandb:                        val_loss 5.51652
wandb: val_sparse_categorical_accuracy 0.0
wandb: 
wandb: üöÄ View run devout-darkness-50 at: https://wandb.ai/kendragivens/StrXL_Compressed/runs/voti6i7s
wandb: Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230506_201957-voti6i7s/logs

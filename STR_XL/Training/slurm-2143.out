2023-05-07 20:25:37.858967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-07 20:25:38.207878: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/klg6z/work/TransformerXL/STR_XL/Training/wandb/run-20230507_202543-ixmxf67g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-frog-61
wandb: â­ï¸ View project at https://wandb.ai/kendragivens/StrXL_Compressed
wandb: ðŸš€ View run at https://wandb.ai/kendragivens/StrXL_Compressed/runs/ixmxf67g
2023-05-07 20:25:52.228672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-07 20:25:54.350555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9632 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5
wandb: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... 
wandb: \ 1 of 420 files downloaded...wandb: | 53 of 420 files downloaded...wandb: / 64 of 420 files downloaded...wandb: - 65 of 420 files downloaded...wandb: \ 92 of 420 files downloaded...wandb: | 108 of 420 files downloaded...wandb: / 122 of 420 files downloaded...wandb: - 134 of 420 files downloaded...wandb: \ 142 of 420 files downloaded...wandb: | 160 of 420 files downloaded...wandb: / 170 of 420 files downloaded...wandb: - 173 of 420 files downloaded...wandb: \ 179 of 420 files downloaded...wandb: | 191 of 420 files downloaded...wandb: / 206 of 420 files downloaded...wandb: - 225 of 420 files downloaded...wandb: \ 233 of 420 files downloaded...wandb: | 252 of 420 files downloaded...wandb: / 267 of 420 files downloaded...wandb: - 290 of 420 files downloaded...wandb: \ 335 of 420 files downloaded...wandb: | 369 of 420 files downloaded...wandb: / 390 of 420 files downloaded...wandb: - 400 of 420 files downloaded...wandb: \ 414 of 420 files downloaded...wandb:   420 of 420 files downloaded.  
Done. 0:0:4.0
wandb:   5 of 5 files downloaded.  
2023-05-07 20:26:10.570241: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
op: "FlatMapDataset"
input: "TensorDataset/_1"
attr {
  key: "Targuments"
  value {
    list {
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: -2
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_Dataset_flat_map_flat_map_fn_70378"
    }
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020FlatMapDataset:1"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: -1
        }
        dim {
          size: -1
        }
        dim {
          size: -1
        }
      }
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: "output_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_INT32
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
['StrXL_Compressed_Training.py', '--dataset-artifact', 'sirdavidludwig/nachusa-dna/nachusa-dna:latest', '--encoder-artifact', 'sirdavidludwig/dnabert-pretrain/dnabert-pretrain-64dim:latest', '--wandb-project', 'StrXL_Compressed', '--save-to', 'StrXL_Compressed_{seed}_{mem_len}_{num_compressed_seeds}', '--mem_len', '250', '--compressed_len', '250', '--num_compressed_seeds', '50', '--num_induce', '0', '--gpus', '0', '--seed', '3', '--epochs', '750'] Namespace(gpus=[0], dataset_path=None, dataset_artifact='sirdavidludwig/nachusa-dna/nachusa-dna:latest', encoder_path=None, encoder_artifact='sirdavidludwig/dnabert-pretrain/dnabert-pretrain-64dim:latest', seed=3, mem_switched=False, num_compressed_seeds=50, compressed_len=250, block_size=250, max_set_len=1000, num_induce=0, embed_dim=64, num_layers=8, num_heads=8, mem_len=250, compressed_mem_len=250, dropout_rate=0.01, num_seeds=1, use_layernorm=True, pre_layernorm=True, use_keras_mha=True, set_len=1000, batches_per_epoch=20, validation_batch_size=5, save_to='StrXL_Compressed_{seed}_{mem_len}_{num_compressed_seeds}', batch_size=20, sub_batch_size=0, data_workers=1, run_eagerly=False, use_dynamic_memory=False, wandb_project='StrXL_Compressed', wandb_name=None, wandb_group=None, wandb_mode='online', resume=None, initial_epoch=0, epochs=750)
Using GPU Strategy. Selected GPUs: [0]
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley049-SB-100420_S188_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley056-NegCtrl_S195_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes44-PCRblank3_S45_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Epoch 1/750
 1/20 [>.............................] - ETA: 19:14 - loss: 5.6315 - sparse_categorical_accuracy: 0.0000e+00 2/20 [==>...........................] - ETA: 1:55 - loss: 5.5579 - sparse_categorical_accuracy: 0.0000e+00  3/20 [===>..........................] - ETA: 1:48 - loss: 5.5829 - sparse_categorical_accuracy: 0.0000e+00 4/20 [=====>........................] - ETA: 1:41 - loss: 5.5719 - sparse_categorical_accuracy: 0.0000e+00 5/20 [======>.......................] - ETA: 1:35 - loss: 5.5220 - sparse_categorical_accuracy: 0.0000e+00 6/20 [========>.....................] - ETA: 1:29 - loss: 5.4833 - sparse_categorical_accuracy: 0.0000e+00 7/20 [=========>....................] - ETA: 1:22 - loss: 5.4902 - sparse_categorical_accuracy: 0.0000e+00 8/20 [===========>..................] - ETA: 1:16 - loss: 5.4929 - sparse_categorical_accuracy: 0.0000e+00 9/20 [============>.................] - ETA: 1:10 - loss: 5.4838 - sparse_categorical_accuracy: 0.0000e+0010/20 [==============>...............] - ETA: 1:03 - loss: 5.4895 - sparse_categorical_accuracy: 0.0000e+0011/20 [===============>..............] - ETA: 57s - loss: 5.4790 - sparse_categorical_accuracy: 0.0000e+00 12/20 [=================>............] - ETA: 51s - loss: 5.4873 - sparse_categorical_accuracy: 0.0000e+0013/20 [==================>...........] - ETA: 44s - loss: 5.4966 - sparse_categorical_accuracy: 0.0000e+0014/20 [====================>.........] - ETA: 38s - loss: 5.4812 - sparse_categorical_accuracy: 0.0000e+0015/20 [=====================>........] - ETA: 31s - loss: 5.4717 - sparse_categorical_accuracy: 0.0000e+0016/20 [=======================>......] - ETA: 25s - loss: 5.4620 - sparse_categorical_accuracy: 0.0000e+0017/20 [========================>.....] - ETA: 19s - loss: 5.4642 - sparse_categorical_accuracy: 0.0029    18/20 [==========================>...] - ETA: 12s - loss: 5.4703 - sparse_categorical_accuracy: 0.002819/20 [===========================>..] - ETA: 6s - loss: 5.4608 - sparse_categorical_accuracy: 0.0026 20/20 [==============================] - ETA: 0s - loss: 5.4611 - sparse_categorical_accuracy: 0.00252023-05-07 20:29:12.706490: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_2"
op: "FlatMapDataset"
input: "TensorDataset/_1"
attr {
  key: "Targuments"
  value {
    list {
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: -2
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_Dataset_flat_map_flat_map_fn_173451"
    }
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\021FlatMapDataset:17"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: -1
        }
        dim {
          size: -1
        }
        dim {
          size: -1
        }
      }
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
attr {
  key: "output_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_INT32
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
20/20 [==============================] - 223s 9s/step - loss: 5.4611 - sparse_categorical_accuracy: 0.0025 - val_loss: 5.5106 - val_sparse_categorical_accuracy: 0.0100
Epoch 2/750
 1/20 [>.............................] - ETA: 2:03 - loss: 5.4113 - sparse_categorical_accuracy: 0.0000e+00 2/20 [==>...........................] - ETA: 1:54 - loss: 5.3313 - sparse_categorical_accuracy: 0.0250     3/20 [===>..........................] - ETA: 1:48 - loss: 5.4112 - sparse_categorical_accuracy: 0.0167 4/20 [=====>........................] - ETA: 1:42 - loss: 5.3881 - sparse_categorical_accuracy: 0.0125 5/20 [======>.......................] - ETA: 1:36 - loss: 5.3836 - sparse_categorical_accuracy: 0.0100 6/20 [========>.....................] - ETA: 1:29 - loss: 5.3720 - sparse_categorical_accuracy: 0.0083 7/20 [=========>....................] - ETA: 1:23 - loss: 5.3620 - sparse_categorical_accuracy: 0.0071 8/20 [===========>..................] - ETA: 1:16 - loss: 5.3658 - sparse_categorical_accuracy: 0.0063 9/20 [============>.................] - ETA: 1:10 - loss: 5.3471 - sparse_categorical_accuracy: 0.005610/20 [==============>...............] - ETA: 1:03 - loss: 5.3357 - sparse_categorical_accuracy: 0.005011/20 [===============>..............] - ETA: 57s - loss: 5.3608 - sparse_categorical_accuracy: 0.0045 12/20 [=================>............] - ETA: 51s - loss: 5.3610 - sparse_categorical_accuracy: 0.004213/20 [==================>...........] - ETA: 44s - loss: 5.3662 - sparse_categorical_accuracy: 0.003814/20 [====================>.........] - ETA: 38s - loss: 5.3642 - sparse_categorical_accuracy: 0.003615/20 [=====================>........] - ETA: 31s - loss: 5.3632 - sparse_categorical_accuracy: 0.003316/20 [=======================>......] - ETA: 25s - loss: 5.3784 - sparse_categorical_accuracy: 0.003117/20 [========================>.....] - ETA: 19s - loss: 5.3816 - sparse_categorical_accuracy: 0.002918/20 [==========================>...] - ETA: 12s - loss: 5.3676 - sparse_categorical_accuracy: 0.002819/20 [===========================>..] - ETA: 6s - loss: 5.3637 - sparse_categorical_accuracy: 0.0026 20/20 [==============================] - ETA: 0s - loss: 5.3527 - sparse_categorical_accuracy: 0.002520/20 [==============================] - 158s 8s/step - loss: 5.3527 - sparse_categorical_accuracy: 0.0025 - val_loss: 5.2538 - val_sparse_categorical_accuracy: 0.0200
Epoch 3/750
 1/20 [>.............................] - ETA: 2:04 - loss: 5.1213 - sparse_categorical_accuracy: 0.0000e+00 2/20 [==>...........................] - ETA: 1:54 - loss: 5.1735 - sparse_categorical_accuracy: 0.0250     3/20 [===>..........................] - ETA: 1:48 - loss: 5.1049 - sparse_categorical_accuracy: 0.0500 4/20 [=====>........................] - ETA: 1:42 - loss: 5.1308 - sparse_categorical_accuracy: 0.0375 5/20 [======>.......................] - ETA: 1:35 - loss: 5.1285 - sparse_categorical_accuracy: 0.0300 6/20 [========>.....................] - ETA: 1:29 - loss: 5.1746 - sparse_categorical_accuracy: 0.0333 7/20 [=========>....................] - ETA: 1:23 - loss: 5.1880 - sparse_categorical_accuracy: 0.0286 8/20 [===========>..................] - ETA: 1:16 - loss: 5.1879 - sparse_categorical_accuracy: 0.0250 9/20 [============>.................] - ETA: 1:10 - loss: 5.2098 - sparse_categorical_accuracy: 0.022210/20 [==============>...............] - ETA: 1:03 - loss: 5.1995 - sparse_categorical_accuracy: 0.020011/20 [===============>..............] - ETA: 57s - loss: 5.1779 - sparse_categorical_accuracy: 0.0227 12/20 [=================>............] - ETA: 51s - loss: 5.1563 - sparse_categorical_accuracy: 0.029213/20 [==================>...........] - ETA: 44s - loss: 5.1636 - sparse_categorical_accuracy: 0.026914/20 [====================>.........] - ETA: 38s - loss: 5.1587 - sparse_categorical_accuracy: 0.025015/20 [=====================>........] - ETA: 31s - loss: 5.1708 - sparse_categorical_accuracy: 0.023316/20 [=======================>......] - ETA: 25s - loss: 5.1686 - sparse_categorical_accuracy: 0.021917/20 [========================>.....] - ETA: 19s - loss: 5.1590 - sparse_categorical_accuracy: 0.0206
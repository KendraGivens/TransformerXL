2023-05-10 23:10:32.630180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/klg6z/work/TransformerXL/STR_XL/Training/wandb/run-20230510_231038-bmfdb0ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-lake-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kendragivens/StrXL_Compressed
wandb: üöÄ View run at https://wandb.ai/kendragivens/StrXL_Compressed/runs/bmfdb0ou
wandb: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... 
wandb: \ 1 of 420 files downloaded...wandb: | 61 of 420 files downloaded...wandb: / 65 of 420 files downloaded...wandb: - 79 of 420 files downloaded...wandb: \ 103 of 420 files downloaded...wandb: | 114 of 420 files downloaded...wandb: / 131 of 420 files downloaded...wandb: - 149 of 420 files downloaded...wandb: \ 166 of 420 files downloaded...wandb: | 174 of 420 files downloaded...wandb: / 177 of 420 files downloaded...wandb: - 185 of 420 files downloaded...wandb: \ 193 of 420 files downloaded...wandb: | 215 of 420 files downloaded...wandb: / 233 of 420 files downloaded...wandb: - 244 of 420 files downloaded...wandb: \ 258 of 420 files downloaded...wandb: | 267 of 420 files downloaded...wandb: / 272 of 420 files downloaded...wandb: - 304 of 420 files downloaded...wandb: \ 345 of 420 files downloaded...wandb: | 362 of 420 files downloaded...wandb: / 391 of 420 files downloaded...wandb: - 399 of 420 files downloaded...wandb: \ 414 of 420 files downloaded...wandb:   420 of 420 files downloaded.  
Done. 0:0:4.3
wandb:   5 of 5 files downloaded.  
Using GPU Strategy. Selected GPUs: [0]
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes44-PCRblank3_S45_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley056-NegCtrl_S195_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley049-SB-100420_S188_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Epoch 1/750
Traceback (most recent call last):
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 141, in <module>
    sys.exit(tfu.scripting.boot(main, sys.argv))
  File "/home/klg6z/.local/lib/python3.10/site-packages/tf_utilities/scripting.py", line 106, in boot
    return job(*args, **kwargs) or 0
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 138, in main
    train(config, model_path)
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 118, in train
    tfu.scripting.run_safely(model.fit, x=train_dataset, validation_data=val_dataset, epochs=config.epochs + config.initial_epoch, initial_epoch=tfu.scripting.initial_epoch(config), verbose=1, callbacks=[wandb_callback])
  File "/home/klg6z/.local/lib/python3.10/site-packages/tf_utilities/scripting.py", line 227, in run_safely
    return fn(*args, **kwargs)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/integration/keras/keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/integration/keras/keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/integration/keras/keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file8k4x7t3t.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/../Scripts/StrXL_Compressed.py", line 292, in train_step
    gradients = tape.gradient(loss+loss_compressed, trainable_vars)
RuntimeError: in user code:

    File "/opt/conda/lib/python3.10/site-packages/keras/engine/training.py", line 1160, in train_function  *
        return step_function(self, iterator)
    File "/opt/conda/lib/python3.10/site-packages/keras/engine/training.py", line 1146, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/opt/conda/lib/python3.10/site-packages/keras/engine/training.py", line 1135, in run_step  **
        outputs = model.train_step(data)
    File "/home/klg6z/work/TransformerXL/STR_XL/Training/../Scripts/StrXL_Compressed.py", line 292, in train_step
        gradients = tape.gradient(loss+loss_compressed, trainable_vars)

    RuntimeError: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)

wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: üöÄ View run fancy-lake-83 at: https://wandb.ai/kendragivens/StrXL_Compressed/runs/bmfdb0ou
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230510_231038-bmfdb0ou/logs
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 258, in check_network_status
    self._loop_check_status(
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 214, in _loop_check_status
    local_handle = request()
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 795, in deliver_network_status
    return self._deliver_network_status(status)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 601, in _deliver_network_status
    return self._deliver_record(record)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py", line 560, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/klg6z/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe

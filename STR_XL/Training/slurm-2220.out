2023-05-11 22:57:12.546459: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 22:57:12.893917: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
wandb: WARNING Tried to auto resume run with id 46fk3x51 but id ru5fte9s is set.
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/klg6z/work/TransformerXL/STR_XL/Training/wandb/run-20230511_225717-ru5fte9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run stellar-jazz-79
wandb: â­ï¸ View project at https://wandb.ai/kendragivens/StrXL_Compressed
wandb: ðŸš€ View run at https://wandb.ai/kendragivens/StrXL_Compressed/runs/ru5fte9s
2023-05-11 22:57:19.226597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 22:57:21.318456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9632 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5
wandb: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... 
wandb: \ 1 of 420 files downloaded...wandb: | 12 of 420 files downloaded...wandb: / 23 of 420 files downloaded...wandb: - 65 of 420 files downloaded...wandb: \ 85 of 420 files downloaded...wandb: | 116 of 420 files downloaded...wandb: / 124 of 420 files downloaded...wandb: - 128 of 420 files downloaded...wandb: \ 133 of 420 files downloaded...wandb: | 150 of 420 files downloaded...wandb: / 169 of 420 files downloaded...wandb: - 177 of 420 files downloaded...wandb: \ 183 of 420 files downloaded...wandb: | 197 of 420 files downloaded...wandb: / 217 of 420 files downloaded...wandb: - 221 of 420 files downloaded...wandb: \ 231 of 420 files downloaded...wandb: | 245 of 420 files downloaded...wandb: / 256 of 420 files downloaded...wandb: - 277 of 420 files downloaded...wandb: \ 293 of 420 files downloaded...wandb: | 320 of 420 files downloaded...wandb: / 356 of 420 files downloaded...wandb: - 385 of 420 files downloaded...wandb: \ 397 of 420 files downloaded...wandb: | 411 of 420 files downloaded...wandb:   420 of 420 files downloaded.  
Done. 0:0:3.9
wandb:   5 of 5 files downloaded.  
Restoring previous model...
750
Using GPU Strategy. Selected GPUs: [0]
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes44-PCRblank3_S45_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley049-SB-100420_S188_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley056-NegCtrl_S195_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Traceback (most recent call last):
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 141, in <module>
    sys.exit(tfu.scripting.boot(main, sys.argv))
  File "/home/klg6z/.local/lib/python3.10/site-packages/tf_utilities/scripting.py", line 106, in boot
    return job(*args, **kwargs) or 0
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 138, in main
    train(config, model_path)
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 104, in train
    model(train_dataset[0][0][:1])
  File "/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/../Scripts/StrXL_Compressed.py", line 322, in call
    output, mems, compressed, loss = self.transformer_xl(content_stream=block, state=mems, compressed=compressed)
ValueError: Exception encountered when calling layer "xl_model" "                 f"(type XlModel).

not enough values to unpack (expected 4, got 3)

Call arguments received by layer "xl_model" "                 f"(type XlModel):
  â€¢ x=tf.Tensor(shape=(1, 1000, 148), dtype=float32)
  â€¢ training=False
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)wandb: \ 0.000 MB of 11.936 MB uploaded (0.000 MB deduped)wandb: | 11.936 MB of 11.936 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb:                      best_epoch 749
wandb:                   best_val_loss 2.13757
wandb:                           epoch 749
wandb:                            loss 2.08757
wandb:     sparse_categorical_accuracy 0.355
wandb:                        val_loss 2.13757
wandb: val_sparse_categorical_accuracy 0.28
wandb: 
wandb: ðŸš€ View run stellar-jazz-79 at: https://wandb.ai/kendragivens/StrXL_Compressed/runs/ru5fte9s
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230511_225717-ru5fte9s/logs

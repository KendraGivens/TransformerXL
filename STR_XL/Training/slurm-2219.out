2023-05-11 22:56:15.543580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 22:56:15.880846: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
wandb: WARNING Tried to auto resume run with id bpt2uqye but id 46fk3x51 is set.
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/klg6z/work/TransformerXL/STR_XL/Training/wandb/run-20230511_225620-46fk3x51
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run graceful-sun-78
wandb: ⭐️ View project at https://wandb.ai/kendragivens/StrXL_Compressed
wandb: 🚀 View run at https://wandb.ai/kendragivens/StrXL_Compressed/runs/46fk3x51
2023-05-11 22:56:22.187154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-11 22:56:24.286946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9632 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5
wandb: Downloading large artifact nachusa-dna:latest, 4079.09MB. 420 files... 
wandb: \ 1 of 420 files downloaded...wandb: | 23 of 420 files downloaded...wandb: / 63 of 420 files downloaded...wandb: - 65 of 420 files downloaded...wandb: \ 87 of 420 files downloaded...wandb: | 107 of 420 files downloaded...wandb: / 129 of 420 files downloaded...wandb: - 133 of 420 files downloaded...wandb: \ 140 of 420 files downloaded...wandb: | 147 of 420 files downloaded...wandb: / 166 of 420 files downloaded...wandb: - 173 of 420 files downloaded...wandb: \ 179 of 420 files downloaded...wandb: | 187 of 420 files downloaded...wandb: / 211 of 420 files downloaded...wandb: - 228 of 420 files downloaded...wandb: \ 242 of 420 files downloaded...wandb: | 255 of 420 files downloaded...wandb: / 268 of 420 files downloaded...wandb: - 283 of 420 files downloaded...wandb: \ 303 of 420 files downloaded...wandb: | 323 of 420 files downloaded...wandb: / 354 of 420 files downloaded...wandb: - 384 of 420 files downloaded...wandb: \ 395 of 420 files downloaded...wandb: | 409 of 420 files downloaded...wandb: / 419 of 420 files downloaded...wandb:   420 of 420 files downloaded.  
Done. 0:0:4.0
wandb:   5 of 5 files downloaded.  
Restoring previous model...
750
Using GPU Strategy. Selected GPUs: [0]
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes44-PCRblank3_S45_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley056-NegCtrl_S195_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wes24-PCRblank2_S25_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Sample './artifacts/nachusa-dna:v0/Wesley049-SB-100420_S188_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.
Traceback (most recent call last):
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 141, in <module>
    sys.exit(tfu.scripting.boot(main, sys.argv))
  File "/home/klg6z/.local/lib/python3.10/site-packages/tf_utilities/scripting.py", line 106, in boot
    return job(*args, **kwargs) or 0
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 138, in main
    train(config, model_path)
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/StrXL_Compressed_Training.py", line 104, in train
    model(train_dataset[0][0][:1])
  File "/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/klg6z/work/TransformerXL/STR_XL/Training/../Scripts/StrXL_Compressed.py", line 322, in call
    output, mems, compressed, loss = self.transformer_xl(content_stream=block, state=mems, compressed=compressed)
ValueError: Exception encountered when calling layer "xl_model" "                 f"(type XlModel).

not enough values to unpack (expected 4, got 3)

Call arguments received by layer "xl_model" "                 f"(type XlModel):
  • x=tf.Tensor(shape=(1, 1000, 148), dtype=float32)
  • training=False
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run summary:
wandb:                      best_epoch 704
wandb:                   best_val_loss 2.10397
wandb:                           epoch 749
wandb:                            loss 2.43052
wandb:     sparse_categorical_accuracy 0.2225
wandb:                        val_loss 2.36014
wandb: val_sparse_categorical_accuracy 0.25
wandb: 
wandb: 🚀 View run graceful-sun-78 at: https://wandb.ai/kendragivens/StrXL_Compressed/runs/46fk3x51
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230511_225620-46fk3x51/logs

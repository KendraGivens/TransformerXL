{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccea5cd-89de-452b-afa6-703df9e9a604",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b9c98a-b4ee-4667-89a3-5f04549f7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7f311f7af6a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-8dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... Done. 0:0:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n",
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n"
     ]
    }
   ],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len, kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac0a881-4dc6-4916-a18c-8c59e026e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Apr2016_S84_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes5-5-CCE_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MR-Apr2016_S13_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Sep2015_S43_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley012-HN-051120_S151_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Sep2015_S91_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Sep2015_S52_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes26-8-AG_S27_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Jul2016_S22_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes25-8-MU_S26_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Oct2016_S63_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes3-5-TCR_S4_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-May2015_S160_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Oct2016_S80_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Jul2015_S74_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Sep2015_S35_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-CCW-Sep2015_S28_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Oct2016_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HF-Jul2015_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-May2015_S73_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Apr2016_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Apr2016_S85_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes20-8-HF_S21_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes38-10-WH_S39_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley047-SF-100420_S186_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley055-HAP-051120_S194_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley006-HLP-051220_S145_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes39-10-HF_S40_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-Jul2016_S38_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley035-HLP2-072820_S174_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes13-5-HLP_S14_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-May2015_S17_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley005-HF-051220_S144_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes47-10-FC_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-May2015_S152_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley045-HLP-100420_S184_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley033-MU-072820_S172_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley043-L-100420_S182_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes48-10-CCW_S49_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Sep2015_S44_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley010-HW-051120_S149_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes36-8-HW_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley011-Ag-051120_S150_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley027-HLP-072820_S166_L001_R1_001.db']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 200\n",
    "seq_len = set_len\n",
    "maxlen = set_len\n",
    "vocab_size = 5\n",
    "num_chars_data = set_len*sequence_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > seq_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(maxlen)\n",
    "print(vocab_size)\n",
    "print(num_chars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b66c98-f8b5-4b80-9736-66a9769cc966",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af4ac04-1eab-4d74-bfc0-716408efeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_initializer(initializer):\n",
    "    if isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer.__class__.from_config(initializer.get_config())\n",
    "    return initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if reuse_length > 0:\n",
    "            current_state = current_state[:, :reuse_length, :]\n",
    "\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 stack,\n",
    "                 num_induce,\n",
    "                 vocab_size,\n",
    "                 hidden_size,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 norm_epsilon=1e-12,\n",
    "                 inner_activation=\"relu\",\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 inner_dropout=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__(**kwargs)\n",
    "        self._stack = stack\n",
    "        self._num_induce = num_induce\n",
    "        self._vocab_size = vocab_size\n",
    "        self._num_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._inner_size = inner_size\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._inner_activation = inner_activation\n",
    "        self._norm_epsilon = norm_epsilon\n",
    "        self._kernel_initializer = kernel_initializer\n",
    "        self._inner_dropout = inner_dropout\n",
    "        self._attention_layer_type = Set_Attention\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape\n",
    "        input_tensor_shape = tf.TensorShape(input_tensor)\n",
    "        if len(input_tensor_shape.as_list()) != 3:\n",
    "            raise ValueError(\"TransformerLayer expects a three-dimensional input of \"\n",
    "                                             \"shape [batch, sequence, width].\")\n",
    "        batch_size, sequence_length, hidden_size = input_tensor_shape\n",
    "\n",
    "        if hidden_size % self._num_heads != 0:\n",
    "            raise ValueError(\n",
    "                    \"The input size (%d) is not a multiple of the number of attention \"\n",
    "                    \"heads (%d)\" % (hidden_size, self._num_heads))\n",
    "            \n",
    "            \n",
    "        self._attention_layer= self._attention_layer_type(num_induce=self._num_induce, embed_dim=self._head_size,num_heads=self._num_heads, stack=self._stack,\n",
    "                                                   use_layernorm=True,pre_layernorm=True,use_keras_mha=True)\n",
    "        \n",
    "        super(TransformerXLBlock, self).build(input_shape)\n",
    "\n",
    "   \n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        attention_output = {\"content_attention\": self._attention_layer(content_stream, state)}        \n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 stack, \n",
    "                 num_induce, \n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 hidden_size,\n",
    "                 maxlen,\n",
    "                 embed_dim,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 initializer,\n",
    "                 tie_attention_biases=True,\n",
    "                 memory_length=None,\n",
    "                 reuse_length=None,\n",
    "                 inner_activation=\"relu\",\n",
    "                 **kwargs):\n",
    "        super(TransformerXL, self).__init__(**kwargs)\n",
    "\n",
    "        self._stack = stack\n",
    "        self._num_induce = num_induce\n",
    "        self._vocab_size = vocab_size\n",
    "        self._initializer = initializer\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._num_attention_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._inner_size = inner_size\n",
    "        self._inner_activation = inner_activation\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._tie_attention_biases = tie_attention_biases\n",
    "        self._memory_length = memory_length\n",
    "        self._reuse_length = reuse_length\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        \n",
    "        for i in range(self._num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(\n",
    "                            stack=self._stack,\n",
    "                            num_induce=num_induce, \n",
    "                            vocab_size=self._vocab_size,\n",
    "                            hidden_size=self._head_size * self._num_attention_heads,\n",
    "                            num_attention_heads=self._num_attention_heads,\n",
    "                            head_size=self._head_size,\n",
    "                            inner_size=self._inner_size,\n",
    "                            dropout_rate=self._dropout_rate,\n",
    "                            attention_dropout_rate=self._attention_dropout_rate,\n",
    "                            norm_epsilon=1e-12,\n",
    "                            inner_activation=self._inner_activation,\n",
    "                            kernel_initializer=\"variance_scaling\",\n",
    "                            name=\"layer_%d\" % i))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             relative_position_encoding,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        if state is None:\n",
    "            state = [None] * self._num_layers\n",
    "            \n",
    "        for i in range(self._num_layers):\n",
    "            new_mems.append(_cache_memory(content_stream, state[i], self._memory_length, self._reuse_length))\n",
    "            \n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(\n",
    "                    content_stream=content_stream,\n",
    "                    content_attention_bias=None,\n",
    "                    positional_attention_bias=None,\n",
    "                    relative_position_encoding=None,\n",
    "                    state=state[i],\n",
    "                    content_attention_mask=content_attention_mask,\n",
    "                    query_attention_mask=query_attention_mask,\n",
    "                    target_mapping=target_mapping)\n",
    "            \n",
    "            content_stream = transformer_xl_output[\"content_attention\"]\n",
    "\n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b77a89f5-b11a-48e4-bf4f-cc70f1e74e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set_Attention(keras.Model):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(Set_Attention, self).__init__()\n",
    "        \n",
    "        self.set_attention = (Set_Transformer.InducedSetAttentionBlock(embed_dim=embed_dim,num_heads=num_heads, num_induce=num_induce, use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha))\n",
    "      \n",
    "    def call(self, data, mems):\n",
    "                \n",
    "            attention = self.set_attention([data, mems])\n",
    "                \n",
    "            return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, stack, num_induce, max_files, encoder, block_size, seq_len_padded, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.seq_len_padded = seq_len_padded\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxlen = maxlen\n",
    "        self.memory_length = memory_length\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.isabs = []\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(\n",
    "                stack=stack, \n",
    "                num_induce=num_induce, \n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                maxlen=maxlen,\n",
    "                embed_dim=embed_dim,\n",
    "                memory_length=memory_length,\n",
    "                reuse_length=reuse_length,\n",
    "                head_size=head_size,\n",
    "                inner_size=inner_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                attention_dropout_rate=attention_dropout_rate,\n",
    "                initializer=initializer, \n",
    "            )\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=True,pre_layernorm=True, use_keras_mha=True,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    " \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.memory_length, self.embed_dim))\n",
    "        \n",
    "        embeddings = self.embedding_layer(x)\n",
    "            \n",
    "        linear_transform = self.linear_layer(embeddings)    \n",
    "            \n",
    "        for i in range(0, self.seq_len_padded, self.block_size):\n",
    "            block = embeddings[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems = self.transformer_xl(content_stream=block, relative_position_encoding=None, state=mems)\n",
    "                \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters\n",
    "stack = 1\n",
    "num_induce = 30\n",
    "embed_dim = 8\n",
    "num_layers = 8\n",
    "hidden_size = 32\n",
    "num_attention_heads = 8\n",
    "memory_length = 200\n",
    "reuse_length = 0\n",
    "head_size = 8\n",
    "inner_size = 32\n",
    "dropout_rate = 0.01\n",
    "attention_dropout_rate = 0.01\n",
    "initializer = keras.initializers.RandomNormal(stddev=0.1) \n",
    "\n",
    "encoder = pretrained_encoder\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73dc6b6c-ad4a-4b28-916d-160d16dfc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = dict(\n",
    "    stack = 1,\n",
    "    num_induce = 30,\n",
    "    embed_dim = 8,\n",
    "    num_layers = 8,\n",
    "    hidden_size = 32,\n",
    "    num_attention_heads = 8,\n",
    "    memory_length = 200,\n",
    "    reuse_length = 0,\n",
    "    head_size = 8,\n",
    "    inner_size = 32,\n",
    "    dropout_rate = 0.01,\n",
    "    attention_dropout_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2a89bb3-457d-4af9-b749-1a9d91656db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkendragivens\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/TransformerXL/STR_XL/wandb/run-20220724_122756-15halbt2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kendragivens/Str_XL_Induced_Mha/runs/15halbt2\" target=\"_blank\">brisk-glitter-4</a></strong> to <a href=\"https://wandb.ai/kendragivens/Str_XL_Induced_Mha\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Str_XL_Induced_Mha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(stack, num_induce, max_files, encoder, block_size, seq_len, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Nadam(1e-4), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e79fc-5cbf-4807-a782-ed7cbe4e4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "20/20 [==============================] - 154s 6s/step - loss: 4.0356 - sparse_categorical_accuracy: 0.0300 - val_loss: 4.1181 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658683839.0000 - _runtime: 163.0000\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 4.0630 - sparse_categorical_accuracy: 0.0250 - val_loss: 3.9947 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658683955.0000 - _runtime: 279.0000\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 4.0248 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.9447 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658684071.0000 - _runtime: 395.0000\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 115s 6s/step - loss: 4.1010 - sparse_categorical_accuracy: 0.0250 - val_loss: 3.9817 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658684187.0000 - _runtime: 511.0000\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 4.0416 - sparse_categorical_accuracy: 0.0175 - val_loss: 4.0102 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658684303.0000 - _runtime: 627.0000\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9727 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.9162 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658684418.0000 - _runtime: 742.0000\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 4.0228 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.9546 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658684534.0000 - _runtime: 858.0000\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9904 - sparse_categorical_accuracy: 0.0175 - val_loss: 4.0576 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658684650.0000 - _runtime: 974.0000\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9835 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.8586 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658684765.0000 - _runtime: 1089.0000\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9604 - sparse_categorical_accuracy: 0.0350 - val_loss: 4.0433 - val_sparse_categorical_accuracy: 0.0000e+00 - _timestamp: 1658684882.0000 - _runtime: 1206.0000\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9559 - sparse_categorical_accuracy: 0.0325 - val_loss: 4.0155 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658684997.0000 - _runtime: 1321.0000\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 3.9758 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.8556 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658685110.0000 - _runtime: 1434.0000\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 115s 6s/step - loss: 3.9505 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.8753 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658685225.0000 - _runtime: 1549.0000\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 115s 6s/step - loss: 3.9261 - sparse_categorical_accuracy: 0.0200 - val_loss: 3.8754 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658685341.0000 - _runtime: 1665.0000\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.9029 - sparse_categorical_accuracy: 0.0075 - val_loss: 3.9245 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658685456.0000 - _runtime: 1780.0000\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 115s 6s/step - loss: 3.8606 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.8904 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658685572.0000 - _runtime: 1896.0000\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8661 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8935 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658685688.0000 - _runtime: 2012.0000\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8616 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.8147 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658685803.0000 - _runtime: 2127.0000\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8442 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.8296 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658685919.0000 - _runtime: 2243.0000\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8411 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8530 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658686035.0000 - _runtime: 2359.0000\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8401 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.8098 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658686151.0000 - _runtime: 2475.0000\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8170 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.8441 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658686267.0000 - _runtime: 2591.0000\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.8127 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.7979 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658686383.0000 - _runtime: 2707.0000\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7654 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.8041 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658686499.0000 - _runtime: 2823.0000\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7609 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.7320 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686614.0000 - _runtime: 2938.0000\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7971 - sparse_categorical_accuracy: 0.0225 - val_loss: 3.7921 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658686730.0000 - _runtime: 3054.0000\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7987 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.7612 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658686846.0000 - _runtime: 3170.0000\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7585 - sparse_categorical_accuracy: 0.0250 - val_loss: 3.7330 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658686962.0000 - _runtime: 3286.0000\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7603 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.8194 - val_sparse_categorical_accuracy: 0.0000e+00 - _timestamp: 1658687078.0000 - _runtime: 3402.0000\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7843 - sparse_categorical_accuracy: 0.0275 - val_loss: 3.8029 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687193.0000 - _runtime: 3517.0000\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7107 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.6968 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687309.0000 - _runtime: 3633.0000\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7561 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.7648 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658687425.0000 - _runtime: 3749.0000\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7550 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.7346 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658687541.0000 - _runtime: 3865.0000\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7183 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.7542 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658687656.0000 - _runtime: 3980.0000\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6965 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.7294 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658687772.0000 - _runtime: 4096.0000\n",
      "Epoch 36/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6501 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.7396 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658687888.0000 - _runtime: 4212.0000\n",
      "Epoch 37/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7060 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.6870 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658688004.0000 - _runtime: 4328.0000\n",
      "Epoch 38/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7133 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.6278 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658688120.0000 - _runtime: 4444.0000\n",
      "Epoch 39/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.7100 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.6415 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658688236.0000 - _runtime: 4560.0000\n",
      "Epoch 40/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6666 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.6963 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658688351.0000 - _runtime: 4675.0000\n",
      "Epoch 41/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6768 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.6584 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658688467.0000 - _runtime: 4791.0000\n",
      "Epoch 42/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6692 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.6336 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658688583.0000 - _runtime: 4907.0000\n",
      "Epoch 43/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6894 - sparse_categorical_accuracy: 0.0175 - val_loss: 3.6460 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658688699.0000 - _runtime: 5023.0000\n",
      "Epoch 44/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6507 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.6394 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658688815.0000 - _runtime: 5139.0000\n",
      "Epoch 45/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6376 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.6306 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658688930.0000 - _runtime: 5254.0000\n",
      "Epoch 46/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6616 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.6294 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658689046.0000 - _runtime: 5370.0000\n",
      "Epoch 47/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6333 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.6083 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658689162.0000 - _runtime: 5486.0000\n",
      "Epoch 48/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6082 - sparse_categorical_accuracy: 0.0350 - val_loss: 3.6261 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658689278.0000 - _runtime: 5602.0000\n",
      "Epoch 49/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6514 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.6687 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658689394.0000 - _runtime: 5718.0000\n",
      "Epoch 50/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6251 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.6364 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658689509.0000 - _runtime: 5833.0000\n",
      "Epoch 51/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5970 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.6515 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658689625.0000 - _runtime: 5949.0000\n",
      "Epoch 52/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6105 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.6372 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658689741.0000 - _runtime: 6065.0000\n",
      "Epoch 53/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6374 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.5763 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658689857.0000 - _runtime: 6181.0000\n",
      "Epoch 54/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6236 - sparse_categorical_accuracy: 0.0250 - val_loss: 3.6276 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658689973.0000 - _runtime: 6297.0000\n",
      "Epoch 55/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5788 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.6178 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658690089.0000 - _runtime: 6413.0000\n",
      "Epoch 56/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5830 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.6324 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690205.0000 - _runtime: 6529.0000\n",
      "Epoch 57/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5662 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.5575 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658690320.0000 - _runtime: 6644.0000\n",
      "Epoch 58/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5683 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.5595 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658690437.0000 - _runtime: 6761.0000\n",
      "Epoch 59/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5579 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.5681 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658690553.0000 - _runtime: 6877.0000\n",
      "Epoch 60/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5657 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.5916 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658690668.0000 - _runtime: 6992.0000\n",
      "Epoch 61/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.6175 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.5216 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658690784.0000 - _runtime: 7108.0000\n",
      "Epoch 62/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5815 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.5767 - val_sparse_categorical_accuracy: 0.0100 - _timestamp: 1658690900.0000 - _runtime: 7224.0000\n",
      "Epoch 63/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5226 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.6408 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658691016.0000 - _runtime: 7340.0000\n",
      "Epoch 64/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5647 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.5556 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658691132.0000 - _runtime: 7456.0000\n",
      "Epoch 65/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5208 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.5607 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658691248.0000 - _runtime: 7572.0000\n",
      "Epoch 66/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5463 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.5245 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658691364.0000 - _runtime: 7688.0000\n",
      "Epoch 67/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5316 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.5554 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658691480.0000 - _runtime: 7804.0000\n",
      "Epoch 68/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5486 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.5663 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658691596.0000 - _runtime: 7920.0000\n",
      "Epoch 69/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5630 - sparse_categorical_accuracy: 0.0450 - val_loss: 3.4912 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658691712.0000 - _runtime: 8036.0000\n",
      "Epoch 70/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5145 - sparse_categorical_accuracy: 0.0325 - val_loss: 3.5390 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658691828.0000 - _runtime: 8152.0000\n",
      "Epoch 71/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5052 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.5433 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658691944.0000 - _runtime: 8268.0000\n",
      "Epoch 72/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5246 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.5267 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692060.0000 - _runtime: 8384.0000\n",
      "Epoch 73/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5279 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4987 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692176.0000 - _runtime: 8500.0000\n",
      "Epoch 74/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5200 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.5305 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658692292.0000 - _runtime: 8616.0000\n",
      "Epoch 75/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5112 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.5444 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658692408.0000 - _runtime: 8732.0000\n",
      "Epoch 76/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5007 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4798 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692524.0000 - _runtime: 8848.0000\n",
      "Epoch 77/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4735 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.5069 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658692640.0000 - _runtime: 8964.0000\n",
      "Epoch 78/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.5182 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.5103 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658692756.0000 - _runtime: 9080.0000\n",
      "Epoch 79/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4716 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.4553 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658692872.0000 - _runtime: 9196.0000\n",
      "Epoch 80/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4755 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4646 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658692988.0000 - _runtime: 9312.0000\n",
      "Epoch 81/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4857 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4451 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658693104.0000 - _runtime: 9428.0000\n",
      "Epoch 82/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4688 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4823 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658693220.0000 - _runtime: 9544.0000\n",
      "Epoch 83/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4553 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4726 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693336.0000 - _runtime: 9660.0000\n",
      "Epoch 84/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4715 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4192 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658693452.0000 - _runtime: 9776.0000\n",
      "Epoch 85/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4811 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4721 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658693569.0000 - _runtime: 9893.0000\n",
      "Epoch 86/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4586 - sparse_categorical_accuracy: 0.0400 - val_loss: 3.4826 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658693685.0000 - _runtime: 10009.0000\n",
      "Epoch 87/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4439 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.5096 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658693800.0000 - _runtime: 10124.0000\n",
      "Epoch 88/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4277 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4819 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658693916.0000 - _runtime: 10240.0000\n",
      "Epoch 89/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4550 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4195 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658694032.0000 - _runtime: 10356.0000\n",
      "Epoch 90/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4439 - sparse_categorical_accuracy: 0.0575 - val_loss: 3.4466 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658694148.0000 - _runtime: 10472.0000\n",
      "Epoch 91/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4307 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.4647 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658694264.0000 - _runtime: 10588.0000\n",
      "Epoch 92/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4581 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4732 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658694380.0000 - _runtime: 10704.0000\n",
      "Epoch 93/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4378 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4366 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694496.0000 - _runtime: 10820.0000\n",
      "Epoch 94/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4480 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.4228 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694612.0000 - _runtime: 10936.0000\n",
      "Epoch 95/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3956 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4425 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658694728.0000 - _runtime: 11052.0000\n",
      "Epoch 96/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4379 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4907 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658694844.0000 - _runtime: 11168.0000\n",
      "Epoch 97/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4143 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4279 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658694960.0000 - _runtime: 11284.0000\n",
      "Epoch 98/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3906 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3870 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658695076.0000 - _runtime: 11400.0000\n",
      "Epoch 99/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4213 - sparse_categorical_accuracy: 0.0425 - val_loss: 3.4145 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658695192.0000 - _runtime: 11516.0000\n",
      "Epoch 100/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4168 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3696 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658695308.0000 - _runtime: 11632.0000\n",
      "Epoch 101/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4194 - sparse_categorical_accuracy: 0.0550 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658695424.0000 - _runtime: 11748.0000\n",
      "Epoch 102/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4118 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3623 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658695540.0000 - _runtime: 11864.0000\n",
      "Epoch 103/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4144 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3660 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658695657.0000 - _runtime: 11981.0000\n",
      "Epoch 104/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4058 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.3881 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658695773.0000 - _runtime: 12097.0000\n",
      "Epoch 105/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4139 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.4207 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658695889.0000 - _runtime: 12213.0000\n",
      "Epoch 106/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3775 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.4753 - val_sparse_categorical_accuracy: 0.0300 - _timestamp: 1658696005.0000 - _runtime: 12329.0000\n",
      "Epoch 107/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.4216 - sparse_categorical_accuracy: 0.0375 - val_loss: 3.3602 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658696121.0000 - _runtime: 12445.0000\n",
      "Epoch 108/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3939 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3925 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658696237.0000 - _runtime: 12561.0000\n",
      "Epoch 109/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3781 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.4355 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658696353.0000 - _runtime: 12677.0000\n",
      "Epoch 110/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3716 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3953 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658696469.0000 - _runtime: 12793.0000\n",
      "Epoch 111/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3978 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.3529 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658696585.0000 - _runtime: 12909.0000\n",
      "Epoch 112/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3821 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3584 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658696701.0000 - _runtime: 13025.0000\n",
      "Epoch 113/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3821 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3608 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658696817.0000 - _runtime: 13141.0000\n",
      "Epoch 114/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3604 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3797 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658696933.0000 - _runtime: 13257.0000\n",
      "Epoch 115/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3951 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3836 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658697049.0000 - _runtime: 13373.0000\n",
      "Epoch 116/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3990 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3942 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658697165.0000 - _runtime: 13489.0000\n",
      "Epoch 117/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3640 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.3864 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658697281.0000 - _runtime: 13605.0000\n",
      "Epoch 118/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3645 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3568 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658697397.0000 - _runtime: 13721.0000\n",
      "Epoch 119/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3370 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3841 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658697512.0000 - _runtime: 13836.0000\n",
      "Epoch 120/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3637 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.4199 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658697628.0000 - _runtime: 13952.0000\n",
      "Epoch 121/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3427 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.3661 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658697744.0000 - _runtime: 14068.0000\n",
      "Epoch 122/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3554 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3642 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658697860.0000 - _runtime: 14184.0000\n",
      "Epoch 123/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3661 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3042 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658697976.0000 - _runtime: 14300.0000\n",
      "Epoch 124/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3382 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.3265 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658698092.0000 - _runtime: 14416.0000\n",
      "Epoch 125/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3332 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3905 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658698208.0000 - _runtime: 14532.0000\n",
      "Epoch 126/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3693 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3267 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658698324.0000 - _runtime: 14648.0000\n",
      "Epoch 127/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3717 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3110 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658698440.0000 - _runtime: 14764.0000\n",
      "Epoch 128/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3055 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.3097 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658698556.0000 - _runtime: 14880.0000\n",
      "Epoch 129/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3168 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.3227 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658698672.0000 - _runtime: 14996.0000\n",
      "Epoch 130/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3367 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.3474 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658698788.0000 - _runtime: 15112.0000\n",
      "Epoch 131/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3257 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3444 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658698904.0000 - _runtime: 15228.0000\n",
      "Epoch 132/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3182 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.3636 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658699020.0000 - _runtime: 15344.0000\n",
      "Epoch 133/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3544 - sparse_categorical_accuracy: 0.0725 - val_loss: 3.3094 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658699135.0000 - _runtime: 15459.0000\n",
      "Epoch 134/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3445 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.3668 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658699251.0000 - _runtime: 15575.0000\n",
      "Epoch 135/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3420 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3504 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658699367.0000 - _runtime: 15691.0000\n",
      "Epoch 136/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3276 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.2935 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658699483.0000 - _runtime: 15807.0000\n",
      "Epoch 137/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3134 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3049 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658699599.0000 - _runtime: 15923.0000\n",
      "Epoch 138/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3036 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3097 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658699715.0000 - _runtime: 16039.0000\n",
      "Epoch 139/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3152 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2955 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658699831.0000 - _runtime: 16155.0000\n",
      "Epoch 140/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2994 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.3063 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658699947.0000 - _runtime: 16271.0000\n",
      "Epoch 141/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3227 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3315 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658700063.0000 - _runtime: 16387.0000\n",
      "Epoch 142/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3309 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.2742 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658700179.0000 - _runtime: 16503.0000\n",
      "Epoch 143/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3238 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.3358 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658700296.0000 - _runtime: 16620.0000\n",
      "Epoch 144/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3023 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.2765 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658700411.0000 - _runtime: 16735.0000\n",
      "Epoch 145/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3390 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658700527.0000 - _runtime: 16851.0000\n",
      "Epoch 146/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3063 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.3077 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658700643.0000 - _runtime: 16967.0000\n",
      "Epoch 147/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2940 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3141 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658700759.0000 - _runtime: 17083.0000\n",
      "Epoch 148/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2982 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2457 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658700875.0000 - _runtime: 17199.0000\n",
      "Epoch 149/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.3106 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3128 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658700991.0000 - _runtime: 17315.0000\n",
      "Epoch 150/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2698 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2812 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658701107.0000 - _runtime: 17431.0000\n",
      "Epoch 151/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2570 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2751 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658701223.0000 - _runtime: 17547.0000\n",
      "Epoch 152/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2999 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.2708 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658701339.0000 - _runtime: 17663.0000\n",
      "Epoch 153/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2727 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.3478 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658701455.0000 - _runtime: 17779.0000\n",
      "Epoch 154/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2711 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3029 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658701571.0000 - _runtime: 17895.0000\n",
      "Epoch 155/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2716 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.2843 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658701687.0000 - _runtime: 18011.0000\n",
      "Epoch 156/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2704 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2939 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658701803.0000 - _runtime: 18127.0000\n",
      "Epoch 157/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2676 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.3140 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658701919.0000 - _runtime: 18243.0000\n",
      "Epoch 158/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2868 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.2797 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658702035.0000 - _runtime: 18359.0000\n",
      "Epoch 159/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2900 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.2702 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658702151.0000 - _runtime: 18475.0000\n",
      "Epoch 160/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2492 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2977 - val_sparse_categorical_accuracy: 0.0200 - _timestamp: 1658702267.0000 - _runtime: 18591.0000\n",
      "Epoch 161/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2849 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2246 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658702382.0000 - _runtime: 18706.0000\n",
      "Epoch 162/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2638 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.3010 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658702499.0000 - _runtime: 18823.0000\n",
      "Epoch 163/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2706 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.2806 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658702615.0000 - _runtime: 18939.0000\n",
      "Epoch 164/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2596 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.2336 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658702731.0000 - _runtime: 19055.0000\n",
      "Epoch 165/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2923 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.2642 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658702847.0000 - _runtime: 19171.0000\n",
      "Epoch 166/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2661 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.3201 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658702963.0000 - _runtime: 19287.0000\n",
      "Epoch 167/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2244 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.2618 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658703079.0000 - _runtime: 19403.0000\n",
      "Epoch 168/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2615 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2103 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703194.0000 - _runtime: 19518.0000\n",
      "Epoch 169/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2582 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.2775 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658703311.0000 - _runtime: 19635.0000\n",
      "Epoch 170/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2578 - sparse_categorical_accuracy: 0.0600 - val_loss: 3.3315 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658703427.0000 - _runtime: 19751.0000\n",
      "Epoch 171/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2419 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.2641 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658703543.0000 - _runtime: 19867.0000\n",
      "Epoch 172/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2604 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2875 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703659.0000 - _runtime: 19983.0000\n",
      "Epoch 173/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2785 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2534 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658703775.0000 - _runtime: 20099.0000\n",
      "Epoch 174/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2516 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.1947 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658703890.0000 - _runtime: 20214.0000\n",
      "Epoch 175/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2422 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1985 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658704007.0000 - _runtime: 20331.0000\n",
      "Epoch 176/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2513 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.2509 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704123.0000 - _runtime: 20447.0000\n",
      "Epoch 177/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2084 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.2603 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658704239.0000 - _runtime: 20563.0000\n",
      "Epoch 178/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2511 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.2638 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658704354.0000 - _runtime: 20678.0000\n",
      "Epoch 179/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2194 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1900 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704471.0000 - _runtime: 20795.0000\n",
      "Epoch 180/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2412 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.2477 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658704587.0000 - _runtime: 20911.0000\n",
      "Epoch 181/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2181 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2124 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658704703.0000 - _runtime: 21027.0000\n",
      "Epoch 182/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2139 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1656 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658704819.0000 - _runtime: 21143.0000\n",
      "Epoch 183/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2370 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2327 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658704935.0000 - _runtime: 21259.0000\n",
      "Epoch 184/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2106 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.2258 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705051.0000 - _runtime: 21375.0000\n",
      "Epoch 185/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2464 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.2057 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658705167.0000 - _runtime: 21491.0000\n",
      "Epoch 186/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2316 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2111 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658705283.0000 - _runtime: 21607.0000\n",
      "Epoch 187/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2037 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.2169 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705399.0000 - _runtime: 21723.0000\n",
      "Epoch 188/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1973 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.2351 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658705515.0000 - _runtime: 21839.0000\n",
      "Epoch 189/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2017 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1181 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658705631.0000 - _runtime: 21955.0000\n",
      "Epoch 190/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2368 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2304 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658705747.0000 - _runtime: 22071.0000\n",
      "Epoch 191/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2418 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2215 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658705863.0000 - _runtime: 22187.0000\n",
      "Epoch 192/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2049 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.1640 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658705978.0000 - _runtime: 22302.0000\n",
      "Epoch 193/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1785 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.2510 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658706094.0000 - _runtime: 22418.0000\n",
      "Epoch 194/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2101 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2047 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658706210.0000 - _runtime: 22534.0000\n",
      "Epoch 195/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2143 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1893 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658706327.0000 - _runtime: 22651.0000\n",
      "Epoch 196/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2369 - sparse_categorical_accuracy: 0.0525 - val_loss: 3.1622 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658706442.0000 - _runtime: 22766.0000\n",
      "Epoch 197/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1929 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.2072 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658706559.0000 - _runtime: 22883.0000\n",
      "Epoch 198/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2096 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.2278 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658706674.0000 - _runtime: 22998.0000\n",
      "Epoch 199/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2257 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2267 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658706791.0000 - _runtime: 23115.0000\n",
      "Epoch 200/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1846 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1900 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658706907.0000 - _runtime: 23231.0000\n",
      "Epoch 201/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2072 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1749 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658707023.0000 - _runtime: 23347.0000\n",
      "Epoch 202/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1961 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1965 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658707138.0000 - _runtime: 23462.0000\n",
      "Epoch 203/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2139 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1620 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658707254.0000 - _runtime: 23578.0000\n",
      "Epoch 204/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1990 - sparse_categorical_accuracy: 0.0675 - val_loss: 3.1952 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658707371.0000 - _runtime: 23695.0000\n",
      "Epoch 205/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1935 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1865 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658707487.0000 - _runtime: 23811.0000\n",
      "Epoch 206/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1832 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.1736 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658707602.0000 - _runtime: 23926.0000\n",
      "Epoch 207/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1910 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.2487 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658707718.0000 - _runtime: 24042.0000\n",
      "Epoch 208/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2023 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2322 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658707834.0000 - _runtime: 24158.0000\n",
      "Epoch 209/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1872 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1475 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658707950.0000 - _runtime: 24274.0000\n",
      "Epoch 210/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1928 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2288 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658708066.0000 - _runtime: 24390.0000\n",
      "Epoch 211/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1983 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1868 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658708182.0000 - _runtime: 24506.0000\n",
      "Epoch 212/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1673 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1615 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658708298.0000 - _runtime: 24622.0000\n",
      "Epoch 213/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2054 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1928 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658708414.0000 - _runtime: 24738.0000\n",
      "Epoch 214/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1849 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1054 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658708530.0000 - _runtime: 24854.0000\n",
      "Epoch 215/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1938 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1972 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658708646.0000 - _runtime: 24970.0000\n",
      "Epoch 216/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2301 - sparse_categorical_accuracy: 0.0700 - val_loss: 3.1997 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658708762.0000 - _runtime: 25086.0000\n",
      "Epoch 217/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1895 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2032 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658708878.0000 - _runtime: 25202.0000\n",
      "Epoch 218/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1973 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1953 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658708994.0000 - _runtime: 25318.0000\n",
      "Epoch 219/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1881 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1734 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658709110.0000 - _runtime: 25434.0000\n",
      "Epoch 220/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1438 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.2134 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658709226.0000 - _runtime: 25550.0000\n",
      "Epoch 221/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1881 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2013 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658709342.0000 - _runtime: 25666.0000\n",
      "Epoch 222/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1872 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1365 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658709458.0000 - _runtime: 25782.0000\n",
      "Epoch 223/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1910 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.1730 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658709574.0000 - _runtime: 25898.0000\n",
      "Epoch 224/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1987 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1895 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658709690.0000 - _runtime: 26014.0000\n",
      "Epoch 225/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1638 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1967 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658709806.0000 - _runtime: 26130.0000\n",
      "Epoch 226/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1732 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1007 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658709922.0000 - _runtime: 26246.0000\n",
      "Epoch 227/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.2181 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1783 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658710038.0000 - _runtime: 26362.0000\n",
      "Epoch 228/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1650 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1924 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658710154.0000 - _runtime: 26478.0000\n",
      "Epoch 229/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1881 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2362 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658710270.0000 - _runtime: 26594.0000\n",
      "Epoch 230/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1635 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.2035 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658710386.0000 - _runtime: 26710.0000\n",
      "Epoch 231/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1557 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1684 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658710502.0000 - _runtime: 26826.0000\n",
      "Epoch 232/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1776 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1692 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658710618.0000 - _runtime: 26942.0000\n",
      "Epoch 233/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1787 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1299 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658710734.0000 - _runtime: 27058.0000\n",
      "Epoch 234/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1449 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.2022 - val_sparse_categorical_accuracy: 0.0400 - _timestamp: 1658710850.0000 - _runtime: 27174.0000\n",
      "Epoch 235/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1700 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1271 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658710966.0000 - _runtime: 27290.0000\n",
      "Epoch 236/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1226 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1609 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658711082.0000 - _runtime: 27406.0000\n",
      "Epoch 237/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1355 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1785 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658711198.0000 - _runtime: 27522.0000\n",
      "Epoch 238/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1637 - sparse_categorical_accuracy: 0.0625 - val_loss: 3.0896 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658711314.0000 - _runtime: 27638.0000\n",
      "Epoch 239/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1364 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.2116 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658711430.0000 - _runtime: 27754.0000\n",
      "Epoch 240/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1441 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1028 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658711546.0000 - _runtime: 27870.0000\n",
      "Epoch 241/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1284 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1574 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658711662.0000 - _runtime: 27986.0000\n",
      "Epoch 242/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1592 - sparse_categorical_accuracy: 0.0800 - val_loss: 3.1983 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658711778.0000 - _runtime: 28102.0000\n",
      "Epoch 243/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1476 - sparse_categorical_accuracy: 0.0650 - val_loss: 3.1449 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658711894.0000 - _runtime: 28218.0000\n",
      "Epoch 244/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1225 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1466 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658712010.0000 - _runtime: 28334.0000\n",
      "Epoch 245/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1310 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1400 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658712126.0000 - _runtime: 28450.0000\n",
      "Epoch 246/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1652 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.2048 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658712242.0000 - _runtime: 28566.0000\n",
      "Epoch 247/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1315 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.0801 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658712358.0000 - _runtime: 28682.0000\n",
      "Epoch 248/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1758 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1232 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658712474.0000 - _runtime: 28798.0000\n",
      "Epoch 249/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0806 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.0742 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658712590.0000 - _runtime: 28914.0000\n",
      "Epoch 250/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1478 - sparse_categorical_accuracy: 0.0825 - val_loss: 3.1091 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658712706.0000 - _runtime: 29030.0000\n",
      "Epoch 251/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1331 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1862 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658712822.0000 - _runtime: 29146.0000\n",
      "Epoch 252/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1536 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1325 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658712938.0000 - _runtime: 29262.0000\n",
      "Epoch 253/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1902 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1819 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658713054.0000 - _runtime: 29378.0000\n",
      "Epoch 254/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1031 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1594 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658713170.0000 - _runtime: 29494.0000\n",
      "Epoch 255/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1467 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1146 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658713286.0000 - _runtime: 29610.0000\n",
      "Epoch 256/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1557 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0752 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658713402.0000 - _runtime: 29726.0000\n",
      "Epoch 257/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1406 - sparse_categorical_accuracy: 0.0875 - val_loss: 3.1099 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658713517.0000 - _runtime: 29841.0000\n",
      "Epoch 258/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1061 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.1240 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658713633.0000 - _runtime: 29957.0000\n",
      "Epoch 259/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0878 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1450 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658713749.0000 - _runtime: 30073.0000\n",
      "Epoch 260/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1286 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1472 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658713865.0000 - _runtime: 30189.0000\n",
      "Epoch 261/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1125 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.0944 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658713981.0000 - _runtime: 30305.0000\n",
      "Epoch 262/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1490 - sparse_categorical_accuracy: 0.0850 - val_loss: 3.1294 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658714097.0000 - _runtime: 30421.0000\n",
      "Epoch 263/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1387 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1551 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658714213.0000 - _runtime: 30537.0000\n",
      "Epoch 264/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1281 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1841 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658714329.0000 - _runtime: 30653.0000\n",
      "Epoch 265/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1274 - sparse_categorical_accuracy: 0.0900 - val_loss: 3.1272 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658714445.0000 - _runtime: 30769.0000\n",
      "Epoch 266/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1215 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1333 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658714561.0000 - _runtime: 30885.0000\n",
      "Epoch 267/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0997 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1346 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658714677.0000 - _runtime: 31001.0000\n",
      "Epoch 268/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1442 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1476 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658714793.0000 - _runtime: 31117.0000\n",
      "Epoch 269/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1409 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1210 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658714909.0000 - _runtime: 31233.0000\n",
      "Epoch 270/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1150 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1543 - val_sparse_categorical_accuracy: 0.0600 - _timestamp: 1658715025.0000 - _runtime: 31349.0000\n",
      "Epoch 271/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1065 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.0627 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658715141.0000 - _runtime: 31465.0000\n",
      "Epoch 272/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1332 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.1051 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658715257.0000 - _runtime: 31581.0000\n",
      "Epoch 273/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1175 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1697 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658715373.0000 - _runtime: 31697.0000\n",
      "Epoch 274/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1209 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.1484 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658715489.0000 - _runtime: 31813.0000\n",
      "Epoch 275/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0951 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0629 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658715605.0000 - _runtime: 31929.0000\n",
      "Epoch 276/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0862 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.0889 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658715721.0000 - _runtime: 32045.0000\n",
      "Epoch 277/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1202 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1173 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658715837.0000 - _runtime: 32161.0000\n",
      "Epoch 278/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0723 - sparse_categorical_accuracy: 0.0925 - val_loss: 3.1807 - val_sparse_categorical_accuracy: 0.0500 - _timestamp: 1658715953.0000 - _runtime: 32277.0000\n",
      "Epoch 279/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1339 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1738 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658716069.0000 - _runtime: 32393.0000\n",
      "Epoch 280/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0941 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0805 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658716185.0000 - _runtime: 32509.0000\n",
      "Epoch 281/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1045 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1164 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658716301.0000 - _runtime: 32625.0000\n",
      "Epoch 282/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1049 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.0979 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658716417.0000 - _runtime: 32741.0000\n",
      "Epoch 283/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0837 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0906 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658716533.0000 - _runtime: 32857.0000\n",
      "Epoch 284/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1138 - sparse_categorical_accuracy: 0.1125 - val_loss: 3.1502 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658716649.0000 - _runtime: 32973.0000\n",
      "Epoch 285/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0828 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.0964 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658716764.0000 - _runtime: 33088.0000\n",
      "Epoch 286/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1032 - sparse_categorical_accuracy: 0.1325 - val_loss: 3.1148 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658716880.0000 - _runtime: 33204.0000\n",
      "Epoch 287/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0959 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1821 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658716996.0000 - _runtime: 33320.0000\n",
      "Epoch 288/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0825 - sparse_categorical_accuracy: 0.0950 - val_loss: 3.1228 - val_sparse_categorical_accuracy: 0.0700 - _timestamp: 1658717112.0000 - _runtime: 33436.0000\n",
      "Epoch 289/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0589 - sparse_categorical_accuracy: 0.1275 - val_loss: 3.0921 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658717228.0000 - _runtime: 33552.0000\n",
      "Epoch 290/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0910 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.1334 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658717344.0000 - _runtime: 33668.0000\n",
      "Epoch 291/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1171 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1258 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658717460.0000 - _runtime: 33784.0000\n",
      "Epoch 292/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.1189 - sparse_categorical_accuracy: 0.0775 - val_loss: 3.0131 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658717576.0000 - _runtime: 33900.0000\n",
      "Epoch 293/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0809 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0909 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658717693.0000 - _runtime: 34017.0000\n",
      "Epoch 294/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0922 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0792 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658717809.0000 - _runtime: 34133.0000\n",
      "Epoch 295/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0890 - sparse_categorical_accuracy: 0.1000 - val_loss: 3.0922 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658717924.0000 - _runtime: 34248.0000\n",
      "Epoch 296/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0827 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.1138 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658718040.0000 - _runtime: 34364.0000\n",
      "Epoch 297/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0857 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.1211 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658718156.0000 - _runtime: 34480.0000\n",
      "Epoch 298/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0573 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0701 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658718272.0000 - _runtime: 34596.0000\n",
      "Epoch 299/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0828 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.0150 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658718388.0000 - _runtime: 34712.0000\n",
      "Epoch 300/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0538 - sparse_categorical_accuracy: 0.0975 - val_loss: 3.0530 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658718504.0000 - _runtime: 34828.0000\n",
      "Epoch 301/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0741 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.1289 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658718620.0000 - _runtime: 34944.0000\n",
      "Epoch 302/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0334 - sparse_categorical_accuracy: 0.1075 - val_loss: 3.0941 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658718736.0000 - _runtime: 35060.0000\n",
      "Epoch 303/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0704 - sparse_categorical_accuracy: 0.1425 - val_loss: 3.0094 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658718852.0000 - _runtime: 35176.0000\n",
      "Epoch 304/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0721 - sparse_categorical_accuracy: 0.1175 - val_loss: 2.9868 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658718968.0000 - _runtime: 35292.0000\n",
      "Epoch 305/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0457 - sparse_categorical_accuracy: 0.1450 - val_loss: 3.1362 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658719085.0000 - _runtime: 35409.0000\n",
      "Epoch 306/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0592 - sparse_categorical_accuracy: 0.1200 - val_loss: 3.0915 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658719201.0000 - _runtime: 35525.0000\n",
      "Epoch 307/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0761 - sparse_categorical_accuracy: 0.1025 - val_loss: 3.1245 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658719316.0000 - _runtime: 35640.0000\n",
      "Epoch 308/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0486 - sparse_categorical_accuracy: 0.1150 - val_loss: 3.1254 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658719432.0000 - _runtime: 35756.0000\n",
      "Epoch 309/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0358 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.0606 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658719548.0000 - _runtime: 35872.0000\n",
      "Epoch 310/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0660 - sparse_categorical_accuracy: 0.1350 - val_loss: 3.1123 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658719664.0000 - _runtime: 35988.0000\n",
      "Epoch 311/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0622 - sparse_categorical_accuracy: 0.1050 - val_loss: 3.0611 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658719780.0000 - _runtime: 36104.0000\n",
      "Epoch 312/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0519 - sparse_categorical_accuracy: 0.1175 - val_loss: 3.0205 - val_sparse_categorical_accuracy: 0.0900 - _timestamp: 1658719896.0000 - _runtime: 36220.0000\n",
      "Epoch 313/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0455 - sparse_categorical_accuracy: 0.1525 - val_loss: 3.0950 - val_sparse_categorical_accuracy: 0.1000 - _timestamp: 1658720012.0000 - _runtime: 36336.0000\n",
      "Epoch 314/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0549 - sparse_categorical_accuracy: 0.1300 - val_loss: 3.0396 - val_sparse_categorical_accuracy: 0.0800 - _timestamp: 1658720128.0000 - _runtime: 36452.0000\n",
      "Epoch 315/10000\n",
      "20/20 [==============================] - 116s 6s/step - loss: 3.0365 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.0519 - val_sparse_categorical_accuracy: 0.1100 - _timestamp: 1658720244.0000 - _runtime: 36568.0000\n",
      "Epoch 316/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 3.0821 - sparse_categorical_accuracy: 0.0875"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1, callbacks=[wandb.keras.WandbCallback(save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6e04f-8083-48e5-a7cf-1d38fa2a3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd3ce8-bf54-4900-ba0d-33848bf129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6add5-4de7-4339-8689-408e9549634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_Xl_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb61df-30cd-40bc-8cb4-7b95364f04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Str_Xl_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0feaa-ccf4-4352-bddc-728529531858",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3f83-2d73-4c19-a50e-eb8a5c636edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ebaae-0583-4553-a957-7d1f45958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eef17b-b311-4277-9bb7-87f05d897473",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504f3ab-5e7b-4082-b017-f46b0b8fbcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccea5cd-89de-452b-afa6-703df9e9a604",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c14f8-8dd8-459f-81fe-a6708e6a8355",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcad43d-67f7-49b9-84ce-6d91a0f468a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7cb9df-5746-44a3-998a-b671b284957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c507a85-fe6f-4d3c-ae1f-16914fdec693",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../deep-learning-dna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b9c98a-b4ee-4667-89a3-5f04549f7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda64db1-8058-4e15-b2d4-1a3e64f23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import math\n",
    "import string\n",
    "\n",
    "import Set_Transformer \n",
    "from common.models import dnabert\n",
    "from common import dna\n",
    "from lmdbm import Lmdb\n",
    "from common.data import DnaSequenceGenerator, DnaLabelType, DnaSampleGenerator, find_dbs\n",
    "import wandb\n",
    "\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb3b1a-2db7-4463-a208-b5d29e20f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tfu.devices.select_gpu(0, use_dynamic_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54593a0f-b5b4-401e-91e2-8c1a1598432e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ec0c2-f4ac-418f-93a5-7f8b21b286ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<common.models.dnabert.DnaBertPretrainModel at 0x7fb3c8d93010>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pretrained model\n",
    "api = wandb.Api()\n",
    "model_path = api.artifact(\"sirdavidludwig/dnabert-pretrain/dnabert-pretrain-8dim:latest\").download()\n",
    "pretrained_model = dnabert.DnaBertModel.load(model_path)\n",
    "pretrained_model.load_weights(model_path + \"/model.h5\")\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb8a00e-6821-4a74-87cb-ecd6c405d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dnasamples-complete:latest, 4079.09MB. 420 files... Done. 0:0:0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/dna_samples:v1/train/WS-CCW-Jul2015_S82_L001_R1_001.db'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datafiles\n",
    "dataset_path = api.artifact(\"sirdavidludwig/nachusa-dna/dnasamples-complete:latest\").download('/data/dna_samples:v1')\n",
    "samples = find_dbs(dataset_path + '/train')\n",
    "samples[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6523647-1042-4dc6-aa46-1ad979f03892",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14bf26f-f2d8-4907-991e-7dcbbc68f206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratios = [0.8, 0.2]\n",
    "set_len = 1000\n",
    "sequence_len = 150\n",
    "kmer = 3\n",
    "batch_size = [20,5]\n",
    "batches_per_epoch = 20\n",
    "augument = True\n",
    "labels = DnaLabelType.SampleIds\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed)\n",
    "random_samples = samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d827ca7f-1900-4e88-a514-ae29daf45858",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.shuffle(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1116c1ae-77e7-44c9-a010-efb23c23db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n",
      "Sample '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db' does not contain enough sequences. This sample will be ignored.\n"
     ]
    }
   ],
   "source": [
    "trimmed_samples, (train_dataset, val_dataset) = DnaSampleGenerator.split(samples=random_samples[0:50], split_ratios=split_ratios, subsample_length=set_len, sequence_length=sequence_len, kmer=kmer,batch_size=batch_size,batches_per_epoch=batches_per_epoch,augment=augument,labels=labels, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac0a881-4dc6-4916-a18c-8c59e026e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dna_samples:v1/train/WS-CCE-Apr2016_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes52-10-TC_S53_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-Jul2016_S46_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes41-10-HN_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley026-Ag-072820_S165_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Apr2016_S84_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes5-5-CCE_S6_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MR-Apr2016_S13_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-MU-Sep2015_S43_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley012-HN-051120_S151_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Sep2015_S91_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Sep2015_S52_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes26-8-AG_S27_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Jul2016_S22_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes25-8-MU_S26_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Oct2016_S63_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes3-5-TCR_S4_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-WH-May2015_S160_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-Oct2016_S80_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Jul2015_S74_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SB-Sep2015_S35_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-CCW-Sep2015_S28_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TC-Oct2016_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HF-Jul2015_S42_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-TCR-May2015_S73_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-Apr2016_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Apr2016_S85_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes7-PCRblank1_S8_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes20-8-HF_S21_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes38-10-WH_S39_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley047-SF-100420_S186_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley055-HAP-051120_S194_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley006-HLP-051220_S145_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes39-10-HF_S40_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-Jul2016_S38_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley035-HLP2-072820_S174_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes13-5-HLP_S14_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-HPN-May2015_S17_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley005-HF-051220_S144_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes47-10-FC_S48_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-SF-May2015_S152_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley045-HLP-100420_S184_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley033-MU-072820_S172_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley043-L-100420_S182_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes48-10-CCW_S49_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/WS-AG-Sep2015_S44_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley010-HW-051120_S149_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wes36-8-HW_S37_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley011-Ag-051120_S150_L001_R1_001.db',\n",
       " '/data/dna_samples:v1/train/Wesley027-HLP-072820_S166_L001_R1_001.db']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855356-4e5a-4047-ae81-323277b11b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "# Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23e34f9-3066-4756-ad0b-ccc1a3194438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 200\n",
    "seq_len = set_len\n",
    "maxlen = set_len\n",
    "vocab_size = 5\n",
    "num_chars_data = set_len*sequence_len\n",
    "max_files = len(train_dataset.samples)\n",
    "max_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e768970c-7af4-4626-9d6e-d712ab7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if block_size-2 > seq_len:\n",
    "    raise ValueError(\"Block size should not be bigger than sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce0777e-c8af-4835-833d-f1717dbf2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(maxlen)\n",
    "print(vocab_size)\n",
    "print(num_chars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3649b2-2e47-4b30-88e5-6792f1646058",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74ee78-6d96-41ed-9989-e66cfd5cb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 8 dimensional embeddings\n",
    "pretrained_encoder = dnabert.DnaBertEncoderModel(pretrained_model.base)\n",
    "pretrained_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d33b634-4927-4f9a-a241-8c33c9249a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Embeddings(keras.layers.Layer):\n",
    "    def __init__(self, encoder):\n",
    "        super(Create_Embeddings, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def subbatch_predict(self, model, batch, subbatch_size, concat=lambda old, new: tf.concat((old, new), axis=0)):\n",
    "        def predict(i, result=None):\n",
    "            n = i + subbatch_size\n",
    "            pred = tf.stop_gradient(model(batch[i:n]))\n",
    "            if result is None:\n",
    "                return [n, pred]\n",
    "            return [n, concat(result, pred)]\n",
    "        i, result = predict(0)\n",
    "        batch_size = tf.shape(batch)[0]\n",
    "        i, result = tf.while_loop(\n",
    "            cond=lambda i, _: i < batch_size,\n",
    "            body=predict,\n",
    "            loop_vars=[i, result],\n",
    "            parallel_iterations=1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def modify_data_for_input(self, data):\n",
    "        batch_size = tf.shape(data)[0]\n",
    "        subsample_size = tf.shape(data)[1]\n",
    "        flat_data = tf.reshape(data, (batch_size*subsample_size, -1))\n",
    "        encoded = self.subbatch_predict(self.encoder, flat_data, 128)\n",
    "        return tf.reshape(encoded, (batch_size, subsample_size, -1))\n",
    "    \n",
    "    def call(self, data):\n",
    "        return  self.modify_data_for_input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b66c98-f8b5-4b80-9736-66a9769cc966",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af4ac04-1eab-4d74-bfc0-716408efeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_initializer(initializer):\n",
    "    if isinstance(initializer, tf.keras.initializers.Initializer):\n",
    "        return initializer.__class__.from_config(initializer.get_config())\n",
    "    return initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c39dd-9fb5-49bf-8763-14ca694a1a35",
   "metadata": {},
   "source": [
    "---\n",
    "# Cache Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4cb5e4-2d26-4e40-a00f-3e71f470b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):\n",
    "    if memory_length is None or memory_length == 0:\n",
    "        return None\n",
    "    else:\n",
    "        if reuse_length > 0:\n",
    "            current_state = current_state[:, :reuse_length, :]\n",
    "\n",
    "        if previous_state is None:\n",
    "            new_mem = current_state[:, -memory_length:, :]\n",
    "        else:\n",
    "            new_mem = tf.concat(\n",
    "                    [previous_state, current_state], 1)[:, -memory_length:, :]\n",
    "\n",
    "    return tf.stop_gradient(new_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32bb5-4520-4802-a8f0-5f7849905a83",
   "metadata": {},
   "source": [
    "---\n",
    "# XL Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7245b7dd-a3b2-464a-9f5b-7efd4a9d0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 stack,\n",
    "                 num_induce,\n",
    "                 vocab_size,\n",
    "                 hidden_size,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 norm_epsilon=1e-12,\n",
    "                 inner_activation=\"relu\",\n",
    "                 kernel_initializer=\"variance_scaling\",\n",
    "                 inner_dropout=0.0,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TransformerXLBlock, self).__init__(**kwargs)\n",
    "        self._stack = stack\n",
    "        self._num_induce = num_induce\n",
    "        self._vocab_size = vocab_size\n",
    "        self._num_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._inner_size = inner_size\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._inner_activation = inner_activation\n",
    "        self._norm_epsilon = norm_epsilon\n",
    "        self._kernel_initializer = kernel_initializer\n",
    "        self._inner_dropout = inner_dropout\n",
    "        self._attention_layer_type = Set_Attention\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape\n",
    "        input_tensor_shape = tf.TensorShape(input_tensor)\n",
    "        if len(input_tensor_shape.as_list()) != 3:\n",
    "            raise ValueError(\"TransformerLayer expects a three-dimensional input of \"\n",
    "                                             \"shape [batch, sequence, width].\")\n",
    "        batch_size, sequence_length, hidden_size = input_tensor_shape\n",
    "\n",
    "        if hidden_size % self._num_heads != 0:\n",
    "            raise ValueError(\n",
    "                    \"The input size (%d) is not a multiple of the number of attention \"\n",
    "                    \"heads (%d)\" % (hidden_size, self._num_heads))\n",
    "            \n",
    "            \n",
    "        self._attention_layer= self._attention_layer_type(num_induce=self._num_induce, embed_dim=self._head_size,num_heads=self._num_heads, stack=self._stack,\n",
    "                                                   use_layernorm=True,pre_layernorm=True,use_keras_mha=True)\n",
    "        \n",
    "        super(TransformerXLBlock, self).build(input_shape)\n",
    "\n",
    "   \n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             content_attention_bias,\n",
    "             positional_attention_bias,\n",
    "             relative_position_encoding=None,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        attention_output = {\"content_attention\": self._attention_layer(content_stream, state)}        \n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749ec30-1281-4f9d-8baa-54b890fb7949",
   "metadata": {},
   "source": [
    "---\n",
    "# Transformer XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019ca25d-e899-4e17-8f41-dfdc3d9bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXL(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 stack, \n",
    "                 num_induce, \n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 hidden_size,\n",
    "                 maxlen,\n",
    "                 embed_dim,\n",
    "                 num_attention_heads,\n",
    "                 head_size,\n",
    "                 inner_size,\n",
    "                 dropout_rate,\n",
    "                 attention_dropout_rate,\n",
    "                 initializer,\n",
    "                 tie_attention_biases=True,\n",
    "                 memory_length=None,\n",
    "                 reuse_length=None,\n",
    "                 inner_activation=\"relu\",\n",
    "                 **kwargs):\n",
    "        super(TransformerXL, self).__init__(**kwargs)\n",
    "\n",
    "        self._stack = stack\n",
    "        self._num_induce = num_induce\n",
    "        self._vocab_size = vocab_size\n",
    "        self._initializer = initializer\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._num_attention_heads = num_attention_heads\n",
    "        self._head_size = head_size\n",
    "        self._inner_size = inner_size\n",
    "        self._inner_activation = inner_activation\n",
    "        self._dropout_rate = dropout_rate\n",
    "        self._attention_dropout_rate = attention_dropout_rate\n",
    "        self._tie_attention_biases = tie_attention_biases\n",
    "        self._memory_length = memory_length\n",
    "        self._reuse_length = reuse_length\n",
    "\n",
    "        self.transformer_xl_layers = []\n",
    "        \n",
    "        for i in range(self._num_layers):\n",
    "            self.transformer_xl_layers.append(\n",
    "                    TransformerXLBlock(\n",
    "                            stack=self._stack,\n",
    "                            num_induce=num_induce, \n",
    "                            vocab_size=self._vocab_size,\n",
    "                            hidden_size=self._head_size * self._num_attention_heads,\n",
    "                            num_attention_heads=self._num_attention_heads,\n",
    "                            head_size=self._head_size,\n",
    "                            inner_size=self._inner_size,\n",
    "                            dropout_rate=self._dropout_rate,\n",
    "                            attention_dropout_rate=self._attention_dropout_rate,\n",
    "                            norm_epsilon=1e-12,\n",
    "                            inner_activation=self._inner_activation,\n",
    "                            kernel_initializer=\"variance_scaling\",\n",
    "                            name=\"layer_%d\" % i))\n",
    "\n",
    "        self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)\n",
    "\n",
    "    def call(self,\n",
    "             content_stream,\n",
    "             relative_position_encoding,\n",
    "             state=None,\n",
    "             content_attention_mask=None,\n",
    "             query_attention_mask=None,\n",
    "             target_mapping=None):\n",
    "        \n",
    "        new_mems = []\n",
    "\n",
    "        if state is None:\n",
    "            state = [None] * self._num_layers\n",
    "            \n",
    "        for i in range(self._num_layers):\n",
    "            new_mems.append(_cache_memory(content_stream, state[i], self._memory_length, self._reuse_length))\n",
    "            \n",
    "            transformer_xl_layer = self.transformer_xl_layers[i]\n",
    "            \n",
    "            transformer_xl_output = transformer_xl_layer(\n",
    "                    content_stream=content_stream,\n",
    "                    content_attention_bias=None,\n",
    "                    positional_attention_bias=None,\n",
    "                    relative_position_encoding=None,\n",
    "                    state=state[i],\n",
    "                    content_attention_mask=content_attention_mask,\n",
    "                    query_attention_mask=query_attention_mask,\n",
    "                    target_mapping=target_mapping)\n",
    "            \n",
    "            content_stream = transformer_xl_output[\"content_attention\"]\n",
    "\n",
    "        output_stream = content_stream\n",
    "        return output_stream, new_mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b77a89f5-b11a-48e4-bf4f-cc70f1e74e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set_Attention(keras.Model):\n",
    "    def __init__(self, num_induce, embed_dim, num_heads, stack, use_layernorm, pre_layernorm, use_keras_mha):\n",
    "        super(Set_Attention, self).__init__()\n",
    "        \n",
    "        self.set_attention = (Set_Transformer.InducedSetAttentionBlock(embed_dim=embed_dim,num_heads=num_heads, num_induce=num_induce, use_layernorm=use_layernorm,pre_layernorm=pre_layernorm,use_keras_mha=use_keras_mha))\n",
    "      \n",
    "    def call(self, data, mems):\n",
    "                \n",
    "            attention = self.set_attention([data, mems])\n",
    "                \n",
    "            return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127a4b5-15e3-46e3-838b-a5e18e4d8dc8",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "855d43dd-e182-4c2a-961a-ff9781141f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlModel(keras.Model):\n",
    "    def __init__(self, stack, num_induce, max_files, encoder, block_size, seq_len_padded, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer):\n",
    "        super(XlModel, self).__init__()\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.seq_len_padded = seq_len_padded\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_attention_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxlen = maxlen\n",
    "        self.memory_length = memory_length\n",
    "        self.max_files = max_files\n",
    "        self.encoder = encoder\n",
    "        self.isabs = []\n",
    "        \n",
    "        self.embedding_layer = Create_Embeddings(encoder)\n",
    "\n",
    "        self.linear_layer = keras.layers.Dense(embed_dim)\n",
    "        \n",
    "        self.transformer_xl = TransformerXL(\n",
    "                stack=stack, \n",
    "                num_induce=num_induce, \n",
    "                vocab_size=vocab_size,\n",
    "                num_layers=num_layers,\n",
    "                hidden_size=hidden_size,\n",
    "                num_attention_heads=num_attention_heads,\n",
    "                maxlen=maxlen,\n",
    "                embed_dim=embed_dim,\n",
    "                memory_length=memory_length,\n",
    "                reuse_length=reuse_length,\n",
    "                head_size=head_size,\n",
    "                inner_size=inner_size,\n",
    "                dropout_rate=dropout_rate,\n",
    "                attention_dropout_rate=attention_dropout_rate,\n",
    "                initializer=initializer, \n",
    "            )\n",
    "        \n",
    "\n",
    "        self.pooling_layer = Set_Transformer.PoolingByMultiHeadAttention(num_seeds=1,embed_dim=embed_dim,num_heads=1,use_layernorm=True,pre_layernorm=True, use_keras_mha=True,is_final_block=True)\n",
    "    \n",
    "        self.reshape_layer = keras.layers.Reshape((embed_dim,))\n",
    "   \n",
    "        self.output_layer = keras.layers.Dense(self.max_files, activation=keras.activations.softmax)\n",
    "        \n",
    "    \n",
    "    def call(self, x, training=None):        \n",
    " \n",
    "        mems = tf.zeros((self.num_layers, tf.shape(x)[0], self.memory_length, self.embed_dim))\n",
    "        \n",
    "        embeddings = self.embedding_layer(x)\n",
    "            \n",
    "        linear_transform = self.linear_layer(embeddings)    \n",
    "            \n",
    "        for i in range(0, self.seq_len_padded, self.block_size):\n",
    "            block = embeddings[:,i:i+self.block_size]\n",
    "            \n",
    "            output, mems = self.transformer_xl(content_stream=block, relative_position_encoding=None, state=mems)\n",
    "                \n",
    "        pooling = self.pooling_layer(output)\n",
    "\n",
    "        reshape = self.reshape_layer(pooling)\n",
    "\n",
    "        output = self.output_layer(reshape)          \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469de1-250d-4c14-bb79-a4e74f0fe93e",
   "metadata": {},
   "source": [
    "---\n",
    "# Xl Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bc3ea7d-d4a1-4a1e-bf2a-7cd1c91430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xl Parameters\n",
    "stack = 1\n",
    "num_induce = 30\n",
    "embed_dim = 8\n",
    "num_layers = 8\n",
    "hidden_size = 32\n",
    "num_attention_heads = 8\n",
    "memory_length = 200\n",
    "reuse_length = 0\n",
    "head_size = 8\n",
    "inner_size = 32\n",
    "dropout_rate = 0.01\n",
    "attention_dropout_rate = 0.01\n",
    "initializer = keras.initializers.RandomNormal(stddev=0.1) \n",
    "\n",
    "encoder = pretrained_encoder\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73dc6b6c-ad4a-4b28-916d-160d16dfc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = dict(\n",
    "    stack = 1,\n",
    "    num_induce = 30,\n",
    "    embed_dim = 8,\n",
    "    num_layers = 8,\n",
    "    hidden_size = 32,\n",
    "    num_attention_heads = 8,\n",
    "    memory_length = 200,\n",
    "    reuse_length = 0,\n",
    "    head_size = 8,\n",
    "    inner_size = 32,\n",
    "    dropout_rate = 0.01,\n",
    "    attention_dropout_rate = 0.01,\n",
    "    block_size = block_size,\n",
    "    set_len=set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2a89bb3-457d-4af9-b749-1a9d91656db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkendragivens\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/TransformerXL/STR_XL/wandb/run-20220725_135737-15halbt2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/kendragivens/Str_XL_Induced_Mha/runs/15halbt2\" target=\"_blank\">BS:200/Mem:200</a></strong> to <a href=\"https://wandb.ai/kendragivens/Str_XL_Induced_Mha\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Str_XL_Induced_Mha\", config=Parameters, id='15halbt2', resume='allow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f97faa4-f2d3-405c-96a2-9af61ad87af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = run.summary.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89649663-7d18-48bc-8678-ce5f093908cc",
   "metadata": {},
   "source": [
    "---\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821b0c4a-6d05-4867-a713-474bfdbff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XlModel(stack, num_induce, max_files, encoder, block_size, seq_len, embed_dim, vocab_size, num_layers, hidden_size, num_attention_heads, maxlen, memory_length, reuse_length, head_size, inner_size, dropout_rate, attention_dropout_rate, initializer)\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer = keras.optimizers.Nadam(1e-4), metrics = keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b233b9fc-1c91-49c6-9d35-8fae339acd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Str_Xl_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e79fc-5cbf-4807-a782-ed7cbe4e4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 644/10000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['xl_model/dense_17/kernel:0', 'xl_model/dense_17/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "20/20 [==============================] - 154s 6s/step - loss: 2.4863 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.5022 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658775741.0000 - _runtime: 75085.0000\n",
      "Epoch 645/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.4838 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.5477 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658775853.0000 - _runtime: 75197.0000\n",
      "Epoch 646/10000\n",
      "20/20 [==============================] - 112s 6s/step - loss: 2.5354 - sparse_categorical_accuracy: 0.1800 - val_loss: 2.5663 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658775965.0000 - _runtime: 75309.0000\n",
      "Epoch 647/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4900 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.4967 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658776078.0000 - _runtime: 75422.0000\n",
      "Epoch 648/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4793 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.5504 - val_sparse_categorical_accuracy: 0.1300 - _timestamp: 1658776192.0000 - _runtime: 75536.0000\n",
      "Epoch 649/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4723 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.5005 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658776305.0000 - _runtime: 75649.0000\n",
      "Epoch 650/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.5223 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.4420 - val_sparse_categorical_accuracy: 0.3100 - _timestamp: 1658776418.0000 - _runtime: 75762.0000\n",
      "Epoch 651/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4883 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.5310 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658776532.0000 - _runtime: 75876.0000\n",
      "Epoch 652/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5134 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.5124 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658776645.0000 - _runtime: 75989.0000\n",
      "Epoch 653/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5059 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.4863 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658776759.0000 - _runtime: 76103.0000\n",
      "Epoch 654/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4837 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.5829 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658776872.0000 - _runtime: 76216.0000\n",
      "Epoch 655/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4807 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.5043 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658776985.0000 - _runtime: 76329.0000\n",
      "Epoch 656/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4808 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.6029 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658777099.0000 - _runtime: 76443.0000\n",
      "Epoch 657/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5034 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.5632 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658777212.0000 - _runtime: 76556.0000\n",
      "Epoch 658/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4717 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.5442 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658777325.0000 - _runtime: 76669.0000\n",
      "Epoch 659/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4831 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.5542 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658777438.0000 - _runtime: 76782.0000\n",
      "Epoch 660/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5034 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.4510 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658777552.0000 - _runtime: 76896.0000\n",
      "Epoch 661/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4966 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.5132 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658777665.0000 - _runtime: 77009.0000\n",
      "Epoch 662/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4686 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.5274 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658777778.0000 - _runtime: 77122.0000\n",
      "Epoch 663/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4880 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.5790 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658777892.0000 - _runtime: 77236.0000\n",
      "Epoch 664/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4989 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.5306 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658778005.0000 - _runtime: 77349.0000\n",
      "Epoch 665/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.5049 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.4150 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658778118.0000 - _runtime: 77462.0000\n",
      "Epoch 666/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4312 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.5281 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658778232.0000 - _runtime: 77576.0000\n",
      "Epoch 667/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5014 - sparse_categorical_accuracy: 0.2050 - val_loss: 2.4505 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658778346.0000 - _runtime: 77690.0000\n",
      "Epoch 668/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4494 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.5541 - val_sparse_categorical_accuracy: 0.1200 - _timestamp: 1658778459.0000 - _runtime: 77803.0000\n",
      "Epoch 669/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4831 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.5443 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658778572.0000 - _runtime: 77916.0000\n",
      "Epoch 670/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4137 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.5429 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658778685.0000 - _runtime: 78029.0000\n",
      "Epoch 671/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4325 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.5158 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658778799.0000 - _runtime: 78143.0000\n",
      "Epoch 672/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4430 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.4867 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658778912.0000 - _runtime: 78256.0000\n",
      "Epoch 673/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4674 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.5410 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658779025.0000 - _runtime: 78369.0000\n",
      "Epoch 674/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4907 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.5288 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658779139.0000 - _runtime: 78483.0000\n",
      "Epoch 675/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4971 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.5149 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658779252.0000 - _runtime: 78596.0000\n",
      "Epoch 676/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4519 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.4764 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658779365.0000 - _runtime: 78709.0000\n",
      "Epoch 677/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4634 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.6026 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658779479.0000 - _runtime: 78823.0000\n",
      "Epoch 678/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4553 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.5174 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658779592.0000 - _runtime: 78936.0000\n",
      "Epoch 679/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.5084 - sparse_categorical_accuracy: 0.1700 - val_loss: 2.4964 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658779705.0000 - _runtime: 79049.0000\n",
      "Epoch 680/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4574 - sparse_categorical_accuracy: 0.1950 - val_loss: 2.4749 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658779818.0000 - _runtime: 79162.0000\n",
      "Epoch 681/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4394 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.4421 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658779932.0000 - _runtime: 79276.0000\n",
      "Epoch 682/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4442 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.5261 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658780045.0000 - _runtime: 79389.0000\n",
      "Epoch 683/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4512 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.5151 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658780158.0000 - _runtime: 79502.0000\n",
      "Epoch 684/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4264 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.4504 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658780272.0000 - _runtime: 79616.0000\n",
      "Epoch 685/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4184 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.5819 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658780385.0000 - _runtime: 79729.0000\n",
      "Epoch 686/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4522 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.4261 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658780498.0000 - _runtime: 79842.0000\n",
      "Epoch 687/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4123 - sparse_categorical_accuracy: 0.2900 - val_loss: 2.4836 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658780611.0000 - _runtime: 79955.0000\n",
      "Epoch 688/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4758 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.5093 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658780725.0000 - _runtime: 80069.0000\n",
      "Epoch 689/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4019 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.4257 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658780838.0000 - _runtime: 80182.0000\n",
      "Epoch 690/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4762 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.4600 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658780952.0000 - _runtime: 80296.0000\n",
      "Epoch 691/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4112 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.4952 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658781065.0000 - _runtime: 80409.0000\n",
      "Epoch 692/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4092 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.3779 - val_sparse_categorical_accuracy: 0.3300 - _timestamp: 1658781179.0000 - _runtime: 80523.0000\n",
      "Epoch 693/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4571 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.4493 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658781292.0000 - _runtime: 80636.0000\n",
      "Epoch 694/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4377 - sparse_categorical_accuracy: 0.1900 - val_loss: 2.4529 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658781406.0000 - _runtime: 80750.0000\n",
      "Epoch 695/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4238 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.3962 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658781519.0000 - _runtime: 80863.0000\n",
      "Epoch 696/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4563 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.3675 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658781632.0000 - _runtime: 80976.0000\n",
      "Epoch 697/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4444 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.5406 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658781746.0000 - _runtime: 81090.0000\n",
      "Epoch 698/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3961 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.3766 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658781859.0000 - _runtime: 81203.0000\n",
      "Epoch 699/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4473 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.5020 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658781973.0000 - _runtime: 81317.0000\n",
      "Epoch 700/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4497 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.4691 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658782086.0000 - _runtime: 81430.0000\n",
      "Epoch 701/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3943 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.4628 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658782199.0000 - _runtime: 81543.0000\n",
      "Epoch 702/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4633 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.4880 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658782313.0000 - _runtime: 81657.0000\n",
      "Epoch 703/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4062 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.4790 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658782426.0000 - _runtime: 81770.0000\n",
      "Epoch 704/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4593 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.3794 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658782539.0000 - _runtime: 81883.0000\n",
      "Epoch 705/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4406 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.4878 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658782653.0000 - _runtime: 81997.0000\n",
      "Epoch 706/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4517 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.4788 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658782766.0000 - _runtime: 82110.0000\n",
      "Epoch 707/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4196 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.4494 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658782879.0000 - _runtime: 82223.0000\n",
      "Epoch 708/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4499 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.4246 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658782993.0000 - _runtime: 82337.0000\n",
      "Epoch 709/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3960 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.4339 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658783106.0000 - _runtime: 82450.0000\n",
      "Epoch 710/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4015 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.4961 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658783219.0000 - _runtime: 82563.0000\n",
      "Epoch 711/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4157 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.4728 - val_sparse_categorical_accuracy: 0.3200 - _timestamp: 1658783333.0000 - _runtime: 82677.0000\n",
      "Epoch 712/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4015 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.4060 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658783446.0000 - _runtime: 82790.0000\n",
      "Epoch 713/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4001 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.5456 - val_sparse_categorical_accuracy: 0.1700 - _timestamp: 1658783560.0000 - _runtime: 82904.0000\n",
      "Epoch 714/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4062 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.4053 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658783673.0000 - _runtime: 83017.0000\n",
      "Epoch 715/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4400 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.4864 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658783786.0000 - _runtime: 83130.0000\n",
      "Epoch 716/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4219 - sparse_categorical_accuracy: 0.2575 - val_loss: 2.5748 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658783900.0000 - _runtime: 83244.0000\n",
      "Epoch 717/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4195 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.3820 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658784013.0000 - _runtime: 83357.0000\n",
      "Epoch 718/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4237 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.5530 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658784126.0000 - _runtime: 83470.0000\n",
      "Epoch 719/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4082 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.3765 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658784239.0000 - _runtime: 83583.0000\n",
      "Epoch 720/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4252 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.4068 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658784353.0000 - _runtime: 83697.0000\n",
      "Epoch 721/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4136 - sparse_categorical_accuracy: 0.2375 - val_loss: 2.5517 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658784466.0000 - _runtime: 83810.0000\n",
      "Epoch 722/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4053 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.5111 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658784579.0000 - _runtime: 83923.0000\n",
      "Epoch 723/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4007 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.4699 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658784693.0000 - _runtime: 84037.0000\n",
      "Epoch 724/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3912 - sparse_categorical_accuracy: 0.2575 - val_loss: 2.4463 - val_sparse_categorical_accuracy: 0.1500 - _timestamp: 1658784806.0000 - _runtime: 84150.0000\n",
      "Epoch 725/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3857 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.5206 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658784919.0000 - _runtime: 84263.0000\n",
      "Epoch 726/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4514 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.4763 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658785033.0000 - _runtime: 84377.0000\n",
      "Epoch 727/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3907 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.5218 - val_sparse_categorical_accuracy: 0.1400 - _timestamp: 1658785146.0000 - _runtime: 84490.0000\n",
      "Epoch 728/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3860 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.4853 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658785260.0000 - _runtime: 84604.0000\n",
      "Epoch 729/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3834 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.3962 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658785373.0000 - _runtime: 84717.0000\n",
      "Epoch 730/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4085 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.4648 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658785487.0000 - _runtime: 84831.0000\n",
      "Epoch 731/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3794 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.4535 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658785600.0000 - _runtime: 84944.0000\n",
      "Epoch 732/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3988 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.4628 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658785714.0000 - _runtime: 85058.0000\n",
      "Epoch 733/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4303 - sparse_categorical_accuracy: 0.2000 - val_loss: 2.4805 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658785827.0000 - _runtime: 85171.0000\n",
      "Epoch 734/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3943 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.3896 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658785941.0000 - _runtime: 85285.0000\n",
      "Epoch 735/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4309 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.6124 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658786054.0000 - _runtime: 85398.0000\n",
      "Epoch 736/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4000 - sparse_categorical_accuracy: 0.2175 - val_loss: 2.4674 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658786168.0000 - _runtime: 85512.0000\n",
      "Epoch 737/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3742 - sparse_categorical_accuracy: 0.2925 - val_loss: 2.3830 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658786282.0000 - _runtime: 85626.0000\n",
      "Epoch 738/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3941 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.4161 - val_sparse_categorical_accuracy: 0.3100 - _timestamp: 1658786395.0000 - _runtime: 85739.0000\n",
      "Epoch 739/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4087 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.5015 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658786509.0000 - _runtime: 85853.0000\n",
      "Epoch 740/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3825 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.3819 - val_sparse_categorical_accuracy: 0.1900 - _timestamp: 1658786622.0000 - _runtime: 85966.0000\n",
      "Epoch 741/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3853 - sparse_categorical_accuracy: 0.2525 - val_loss: 2.4725 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658786736.0000 - _runtime: 86080.0000\n",
      "Epoch 742/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4043 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.3857 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658786849.0000 - _runtime: 86193.0000\n",
      "Epoch 743/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4176 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.4490 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658786962.0000 - _runtime: 86306.0000\n",
      "Epoch 744/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4102 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.3436 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658787076.0000 - _runtime: 86420.0000\n",
      "Epoch 745/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3721 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.4199 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658787190.0000 - _runtime: 86534.0000\n",
      "Epoch 746/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3914 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.3650 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658787304.0000 - _runtime: 86648.0000\n",
      "Epoch 747/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4277 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.4074 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658787417.0000 - _runtime: 86761.0000\n",
      "Epoch 748/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4110 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.4047 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658787531.0000 - _runtime: 86875.0000\n",
      "Epoch 749/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3668 - sparse_categorical_accuracy: 0.2300 - val_loss: 2.4866 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658787644.0000 - _runtime: 86988.0000\n",
      "Epoch 750/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3891 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.4556 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658787758.0000 - _runtime: 87102.0000\n",
      "Epoch 751/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3486 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.4093 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658787871.0000 - _runtime: 87215.0000\n",
      "Epoch 752/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3882 - sparse_categorical_accuracy: 0.2500 - val_loss: 2.4329 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658787985.0000 - _runtime: 87329.0000\n",
      "Epoch 753/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3443 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.4136 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658788098.0000 - _runtime: 87442.0000\n",
      "Epoch 754/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4008 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.3712 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658788212.0000 - _runtime: 87556.0000\n",
      "Epoch 755/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3793 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.5018 - val_sparse_categorical_accuracy: 0.2100 - _timestamp: 1658788326.0000 - _runtime: 87670.0000\n",
      "Epoch 756/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4003 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.3623 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658788439.0000 - _runtime: 87783.0000\n",
      "Epoch 757/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3530 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.4610 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658788553.0000 - _runtime: 87897.0000\n",
      "Epoch 758/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.4029 - sparse_categorical_accuracy: 0.2550 - val_loss: 2.4632 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658788666.0000 - _runtime: 88010.0000\n",
      "Epoch 759/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.4021 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.3669 - val_sparse_categorical_accuracy: 0.2900 - _timestamp: 1658788780.0000 - _runtime: 88124.0000\n",
      "Epoch 760/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3626 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.3872 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658788894.0000 - _runtime: 88238.0000\n",
      "Epoch 761/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3814 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.4733 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658789007.0000 - _runtime: 88351.0000\n",
      "Epoch 762/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3555 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.4586 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658789121.0000 - _runtime: 88465.0000\n",
      "Epoch 763/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3974 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.3914 - val_sparse_categorical_accuracy: 0.3300 - _timestamp: 1658789234.0000 - _runtime: 88578.0000\n",
      "Epoch 764/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3337 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.4403 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658789348.0000 - _runtime: 88692.0000\n",
      "Epoch 765/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3850 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.4654 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658789461.0000 - _runtime: 88805.0000\n",
      "Epoch 766/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3513 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.3559 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658789575.0000 - _runtime: 88919.0000\n",
      "Epoch 767/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3422 - sparse_categorical_accuracy: 0.2625 - val_loss: 2.3168 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658789689.0000 - _runtime: 89033.0000\n",
      "Epoch 768/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3487 - sparse_categorical_accuracy: 0.2800 - val_loss: 2.3384 - val_sparse_categorical_accuracy: 0.3200 - _timestamp: 1658789803.0000 - _runtime: 89147.0000\n",
      "Epoch 769/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3517 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.3769 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658789916.0000 - _runtime: 89260.0000\n",
      "Epoch 770/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3951 - sparse_categorical_accuracy: 0.2850 - val_loss: 2.4456 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658790030.0000 - _runtime: 89374.0000\n",
      "Epoch 771/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3354 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.3531 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658790143.0000 - _runtime: 89487.0000\n",
      "Epoch 772/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3026 - sparse_categorical_accuracy: 0.2575 - val_loss: 2.4244 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658790257.0000 - _runtime: 89601.0000\n",
      "Epoch 773/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3095 - sparse_categorical_accuracy: 0.2875 - val_loss: 2.3289 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658790370.0000 - _runtime: 89714.0000\n",
      "Epoch 774/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3314 - sparse_categorical_accuracy: 0.2700 - val_loss: 2.4647 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658790484.0000 - _runtime: 89828.0000\n",
      "Epoch 775/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3227 - sparse_categorical_accuracy: 0.2925 - val_loss: 2.3691 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658790598.0000 - _runtime: 89942.0000\n",
      "Epoch 776/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3566 - sparse_categorical_accuracy: 0.2800 - val_loss: 2.3977 - val_sparse_categorical_accuracy: 0.2600 - _timestamp: 1658790711.0000 - _runtime: 90055.0000\n",
      "Epoch 777/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3925 - sparse_categorical_accuracy: 0.2425 - val_loss: 2.4592 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658790825.0000 - _runtime: 90169.0000\n",
      "Epoch 778/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3488 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.4040 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658790938.0000 - _runtime: 90282.0000\n",
      "Epoch 779/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3431 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.4348 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658791052.0000 - _runtime: 90396.0000\n",
      "Epoch 780/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3597 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.3587 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658791165.0000 - _runtime: 90509.0000\n",
      "Epoch 781/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3165 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.5685 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658791279.0000 - _runtime: 90623.0000\n",
      "Epoch 782/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3705 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.3596 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658791392.0000 - _runtime: 90736.0000\n",
      "Epoch 783/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3630 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.3949 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658791506.0000 - _runtime: 90850.0000\n",
      "Epoch 784/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3679 - sparse_categorical_accuracy: 0.2600 - val_loss: 2.4009 - val_sparse_categorical_accuracy: 0.3000 - _timestamp: 1658791619.0000 - _runtime: 90963.0000\n",
      "Epoch 785/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3797 - sparse_categorical_accuracy: 0.2250 - val_loss: 2.3127 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658791733.0000 - _runtime: 91077.0000\n",
      "Epoch 786/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3755 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.3049 - val_sparse_categorical_accuracy: 0.2500 - _timestamp: 1658791847.0000 - _runtime: 91191.0000\n",
      "Epoch 787/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3209 - sparse_categorical_accuracy: 0.2450 - val_loss: 2.3681 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658791961.0000 - _runtime: 91305.0000\n",
      "Epoch 788/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3358 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.3564 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658792074.0000 - _runtime: 91418.0000\n",
      "Epoch 789/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3608 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.4777 - val_sparse_categorical_accuracy: 0.1600 - _timestamp: 1658792188.0000 - _runtime: 91532.0000\n",
      "Epoch 790/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3678 - sparse_categorical_accuracy: 0.2800 - val_loss: 2.4433 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658792301.0000 - _runtime: 91645.0000\n",
      "Epoch 791/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3371 - sparse_categorical_accuracy: 0.2475 - val_loss: 2.3979 - val_sparse_categorical_accuracy: 0.2400 - _timestamp: 1658792415.0000 - _runtime: 91759.0000\n",
      "Epoch 792/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.2984 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.4508 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658792528.0000 - _runtime: 91872.0000\n",
      "Epoch 793/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.2989 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.3533 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658792642.0000 - _runtime: 91986.0000\n",
      "Epoch 794/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3347 - sparse_categorical_accuracy: 0.2100 - val_loss: 2.3663 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658792755.0000 - _runtime: 92099.0000\n",
      "Epoch 795/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3039 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.3209 - val_sparse_categorical_accuracy: 0.2000 - _timestamp: 1658792869.0000 - _runtime: 92213.0000\n",
      "Epoch 796/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3035 - sparse_categorical_accuracy: 0.2925 - val_loss: 2.4777 - val_sparse_categorical_accuracy: 0.1800 - _timestamp: 1658792982.0000 - _runtime: 92326.0000\n",
      "Epoch 797/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3571 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.3543 - val_sparse_categorical_accuracy: 0.2800 - _timestamp: 1658793096.0000 - _runtime: 92440.0000\n",
      "Epoch 798/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3157 - sparse_categorical_accuracy: 0.2775 - val_loss: 2.3434 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658793209.0000 - _runtime: 92553.0000\n",
      "Epoch 799/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3335 - sparse_categorical_accuracy: 0.2825 - val_loss: 2.4068 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658793323.0000 - _runtime: 92667.0000\n",
      "Epoch 800/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3216 - sparse_categorical_accuracy: 0.2750 - val_loss: 2.4051 - val_sparse_categorical_accuracy: 0.2200 - _timestamp: 1658793436.0000 - _runtime: 92780.0000\n",
      "Epoch 801/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3775 - sparse_categorical_accuracy: 0.2350 - val_loss: 2.3912 - val_sparse_categorical_accuracy: 0.2900 - _timestamp: 1658793550.0000 - _runtime: 92894.0000\n",
      "Epoch 802/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3645 - sparse_categorical_accuracy: 0.2225 - val_loss: 2.3744 - val_sparse_categorical_accuracy: 0.2300 - _timestamp: 1658793663.0000 - _runtime: 93007.0000\n",
      "Epoch 803/10000\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.3252 - sparse_categorical_accuracy: 0.2325 - val_loss: 2.3630 - val_sparse_categorical_accuracy: 0.2700 - _timestamp: 1658793777.0000 - _runtime: 93121.0000\n",
      "Epoch 804/10000\n",
      "20/20 [==============================] - 114s 6s/step - loss: 2.3742 - sparse_categorical_accuracy: 0.2400 - val_loss: 2.3271 - val_sparse_categorical_accuracy: 0.2900 - _timestamp: 1658793891.0000 - _runtime: 93235.0000\n",
      "Epoch 805/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.3352 - sparse_categorical_accuracy: 0.2450"
     ]
    }
   ],
   "source": [
    "history = model.fit(initial_epoch=initial_epoch, x=train_dataset, validation_data=val_dataset, epochs=epochs, verbose=1, callbacks=[wandb.keras.WandbCallback(save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6e04f-8083-48e5-a7cf-1d38fa2a3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd3ce8-bf54-4900-ba0d-33848bf129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6add5-4de7-4339-8689-408e9549634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./Saved_Models/Str_Xl_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fdb61df-30cd-40bc-8cb4-7b95364f04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./Saved_Models/Str_Xl_Induced.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d8f6-2e7a-4a97-8a6a-aa3cfc571008",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0feaa-ccf4-4352-bddc-728529531858",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3f83-2d73-4c19-a50e-eb8a5c636edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ebaae-0583-4553-a957-7d1f45958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eef17b-b311-4277-9bb7-87f05d897473",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c99b9-a5d1-4d9e-a1ee-8d39f8e6dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_samples[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504f3ab-5e7b-4082-b017-f46b0b8fbcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
